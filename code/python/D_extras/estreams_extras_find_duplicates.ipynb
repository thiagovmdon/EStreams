{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e94d6f",
   "metadata": {},
   "source": [
    "# Find duplicate candidates\n",
    "\n",
    "\n",
    "Author: Thiago Nascimento (thiago.nascimento@eawag.ch)\n",
    "\n",
    "This notebook is part of the EStreams publication and is used to find potential duplicated catchments within the dataset.\n",
    "\n",
    "* Note that this code enables not only the replicability of the current database but also the extrapolation to new catchment areas. \n",
    "* Additionally, the user should download and insert the original raw-data in the folder of the same name prior to run this code. \n",
    "* The original third-party data used were not made available in this repository due to redistribution and storage-space reasons.  \n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "\n",
    "* Python>=3.6\n",
    "* Jupyter\n",
    "* geopandas=0.10.2\n",
    "* numpy\n",
    "* os\n",
    "* pandas\n",
    "* shapely\n",
    "* textdistance\n",
    "* tqdm\n",
    "* warnings\n",
    "\n",
    "Check the Github repository for an environment.yml (for conda environments) or requirements.txt (pip) file.\n",
    "\n",
    "**Files:**\n",
    "\n",
    "* data/streamflow/estreams_gauging_stations.csv\n",
    "\n",
    "**Directory:**\n",
    "\n",
    "* Clone the GitHub directory locally\n",
    "* Place any third-data variables in their respective directory.\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. \n",
    "\n",
    "## References\n",
    "\n",
    "\n",
    "## Observations\n",
    "* As this step is rather qualitative, we believe that the users can also adapt the conditons accordinly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7648ab",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "import os\n",
    "import warnings\n",
    "import textdistance\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c9d67",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13078a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variables\n",
    "# Relative path to your local directory\n",
    "PATH = \"../../..\"\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Constrains\n",
    "JARO_THRESHOLD = 0.75\n",
    "SPATIAL_THRESHOLD = 1000\n",
    "PROVIDER_THRESHOLD = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c05d88a",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f5fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-editable variables:\n",
    "PATH_OUTPUT = \"results/\"\n",
    "\n",
    "# Set the directory:\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909fe84",
   "metadata": {},
   "source": [
    "# Import data\n",
    "## Streamflow gauges network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b61c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_estreams = pd.read_csv('data/streamflow/estreams_gauging_stations.csv', encoding='utf-8')\n",
    "network_estreams.set_index(\"basin_id\", inplace = True)\n",
    "network_estreams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d3d112",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e595f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to clip the data to be used:\n",
    "df = network_estreams.iloc[:, :]\n",
    "\n",
    "# Create a GeoDataFrame from DataFrame with WGS 84 coordinates\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(network_estreams['lon'], network_estreams['lat'])]\n",
    "gdf_wgs84 = gpd.GeoDataFrame(network_estreams, geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "# Reproject the GeoDataFrame to ETRS89 LAEA (EPSG:3035)\n",
    "gdf_etrs89 = gdf_wgs84.to_crs(epsg=3035)\n",
    "\n",
    "df = gdf_etrs89.loc[df.index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4e164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store distances\n",
    "distances = {}\n",
    "\n",
    "# Calculate Jaro-Winkler distance for each unique pair of 'gauge_name'\n",
    "for i, row1 in tqdm.tqdm(df.iterrows()):\n",
    "    for j, row2 in gdf_etrs89.iterrows():\n",
    "        # Skip self-comparisons\n",
    "        if i != j:\n",
    "            # Calculate gauge name distance\n",
    "            try:\n",
    "                gauge_distance = textdistance.jaro_winkler(row1['gauge_name'].lower(), row2['gauge_name'].lower())\n",
    "            except: \n",
    "                gauge_distance = np.nan\n",
    "                \n",
    "            # Calculate river distance\n",
    "            try:\n",
    "                river_distance = textdistance.jaro_winkler(row1['river'].lower(), row2['river'].lower())\n",
    "            except: \n",
    "                river_distance = np.nan\n",
    "                \n",
    "\n",
    "            provider_distance = row1['gauge_provider'].lower() == row2['gauge_provider'].lower()          \n",
    "        \n",
    "            # Calculate distance between points\n",
    "            point1 = row1['geometry']\n",
    "            point2 = row2['geometry']\n",
    "            point_distance = point1.distance(point2)\n",
    "            \n",
    "            # gauges and river distance normalized:\n",
    "            #dist_norm = (gauge_distance + river_distance)/2\n",
    "            \n",
    "            # Store distances along with first and second gauge indices only if gauge_distance > 0.9\n",
    "            if (gauge_distance > JARO_THRESHOLD) & (river_distance > JARO_THRESHOLD) & (point_distance < SPATIAL_THRESHOLD) & (provider_distance == False):\n",
    "                distances[(row1['gauge_name'], row2['gauge_name'])] = {'gauge_first_index': i, \n",
    "                                                                        'gauge_second_index': j,\n",
    "                                                                        'gauge_distance': gauge_distance, \n",
    "                                                                        'river_distance': river_distance,\n",
    "                                                                        'point_distance': point_distance,\n",
    "                                                                        'provider_distance': provider_distance}\n",
    "# Convert dictionary to DataFrame for visualization\n",
    "dist_df = pd.DataFrame.from_dict(distances, orient='index')\n",
    "dist_df.index.names = ['gauge_name1', 'gauge_name2']\n",
    "dist_df.reset_index(inplace = True)\n",
    "dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c50f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dist_df.gauge_first_index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec22675",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_name = dist_df['gauge_first_index'].value_counts().idxmax()\n",
    "\n",
    "print(\"The most common name in the column is:\", most_common_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df[dist_df.gauge_first_index == \"ITLI0307\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df['gauge_first_index'].value_counts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093dd8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we add the list of duplicated suspects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_estreams[\"duplicated_suspect\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First column:\n",
    "for gauge in tqdm.tqdm(dist_df.gauge_first_index):\n",
    "    \n",
    "    duplicated_list = str(dist_df.gauge_second_index[dist_df.gauge_first_index == gauge].tolist()).replace(\"[\", \"\")\n",
    "    duplicated_list = duplicated_list.replace(\"]\", \"\")\n",
    "    duplicated_list = duplicated_list.replace(\"'\", \"\")\n",
    "    network_estreams.loc[gauge, \"duplicated_suspect\"] = duplicated_list\n",
    "    network_estreams.loc[gauge, \"duplicated_suspect\"] = network_estreams.loc[gauge, \"duplicated_suspect\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second column:\n",
    "for gauge in tqdm.tqdm(dist_df.gauge_second_index):\n",
    "    \n",
    "    duplicated_list = str(dist_df.gauge_first_index[dist_df.gauge_second_index == gauge].tolist()).replace(\"[\", \"\")\n",
    "    duplicated_list = duplicated_list.replace(\"]\", \"\")\n",
    "    duplicated_list = duplicated_list.replace(\"'\", \"\")\n",
    "    network_estreams.loc[gauge, \"duplicated_suspect\"] = duplicated_list\n",
    "    network_estreams.loc[gauge, \"duplicated_suspect\"] = network_estreams.loc[gauge, \"duplicated_suspect\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a903f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_estreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_estreams.loc[\"ITLI0307\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data:\n",
    "network_estreams.to_csv(\"results/extras/estreams_gauging_stations_duplicates.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfa5cd2",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
