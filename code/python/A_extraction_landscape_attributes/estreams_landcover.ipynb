{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9429523",
   "metadata": {},
   "source": [
    "# Landcover attributes extraction\n",
    "\n",
    "Author: Thiago Nascimento (thiago.nascimento@eawag.ch)\n",
    "\n",
    "This notebook is part of the EStreams publication and was used to extract and aggregate the lancover characteristics from the Corine dataset.\n",
    "\n",
    "* Note that this code enables not only the replicability of the current database but also the extrapolation to new catchment areas. \n",
    "* Additionally, the user should download and insert the original raw-data in the folder of the same name prior to run this code. \n",
    "* The original third-party data used were not made avaialable in this repository due to redistribution and storage-space reasons.\n",
    "\n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "* Python>=3.6\n",
    "* Jupyter\n",
    "* geopandas=0.10.2\n",
    "* glob\n",
    "* numpy\n",
    "* os\n",
    "* pandas\n",
    "* tqdm\n",
    "\n",
    "Check the Github repository for an environment.yml (for conda environments) or requirements.txt (pip) file.\n",
    "\n",
    "**Files:**\n",
    "* data/gee/landcover/EStreams_lulc{1990, 2000, 2006, 2012, 2018}_attributes_gee.csv. Landcover attributes CSV-files exported from GEE\n",
    "* data/shapefiles/estreams_catchments.shp\n",
    "\n",
    "**Directory:**\n",
    "* Clone the GitHub directory locally\n",
    "* Place any third-data variables in their respective directory.\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. \n",
    "\n",
    "## References\n",
    "\n",
    "* CORINE Land Cover â€” Copernicus Land Monitoring Service. European Environment Agency [data set], Copenhagen, Denmark https://land.copernicus.eu/en/products/corine-land-cover.\n",
    "\n",
    "## Licenses\n",
    "* Corine: Open access. \"The Copernicus land monitoring products and services are made available on a principle of full, open and free access, as established by the Commission Delegated Regulation (EU) No 1159/2013 of 12 July 2013.\" https://land.copernicus.eu/en/data-policy (Last access 27 November 2023)\n",
    "\n",
    "## Observations\n",
    "* This notebook assumes that the GEE code to export the landcover descriptors from the Corine dataset (EStreams_landscape_attributes_landcover_gee.txt) was run before in the GEE platform and that all the output CSV-files are locally available. \n",
    "* It is possible that there are more than one CSV-file per year if the user decided to subset the catchments in smaller groups for optimze the exportation. \n",
    "* All the lulc csv-files must be placed in a single folder together. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395ba82c",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026bcd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tqdm as tqdm\n",
    "import glob\n",
    "from utils.landcover import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f5a4e8",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variables:\n",
    "# Relative path to your local directory\n",
    "PATH = \"../../..\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0669544",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a31d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-editable variables:\n",
    "PATH_LULC=\"data/gee/landcover\"\n",
    "PATH_OUTPUT = \"results/staticattributes/\"\n",
    "\n",
    "# Set the directory:\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896190fa",
   "metadata": {},
   "source": [
    "# Import data\n",
    "## Catchment boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ab7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_boundaries = gpd.read_file('data/shapefiles/estreams_catchments.shp')\n",
    "catchment_boundaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The total number of catchments to be processed are:\", len(catchment_boundaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc66947a",
   "metadata": {},
   "source": [
    "# Reproject to projected coordinates system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96009f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target CRS to ETRS89 LAEA\n",
    "target_crs = 'EPSG:3035' \n",
    "\n",
    "# Reproject the GeoDataFrame to the target CRS\n",
    "catchment_boundaries_reprojected = catchment_boundaries.to_crs(target_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b2905",
   "metadata": {},
   "source": [
    "## GEE outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8246c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the files in the subdirectory:\n",
    "filenames = glob.glob(PATH_LULC + \"/*.csv\")\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab08d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create an empty dataframe for the data:\n",
    "landcover_df = pd.DataFrame()\n",
    "\n",
    "# Loop for reading and concatenating the data:\n",
    "for file in tqdm.tqdm(filenames):\n",
    "    \n",
    "    # First we read our data:\n",
    "    landcover_file = pd.read_csv(file)\n",
    "    landcover_file.drop([\"system:index\", \".geo\"], axis = 1, inplace = True)\n",
    "    landcover_file[\"class_name\"] = \"lulc_\" + landcover_file[\"year\"].astype(str) + \"_\" + landcover_file[\"class\"].astype(str)\n",
    "    year = landcover_file.loc[0, \"year\"]\n",
    "    \n",
    "    # Here we can create a pivot-table to organize our dataset:\n",
    "    landcover_pivot = pd.pivot_table(\n",
    "        landcover_file,\n",
    "        values='area_sqm',          \n",
    "        index='code',               # Rows are based on 'code'\n",
    "        columns='class_name',       # Columns are based on 'class_name'\n",
    "        fill_value=np.nan)\n",
    "    \n",
    "    # Total are per year:\n",
    "    #landcover_pivot[str(year)+\"_tot_area\"] = landcover_pivot.sum(axis = 1)\n",
    "    #landcover_pivot.iloc[:, :-1] = landcover_pivot.iloc[:, :-1].div(landcover_pivot[str(year)+\"_tot_area\"], axis=0)\n",
    "    landcover_pivot[\"tot_area_\"+str(year)] = landcover_pivot.sum(axis = 1)\n",
    "    landcover_pivot.iloc[:, :-1] = landcover_pivot.iloc[:, :-1].div(landcover_pivot[\"tot_area_\"+str(year)], axis=0)\n",
    "    \n",
    "    # Now we proceed with the concatenation:\n",
    "    landcover_df = pd.concat([landcover_df, landcover_pivot], axis=1)\n",
    "    \n",
    "    # Here we deal with the case we have more than one file for the same year:\n",
    "    landcover_df = landcover_df.T.groupby(level=0).apply(lambda group: group.ffill().bfill().iloc[0]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c3a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we add the majority class for each basin:\n",
    "landcover_df = pd.concat([landcover_df, landcover_df.apply(get_majority_columns, axis=1)], axis=1)\n",
    "\n",
    "landcover_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161edbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we add the percentage of each catchment area covered by the Corine (there are countries not covered)\n",
    "columns_tot_areas = [\"tot_area_1990\", \"tot_area_2000\", \"tot_area_2006\", \"tot_area_2012\", \"tot_area_2018\"]\n",
    "\n",
    "landcover_df.loc[:, columns_tot_areas] = landcover_df.loc[:, columns_tot_areas].div(catchment_boundaries_reprojected.set_index(\"basin_id\").area, axis=0)\n",
    "landcover_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e35dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we sort the index:\n",
    "landcover_df = landcover_df.sort_index(axis=0)\n",
    "landcover_df.index.name = \"basin_id\"\n",
    "landcover_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the data to 3 decimals:\n",
    "landcover_df.iloc[:, 0:-5] = landcover_df.iloc[:, 0:-5].astype(float).round(3)\n",
    "landcover_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc9bf04",
   "metadata": {},
   "source": [
    "# Data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the final dataset:\n",
    "landcover_df.to_csv(PATH_OUTPUT+\"estreams_landcover_attributes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3890db",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
