{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e94d6f",
   "metadata": {},
   "source": [
    "# Hydrological attributes extraction\n",
    "\n",
    "\n",
    "Author: Thiago Nascimento (thiago.nascimento@eawag.ch)\n",
    "\n",
    "This notebook is part of the EStreams publication and was used to extract and aggregate the hydrological attributes from the GeoDAR and HydroLakes database. \n",
    "\n",
    "* Note that this code enables not only the replicability of the current database but also the extrapolation to new catchment areas. \n",
    "* Additionally, the user should download and insert the original raw-data in the folder of the same name prior to run this code. \n",
    "* The original third-party data used were not made available in this repository due to redistribution and storage-space reasons.  \n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "\n",
    "* Python>=3.6\n",
    "* Jupyter\n",
    "* geopandas=0.10.2\n",
    "* pandas\n",
    "* numpy\n",
    "* tqdm\n",
    "* os\n",
    "* osgeo\n",
    "\n",
    "Check the Github repository for an environment.yml (for conda environments) or requirements.txt (pip) file.\n",
    "\n",
    "**Files:**\n",
    "\n",
    "* data/hidrology/GeoDAR_v11_dams.shp. Available at: https://doi.org/10.5281/zenodo.6163413 (Last access: 23 November 2023)\n",
    "* data/hidrology/GeoDAR_v11_reservoirs.shp. Available at: https://doi.org/10.5281/zenodo.6163413 (Last access: 23 November 2023)\n",
    "* data/hidrology/GRanD_v13_issues.csv. Available at: https://doi.org/10.5281/zenodo.6163413 (Last access: 23 November 2023)\n",
    "* data/hidrology/HydroLAKES_polys_v10.shp. Available at: https://www.hydrosheds.org/products/hydrolakes (Last access 05 December 2023)\n",
    "* data/shapefiles/estreams_boundaries.shp\n",
    "\n",
    "**Directory:**\n",
    "\n",
    "* Clone the GitHub directory locally\n",
    "* Place any third-data variables in their respective directory.\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. \n",
    "\n",
    "## References\n",
    "\n",
    "* GeoDAR Dataset:  Jida Wang, Blake A. Walter, Fangfang Yao, Chunqiao Song, Meng Ding, Abu S. Maroof, Jingying Zhu, Chenyu Fan, Jordan M. McAlister, Md Safat Sikder, Yongwei Sheng, George H. Allen, Jean-François Crétaux, & Yoshihide Wada. (2022). GeoDAR: Georeferenced global Dams And Reservoirs dataset for bridging attributes and geolocations [Data set]. In Earth System Science Data (v1.1; v1.0, Vol. 14, Number 4, pp. 1869–1899). Zenodo. https://doi.org/10.5281/zenodo.6163413 (Last access: 23 November 2023)\n",
    "\n",
    "* Wang, J. et al. GeoDAR: georeferenced global dams and reservoirs dataset for bridging attributes and geolocations. Earth Syst Sci Data 14, 1869–1899 (2022).\n",
    "\n",
    "* Messager, M.L., Lehner, B., Grill, G., Nedeva, I., Schmitt, O. (2016). Estimating the volume and age of water stored in global lakes using a geo-statistical approach. Nature Communications, 7: 13603. https://doi.org/10.1038/ncomms13603\n",
    "\n",
    "## Licenses\n",
    "* GeoDAR: CC BY 4.0. https://doi.org/10.5281/zenodo.6163413 (Last access: 27 November 2023)\n",
    "* HydroLAKES: CC BY 4.0. https://www.hydrosheds.org/products/hydrolakes (Last access: 27 November 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7648ab",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "import os\n",
    "from utils.hydrology import count_geometries_in_polygons\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c9d67",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13078a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variables:\n",
    "# Relative path to your local directory\n",
    "PATH = \"../../..\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c05d88a",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f5fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-editable variables:\n",
    "PATH_OUTPUT = \"results/staticattributes/\"\n",
    "# Set SHAPE_RESTORE_SHX config option to avoid problems when SHX is missing.\n",
    "gdal.SetConfigOption('SHAPE_RESTORE_SHX', 'YES')\n",
    "# Set the directory:\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909fe84",
   "metadata": {},
   "source": [
    "# Import data\n",
    "## Catchment boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5948d5bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "catchment_boundaries = gpd.read_file('data/shapefiles/Catchment_Boundaries_HUGR_33new.shp')\n",
    "catchment_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The total number of catchments to be processed are:\", len(catchment_boundaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761ff848",
   "metadata": {},
   "source": [
    "## GeoDAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f47633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dams and reservois shapefiles:\n",
    "GeoDAR_v11_dams = gpd.read_file('data/hydrology/GeoDAR_v11_dams.shp')\n",
    "GeoDAR_v11_dams.replace(-999.0, np.nan, inplace = True)\n",
    "\n",
    "GeoDAR_v11_reservoirs = gpd.read_file('data/hydrology/GeoDAR_v11_reservoirs.shp')\n",
    "GeoDAR_v11_reservoirs.replace(-999.0, np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab799a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRanD file with extra information:\n",
    "GRanD_v13_issues = pd.read_csv('data/hydrology/GRanD_v13_issues.csv', index_col=0)\n",
    "GRanD_v13_issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e5a3f",
   "metadata": {},
   "source": [
    "## HydroLAKES data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HydroLAKES shapefiles:\n",
    "hydroLAKES = gpd.read_file('data/hydrology/HydroLAKES_polys_v10.shp')\n",
    "hydroLAKES.replace(-9999.0, np.nan, inplace = True)\n",
    "\n",
    "hydroLAKES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa57cc5",
   "metadata": {},
   "source": [
    "## Concatenate information from GRanD_v13_issues.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create an auxiliar dataframe to help with the concatenation:\n",
    "GeoDAR_v11_dams_aux = GeoDAR_v11_dams.loc[:, [\"id_grd_v13\", \"id_v11\"]].copy()\n",
    "GeoDAR_v11_dams_aux = GeoDAR_v11_dams_aux[GeoDAR_v11_dams_aux.id_grd_v13>0] #Delete the -999 values\n",
    "GeoDAR_v11_dams_aux.set_index(\"id_grd_v13\", inplace = True)\n",
    "\n",
    "# Here we retrieve the year of construction of the dam:\n",
    "GeoDAR_v11_dams_aux[\"YEAR\"] = GRanD_v13_issues.YEAR\n",
    "\n",
    "# Now we set the id_v11 as index:\n",
    "GeoDAR_v11_dams_aux.set_index(\"id_v11\", inplace = True)\n",
    "\n",
    "#Here we assign the YEAR value when avaialble:\n",
    "GeoDAR_v11_dams.set_index(\"id_v11\", inplace = True)\n",
    "GeoDAR_v11_dams[\"YEAR\"] = GeoDAR_v11_dams_aux[\"YEAR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8491031",
   "metadata": {},
   "source": [
    "## Reproject the coordinates system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can check the crs of the datasets:\n",
    "print(\"CRS of catchment_boundaries:\", catchment_boundaries.crs)\n",
    "print(\"CRS of GeoDAR_v11_dams:\", GeoDAR_v11_dams.crs)\n",
    "print(\"CRS of GeoDAR_v11_reservoirs:\", GeoDAR_v11_reservoirs.crs)\n",
    "print(\"CRS of hydroLAKES:\", hydroLAKES.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be378c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target CRS to ETRS89 LAEA (3035)\n",
    "target_crs = 'EPSG:4326'  \n",
    "\n",
    "# Reproject the GeoDataFrame to the target CRS\n",
    "GeoDAR_v11_reservoirs_reprojected = GeoDAR_v11_reservoirs.to_crs(target_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5677474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can check the crs of the datasets:\n",
    "print(\"CRS of GeoDAR_v11_reservoirs_reprojected:\", GeoDAR_v11_reservoirs_reprojected.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d52822",
   "metadata": {},
   "source": [
    "# Intersection areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e5516",
   "metadata": {},
   "source": [
    "## Number of dams and reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ad753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create an empty dataframe:\n",
    "hydrology_df = pd.DataFrame()\n",
    "\n",
    "# Here we use utils.count_geometries_in_polygons function\n",
    "hydrology_df[\"dam_num\"] = count_geometries_in_polygons(GeoDAR_v11_dams, catchment_boundaries, \"basin_id\", new_column=\"dam_num\")\n",
    "hydrology_df[\"res_num\"] = count_geometries_in_polygons(GeoDAR_v11_reservoirs_reprojected, catchment_boundaries, \"basin_id\", new_column=\"res_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrology_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8413991",
   "metadata": {},
   "source": [
    "## Max and min year of dam's construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333138d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = gpd.sjoin(GeoDAR_v11_dams, catchment_boundaries, how=\"inner\", op='within')\n",
    "\n",
    "hydrology_df[\"dam_yr_first\"] = data_merged.loc[:, [\"basin_id\", \"YEAR\"]].groupby('basin_id').agg('min').copy()\n",
    "hydrology_df[\"dam_yr_last\"] = data_merged.loc[:, [\"basin_id\", \"YEAR\"]].groupby('basin_id').agg('max').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b289a49a",
   "metadata": {},
   "source": [
    "## Reservoir maximum capacity (total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a705d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = gpd.sjoin(GeoDAR_v11_reservoirs_reprojected, catchment_boundaries, how=\"inner\", op='within')\n",
    "\n",
    "hydrology_df[\"res_tot_sto\"] = data_merged.loc[:, [\"basin_id\", \"rv_mcm_v11\"]].groupby('basin_id').agg('sum').copy()\n",
    "\n",
    "# Here we correct the res_tot_sto to be set as nan when no information is avaialble and not 0\n",
    "hydrology_df.loc[:, \"res_tot_sto\"].replace(0, np.nan, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1589ac9",
   "metadata": {},
   "source": [
    "## Number of lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e842985",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrology_df[\"lakes_num\"] = count_geometries_in_polygons(hydroLAKES, catchment_boundaries, \"basin_id\", new_column=\"lakes_num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d1706",
   "metadata": {},
   "source": [
    "## Total upstream lakes' area and volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e53287",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = gpd.sjoin(hydroLAKES, catchment_boundaries, how=\"inner\", op='within')\n",
    "\n",
    "hydrology_df[\"lakes_tot_area\"] = data_merged.loc[:, [\"basin_id\", \"Lake_area\"]].groupby('basin_id').agg('sum').copy()\n",
    "hydrology_df[\"lakes_tot_vol\"] = data_merged.loc[:, [\"basin_id\", \"Vol_total\"]].groupby('basin_id').agg('sum').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f3f186",
   "metadata": {},
   "source": [
    "## Check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f492d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrology_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befbca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we sort the index:\n",
    "hydrology_df = hydrology_df.sort_index(axis=0)\n",
    "hydrology_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b93caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the data to 3 decimals\n",
    "hydrology_df = hydrology_df.astype(float).round(3)\n",
    "hydrology_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b61f8",
   "metadata": {},
   "source": [
    "# Data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce35b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the final dataset:\n",
    "hydrology_df.to_csv(PATH_OUTPUT+\"estreams_hydrology_attributes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfa5cd2",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
