{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e94d6f",
   "metadata": {},
   "source": [
    "# Streamflow indices computation\n",
    "\n",
    "Author: Thiago Nascimento (thiago.nascimento@eawag.ch)\n",
    "\n",
    "This notebook is part of the EStreams publication and was used to the computation of the miscelaneous of streamflow indexes provided in this publication.\n",
    "\n",
    "* Note that this code enables not only the replicability of the current database but also the extrapolation to new catchment areas. \n",
    "* Additionally, the user should download and insert the original raw-data in the folder of the same name prior to run this code. \n",
    "* The original third-party data used were not made available in this repository due to redistribution and storage-space reasons.  \n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "\n",
    "* Python>=3.6\n",
    "* Jupyter\n",
    "* geopandas=0.10.2\n",
    "* numpy\n",
    "* os\n",
    "* pandas\n",
    "* tqdm\n",
    "\n",
    "Check the Github repository for an environment.yml (for conda environments) or requirements.txt (pip) file.\n",
    "\n",
    "**Files:**\n",
    "\n",
    "* data/streamflow/estreams_gauging_stations.csv\n",
    "* data/streamflow/estreams_timeseries_runoff.csv\n",
    "* data/shapefiles/estreams_catchments.shp\n",
    "\n",
    "**Directory:**\n",
    "\n",
    "* Clone the GitHub directory locally\n",
    "* Place any third-data variables in their respective directory.\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. \n",
    "\n",
    "## References\n",
    "* Do, H. X., Gudmundsson, L., Leonard, M. & Westra, S. The Global Streamflow Indices and Metadata Archive (GSIM)-Part 1: The production of a daily streamflow archive and metadata. Earth Syst Sci Data 10, 765–785 (2018).\n",
    "\n",
    "* Gudmundsson, L., Do, H. X., Leonard, M. & Westra, S. The Global Streamflow Indices and Metadata Archive (GSIM)-Part 2: Quality control, time-series indices and homogeneity assessment. Earth Syst Sci Data 10, 787–804 (2018).\n",
    "\n",
    "## Observations\n",
    "* Here we compute the streamflow indices well-discussed and computed in the GSIM papers (Gudmundsson et al., 2018; Do et al., 2018). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7648ab",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f6e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from utils.streamflowindices import *\n",
    "from utils.general import calculate_areas_when_0, calculate_specific_discharge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a0050",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec3eb41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variables:\n",
    "# Relative path to your local directory\n",
    "PATH = \"../../..\"\n",
    "# Set some constraints for minimum number of daily measurments at each time-resolution:\n",
    "THRESHOLD_YR = 360 \n",
    "THRESHOLD_MO = 25\n",
    "THRESHOLD_WE = 7\n",
    "THRESHOLD_SE = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c1c1e",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d25b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-editable variables:\n",
    "PATH_YR = \"results/timeseries/streamflowindices/yearly/\"\n",
    "PATH_MO = \"results/timeseries/streamflowindices/monthly/\"\n",
    "PATH_WE = \"results/timeseries/streamflowindices/weekly/\"\n",
    "PATH_SE = \"results/timeseries/streamflowindices/seasonally/\"\n",
    "\n",
    "# Set the directory:\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54907f",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea546d0",
   "metadata": {},
   "source": [
    "## Daily specific discharge time series\n",
    "It is important to note that this time series was already filtered under a quality-check to delete negative values. The data is in milimeters per day (mm/day).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb14bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_EU = pd.read_csv(\"data/streamflow/estreams_timeseries_streamflow.csv\", index_col=0)\n",
    "timeseries_EU.index = pd.to_datetime(timeseries_EU.index)\n",
    "timeseries_EU.index.name = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3c3ffc",
   "metadata": {},
   "source": [
    "## Streamflow gauges network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da333773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gauge_id</th>\n",
       "      <th>gauge_name</th>\n",
       "      <th>gauge_country</th>\n",
       "      <th>gauge_provider</th>\n",
       "      <th>river</th>\n",
       "      <th>lon_snap</th>\n",
       "      <th>lat_snap</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>area</th>\n",
       "      <th>...</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>num_years</th>\n",
       "      <th>num_months</th>\n",
       "      <th>num_days</th>\n",
       "      <th>num_days_gaps</th>\n",
       "      <th>num_continuous_days</th>\n",
       "      <th>duplicated_suspect</th>\n",
       "      <th>watershed_group</th>\n",
       "      <th>gauges_upstream</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basin_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AT000001</th>\n",
       "      <td>200014</td>\n",
       "      <td>Bangs</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT_EHYD</td>\n",
       "      <td>Rhein</td>\n",
       "      <td>9.534835</td>\n",
       "      <td>47.273748</td>\n",
       "      <td>9.534835</td>\n",
       "      <td>47.273748</td>\n",
       "      <td>4647.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>24</td>\n",
       "      <td>288</td>\n",
       "      <td>8766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8766</td>\n",
       "      <td>CH000197</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT000002</th>\n",
       "      <td>200048</td>\n",
       "      <td>Schruns (Vonbunweg)</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT_EHYD</td>\n",
       "      <td>Litz</td>\n",
       "      <td>9.913677</td>\n",
       "      <td>47.080301</td>\n",
       "      <td>9.913677</td>\n",
       "      <td>47.080301</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1958-10-01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>62</td>\n",
       "      <td>735</td>\n",
       "      <td>22372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22372</td>\n",
       "      <td>CH000221</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT000003</th>\n",
       "      <td>231662</td>\n",
       "      <td>Loruens-Aeule</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT_EHYD</td>\n",
       "      <td>Ill</td>\n",
       "      <td>9.847765</td>\n",
       "      <td>47.132821</td>\n",
       "      <td>9.847765</td>\n",
       "      <td>47.132821</td>\n",
       "      <td>535.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1985-01-02</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>35</td>\n",
       "      <td>420</td>\n",
       "      <td>12782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12782</td>\n",
       "      <td>CH000215</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT000004</th>\n",
       "      <td>200592</td>\n",
       "      <td>Kloesterle (OEBB)</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT_EHYD</td>\n",
       "      <td>Alfenz</td>\n",
       "      <td>10.061843</td>\n",
       "      <td>47.128994</td>\n",
       "      <td>10.061843</td>\n",
       "      <td>47.128994</td>\n",
       "      <td>66.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1998-01-02</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>22</td>\n",
       "      <td>264</td>\n",
       "      <td>8034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8034</td>\n",
       "      <td>CH000227</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT000005</th>\n",
       "      <td>200097</td>\n",
       "      <td>Buers (Bruecke L82)</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT_EHYD</td>\n",
       "      <td>Alvier</td>\n",
       "      <td>9.802668</td>\n",
       "      <td>47.150770</td>\n",
       "      <td>9.802668</td>\n",
       "      <td>47.150770</td>\n",
       "      <td>72.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>30</td>\n",
       "      <td>360</td>\n",
       "      <td>10957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10957</td>\n",
       "      <td>CH000214</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAGR0017</th>\n",
       "      <td>6682300</td>\n",
       "      <td>BASHTANOVKA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_GRDC</td>\n",
       "      <td>KACHA</td>\n",
       "      <td>33.894739</td>\n",
       "      <td>44.691884</td>\n",
       "      <td>33.900000</td>\n",
       "      <td>44.683333</td>\n",
       "      <td>321.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>1987-12-31</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAGR0018</th>\n",
       "      <td>6682500</td>\n",
       "      <td>YALTA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_GRDC</td>\n",
       "      <td>DERE-KIOY</td>\n",
       "      <td>34.166667</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>34.166667</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>49.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>1987-12-31</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAGR0019</th>\n",
       "      <td>6683010</td>\n",
       "      <td>PIONERSKOE</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_GRDC</td>\n",
       "      <td>SALHYR</td>\n",
       "      <td>34.199841</td>\n",
       "      <td>44.887685</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>44.883333</td>\n",
       "      <td>261.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>1987-12-31</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAGR0020</th>\n",
       "      <td>6683200</td>\n",
       "      <td>TOKMAK</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_GRDC</td>\n",
       "      <td>TOKMAK</td>\n",
       "      <td>35.705833</td>\n",
       "      <td>47.251389</td>\n",
       "      <td>35.705833</td>\n",
       "      <td>47.251389</td>\n",
       "      <td>760.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>1987-12-31</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAGR0021</th>\n",
       "      <td>6683300</td>\n",
       "      <td>NOVOSELOVKA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_GRDC</td>\n",
       "      <td>KRYNKA</td>\n",
       "      <td>38.144722</td>\n",
       "      <td>48.153333</td>\n",
       "      <td>38.144722</td>\n",
       "      <td>48.153333</td>\n",
       "      <td>582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>1987-12-31</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15047 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gauge_id           gauge_name gauge_country gauge_provider  \\\n",
       "basin_id                                                              \n",
       "AT000001   200014                Bangs            AT        AT_EHYD   \n",
       "AT000002   200048  Schruns (Vonbunweg)            AT        AT_EHYD   \n",
       "AT000003   231662        Loruens-Aeule            AT        AT_EHYD   \n",
       "AT000004   200592    Kloesterle (OEBB)            AT        AT_EHYD   \n",
       "AT000005   200097  Buers (Bruecke L82)            AT        AT_EHYD   \n",
       "...           ...                  ...           ...            ...   \n",
       "UAGR0017  6682300          BASHTANOVKA            UA        UA_GRDC   \n",
       "UAGR0018  6682500                YALTA            UA        UA_GRDC   \n",
       "UAGR0019  6683010           PIONERSKOE            UA        UA_GRDC   \n",
       "UAGR0020  6683200               TOKMAK            UA        UA_GRDC   \n",
       "UAGR0021  6683300          NOVOSELOVKA            UA        UA_GRDC   \n",
       "\n",
       "              river   lon_snap   lat_snap        lon        lat    area  ...  \\\n",
       "basin_id                                                                 ...   \n",
       "AT000001      Rhein   9.534835  47.273748   9.534835  47.273748  4647.9  ...   \n",
       "AT000002       Litz   9.913677  47.080301   9.913677  47.080301   102.0  ...   \n",
       "AT000003        Ill   9.847765  47.132821   9.847765  47.132821   535.2  ...   \n",
       "AT000004     Alfenz  10.061843  47.128994  10.061843  47.128994    66.6  ...   \n",
       "AT000005     Alvier   9.802668  47.150770   9.802668  47.150770    72.2  ...   \n",
       "...             ...        ...        ...        ...        ...     ...  ...   \n",
       "UAGR0017      KACHA  33.894739  44.691884  33.900000  44.683333   321.0  ...   \n",
       "UAGR0018  DERE-KIOY  34.166667  44.500000  34.166667  44.500000    49.7  ...   \n",
       "UAGR0019     SALHYR  34.199841  44.887685  34.200000  44.883333   261.0  ...   \n",
       "UAGR0020     TOKMAK  35.705833  47.251389  35.705833  47.251389   760.0  ...   \n",
       "UAGR0021     KRYNKA  38.144722  48.153333  38.144722  48.153333   582.0  ...   \n",
       "\n",
       "         start_date   end_date  num_years  num_months num_days num_days_gaps  \\\n",
       "basin_id                                                                       \n",
       "AT000001 1996-01-01 2019-12-31         24         288     8766           0.0   \n",
       "AT000002 1958-10-01 2019-12-31         62         735    22372           0.0   \n",
       "AT000003 1985-01-02 2019-12-31         35         420    12782           0.0   \n",
       "AT000004 1998-01-02 2019-12-31         22         264     8034           0.0   \n",
       "AT000005 1990-01-01 2019-12-31         30         360    10957           0.0   \n",
       "...             ...        ...        ...         ...      ...           ...   \n",
       "UAGR0017 1978-01-01 1987-12-31         10         120     3652           0.0   \n",
       "UAGR0018 1978-01-01 1987-12-31         10         120     3652           0.0   \n",
       "UAGR0019 1978-01-01 1987-12-31         10         120     3652           0.0   \n",
       "UAGR0020 1978-01-01 1987-12-31         10         120     3652           0.0   \n",
       "UAGR0021 1978-01-01 1987-12-31         10         120     3652           0.0   \n",
       "\n",
       "          num_continuous_days  duplicated_suspect  watershed_group  \\\n",
       "basin_id                                                             \n",
       "AT000001                 8766            CH000197                1   \n",
       "AT000002                22372            CH000221                1   \n",
       "AT000003                12782            CH000215                1   \n",
       "AT000004                 8034            CH000227                1   \n",
       "AT000005                10957            CH000214                1   \n",
       "...                       ...                 ...              ...   \n",
       "UAGR0017                 3652                 NaN             1916   \n",
       "UAGR0018                 3652                 NaN             1917   \n",
       "UAGR0019                 3652                 NaN             1918   \n",
       "UAGR0020                 3652                 NaN             1919   \n",
       "UAGR0021                 3652                 NaN             1920   \n",
       "\n",
       "          gauges_upstream  \n",
       "basin_id                   \n",
       "AT000001               13  \n",
       "AT000002                0  \n",
       "AT000003                1  \n",
       "AT000004                0  \n",
       "AT000005                0  \n",
       "...                   ...  \n",
       "UAGR0017                0  \n",
       "UAGR0018                0  \n",
       "UAGR0019                0  \n",
       "UAGR0020                0  \n",
       "UAGR0021                0  \n",
       "\n",
       "[15047 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_estreams = pd.read_csv('data/streamflow/estreams_gauging_stations.csv', encoding='utf-8')\n",
    "network_estreams.set_index(\"basin_id\", inplace = True)\n",
    "network_estreams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c07b27",
   "metadata": {},
   "source": [
    "## Catchment boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f8e1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gauge_id</th>\n",
       "      <th>gauge_coun</th>\n",
       "      <th>area</th>\n",
       "      <th>area_calc</th>\n",
       "      <th>area_flag</th>\n",
       "      <th>area_perc</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>gauge_hier</th>\n",
       "      <th>watershed_</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basin_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AT000001</th>\n",
       "      <td>200014</td>\n",
       "      <td>AT</td>\n",
       "      <td>4647.9</td>\n",
       "      <td>4668.379</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.440608</td>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((9.69406 46.54322 0.00000, 9.69570 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT000002</th>\n",
       "      <td>200048</td>\n",
       "      <td>AT</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.287</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.281373</td>\n",
       "      <td>1958-10-01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((10.13650 47.02949 0.00000, 10.1349...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT000003</th>\n",
       "      <td>231662</td>\n",
       "      <td>AT</td>\n",
       "      <td>535.2</td>\n",
       "      <td>536.299</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.205344</td>\n",
       "      <td>1985-01-02</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((10.11095 46.89437 0.00000, 10.1122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT000004</th>\n",
       "      <td>200592</td>\n",
       "      <td>AT</td>\n",
       "      <td>66.6</td>\n",
       "      <td>66.286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471471</td>\n",
       "      <td>1998-01-02</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((10.14189 47.09706 0.00000, 10.1404...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT000005</th>\n",
       "      <td>200097</td>\n",
       "      <td>AT</td>\n",
       "      <td>72.2</td>\n",
       "      <td>72.448</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.343490</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((9.67851 47.06249 0.00000, 9.67888 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gauge_id gauge_coun    area  area_calc  area_flag  area_perc  \\\n",
       "basin_id                                                                \n",
       "AT000001   200014         AT  4647.9   4668.379          0  -0.440608   \n",
       "AT000002   200048         AT   102.0    102.287          0  -0.281373   \n",
       "AT000003   231662         AT   535.2    536.299          0  -0.205344   \n",
       "AT000004   200592         AT    66.6     66.286          0   0.471471   \n",
       "AT000005   200097         AT    72.2     72.448          0  -0.343490   \n",
       "\n",
       "          start_date    end_date  gauge_hier  watershed_  \\\n",
       "basin_id                                                   \n",
       "AT000001  1996-01-01  2019-12-31          14           1   \n",
       "AT000002  1958-10-01  2019-12-31           1           1   \n",
       "AT000003  1985-01-02  2019-12-31           2           1   \n",
       "AT000004  1998-01-02  2019-12-31           1           1   \n",
       "AT000005  1990-01-01  2019-12-31           1           1   \n",
       "\n",
       "                                                   geometry  \n",
       "basin_id                                                     \n",
       "AT000001  POLYGON Z ((9.69406 46.54322 0.00000, 9.69570 ...  \n",
       "AT000002  POLYGON Z ((10.13650 47.02949 0.00000, 10.1349...  \n",
       "AT000003  POLYGON Z ((10.11095 46.89437 0.00000, 10.1122...  \n",
       "AT000004  POLYGON Z ((10.14189 47.09706 0.00000, 10.1404...  \n",
       "AT000005  POLYGON Z ((9.67851 47.06249 0.00000, 9.67888 ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catchment_boundaries = gpd.read_file('data/shapefiles/estreams_catchments.shp')\n",
    "catchment_boundaries.set_index(\"basin_id\", inplace = True)\n",
    "catchment_boundaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b17eb94",
   "metadata": {},
   "source": [
    "# Computation processing\n",
    "## Pre-processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d611e6f",
   "metadata": {},
   "source": [
    "### Specific discharge computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727353f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gauge_id</th>\n",
       "      <th>gauge_name</th>\n",
       "      <th>gauge_country</th>\n",
       "      <th>gauge_provider</th>\n",
       "      <th>river</th>\n",
       "      <th>lon_snap</th>\n",
       "      <th>lat_snap</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>area</th>\n",
       "      <th>...</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>num_years</th>\n",
       "      <th>num_months</th>\n",
       "      <th>num_days</th>\n",
       "      <th>num_days_gaps</th>\n",
       "      <th>num_continuous_days</th>\n",
       "      <th>duplicated_suspect</th>\n",
       "      <th>watershed_group</th>\n",
       "      <th>gauges_upstream</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basin_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AT000001</th>\n",
       "      <td>200014</td>\n",
       "      <td>Bangs</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT_EHYD</td>\n",
       "      <td>Rhein</td>\n",
       "      <td>9.534835</td>\n",
       "      <td>47.273748</td>\n",
       "      <td>9.534835</td>\n",
       "      <td>47.273748</td>\n",
       "      <td>4647.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>24</td>\n",
       "      <td>288</td>\n",
       "      <td>8766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8766</td>\n",
       "      <td>CH000197</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT000002</th>\n",
       "      <td>200048</td>\n",
       "      <td>Schruns (Vonbunweg)</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT_EHYD</td>\n",
       "      <td>Litz</td>\n",
       "      <td>9.913677</td>\n",
       "      <td>47.080301</td>\n",
       "      <td>9.913677</td>\n",
       "      <td>47.080301</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1958-10-01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>62</td>\n",
       "      <td>735</td>\n",
       "      <td>22372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22372</td>\n",
       "      <td>CH000221</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT000003</th>\n",
       "      <td>231662</td>\n",
       "      <td>Loruens-Aeule</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT_EHYD</td>\n",
       "      <td>Ill</td>\n",
       "      <td>9.847765</td>\n",
       "      <td>47.132821</td>\n",
       "      <td>9.847765</td>\n",
       "      <td>47.132821</td>\n",
       "      <td>535.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1985-01-02</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>35</td>\n",
       "      <td>420</td>\n",
       "      <td>12782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12782</td>\n",
       "      <td>CH000215</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT000004</th>\n",
       "      <td>200592</td>\n",
       "      <td>Kloesterle (OEBB)</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT_EHYD</td>\n",
       "      <td>Alfenz</td>\n",
       "      <td>10.061843</td>\n",
       "      <td>47.128994</td>\n",
       "      <td>10.061843</td>\n",
       "      <td>47.128994</td>\n",
       "      <td>66.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1998-01-02</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>22</td>\n",
       "      <td>264</td>\n",
       "      <td>8034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8034</td>\n",
       "      <td>CH000227</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT000005</th>\n",
       "      <td>200097</td>\n",
       "      <td>Buers (Bruecke L82)</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT_EHYD</td>\n",
       "      <td>Alvier</td>\n",
       "      <td>9.802668</td>\n",
       "      <td>47.150770</td>\n",
       "      <td>9.802668</td>\n",
       "      <td>47.150770</td>\n",
       "      <td>72.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>30</td>\n",
       "      <td>360</td>\n",
       "      <td>10957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10957</td>\n",
       "      <td>CH000214</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAGR0017</th>\n",
       "      <td>6682300</td>\n",
       "      <td>BASHTANOVKA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_GRDC</td>\n",
       "      <td>KACHA</td>\n",
       "      <td>33.894739</td>\n",
       "      <td>44.691884</td>\n",
       "      <td>33.900000</td>\n",
       "      <td>44.683333</td>\n",
       "      <td>321.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>1987-12-31</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAGR0018</th>\n",
       "      <td>6682500</td>\n",
       "      <td>YALTA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_GRDC</td>\n",
       "      <td>DERE-KIOY</td>\n",
       "      <td>34.166667</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>34.166667</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>49.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>1987-12-31</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAGR0019</th>\n",
       "      <td>6683010</td>\n",
       "      <td>PIONERSKOE</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_GRDC</td>\n",
       "      <td>SALHYR</td>\n",
       "      <td>34.199841</td>\n",
       "      <td>44.887685</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>44.883333</td>\n",
       "      <td>261.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>1987-12-31</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAGR0020</th>\n",
       "      <td>6683200</td>\n",
       "      <td>TOKMAK</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_GRDC</td>\n",
       "      <td>TOKMAK</td>\n",
       "      <td>35.705833</td>\n",
       "      <td>47.251389</td>\n",
       "      <td>35.705833</td>\n",
       "      <td>47.251389</td>\n",
       "      <td>760.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>1987-12-31</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAGR0021</th>\n",
       "      <td>6683300</td>\n",
       "      <td>NOVOSELOVKA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA_GRDC</td>\n",
       "      <td>KRYNKA</td>\n",
       "      <td>38.144722</td>\n",
       "      <td>48.153333</td>\n",
       "      <td>38.144722</td>\n",
       "      <td>48.153333</td>\n",
       "      <td>582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>1987-12-31</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15047 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gauge_id           gauge_name gauge_country gauge_provider  \\\n",
       "basin_id                                                              \n",
       "AT000001   200014                Bangs            AT        AT_EHYD   \n",
       "AT000002   200048  Schruns (Vonbunweg)            AT        AT_EHYD   \n",
       "AT000003   231662        Loruens-Aeule            AT        AT_EHYD   \n",
       "AT000004   200592    Kloesterle (OEBB)            AT        AT_EHYD   \n",
       "AT000005   200097  Buers (Bruecke L82)            AT        AT_EHYD   \n",
       "...           ...                  ...           ...            ...   \n",
       "UAGR0017  6682300          BASHTANOVKA            UA        UA_GRDC   \n",
       "UAGR0018  6682500                YALTA            UA        UA_GRDC   \n",
       "UAGR0019  6683010           PIONERSKOE            UA        UA_GRDC   \n",
       "UAGR0020  6683200               TOKMAK            UA        UA_GRDC   \n",
       "UAGR0021  6683300          NOVOSELOVKA            UA        UA_GRDC   \n",
       "\n",
       "              river   lon_snap   lat_snap        lon        lat    area  ...  \\\n",
       "basin_id                                                                 ...   \n",
       "AT000001      Rhein   9.534835  47.273748   9.534835  47.273748  4647.9  ...   \n",
       "AT000002       Litz   9.913677  47.080301   9.913677  47.080301   102.0  ...   \n",
       "AT000003        Ill   9.847765  47.132821   9.847765  47.132821   535.2  ...   \n",
       "AT000004     Alfenz  10.061843  47.128994  10.061843  47.128994    66.6  ...   \n",
       "AT000005     Alvier   9.802668  47.150770   9.802668  47.150770    72.2  ...   \n",
       "...             ...        ...        ...        ...        ...     ...  ...   \n",
       "UAGR0017      KACHA  33.894739  44.691884  33.900000  44.683333   321.0  ...   \n",
       "UAGR0018  DERE-KIOY  34.166667  44.500000  34.166667  44.500000    49.7  ...   \n",
       "UAGR0019     SALHYR  34.199841  44.887685  34.200000  44.883333   261.0  ...   \n",
       "UAGR0020     TOKMAK  35.705833  47.251389  35.705833  47.251389   760.0  ...   \n",
       "UAGR0021     KRYNKA  38.144722  48.153333  38.144722  48.153333   582.0  ...   \n",
       "\n",
       "         start_date   end_date  num_years  num_months num_days num_days_gaps  \\\n",
       "basin_id                                                                       \n",
       "AT000001 1996-01-01 2019-12-31         24         288     8766           0.0   \n",
       "AT000002 1958-10-01 2019-12-31         62         735    22372           0.0   \n",
       "AT000003 1985-01-02 2019-12-31         35         420    12782           0.0   \n",
       "AT000004 1998-01-02 2019-12-31         22         264     8034           0.0   \n",
       "AT000005 1990-01-01 2019-12-31         30         360    10957           0.0   \n",
       "...             ...        ...        ...         ...      ...           ...   \n",
       "UAGR0017 1978-01-01 1987-12-31         10         120     3652           0.0   \n",
       "UAGR0018 1978-01-01 1987-12-31         10         120     3652           0.0   \n",
       "UAGR0019 1978-01-01 1987-12-31         10         120     3652           0.0   \n",
       "UAGR0020 1978-01-01 1987-12-31         10         120     3652           0.0   \n",
       "UAGR0021 1978-01-01 1987-12-31         10         120     3652           0.0   \n",
       "\n",
       "          num_continuous_days  duplicated_suspect  watershed_group  \\\n",
       "basin_id                                                             \n",
       "AT000001                 8766            CH000197                1   \n",
       "AT000002                22372            CH000221                1   \n",
       "AT000003                12782            CH000215                1   \n",
       "AT000004                 8034            CH000227                1   \n",
       "AT000005                10957            CH000214                1   \n",
       "...                       ...                 ...              ...   \n",
       "UAGR0017                 3652                 NaN             1916   \n",
       "UAGR0018                 3652                 NaN             1917   \n",
       "UAGR0019                 3652                 NaN             1918   \n",
       "UAGR0020                 3652                 NaN             1919   \n",
       "UAGR0021                 3652                 NaN             1920   \n",
       "\n",
       "          gauges_upstream  \n",
       "basin_id                   \n",
       "AT000001               13  \n",
       "AT000002                0  \n",
       "AT000003                1  \n",
       "AT000004                0  \n",
       "AT000005                0  \n",
       "...                   ...  \n",
       "UAGR0017                0  \n",
       "UAGR0018                0  \n",
       "UAGR0019                0  \n",
       "UAGR0020                0  \n",
       "UAGR0021                0  \n",
       "\n",
       "[15047 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust areas that might be zero: \n",
    "network_estreams = calculate_areas_when_0(network_estreams, catchment_boundaries)\n",
    "network_estreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b19c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific discharge computation\n",
    "timeseries_EU = calculate_specific_discharge(network_estreams, timeseries_EU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b33f950",
   "metadata": {},
   "source": [
    "## Other preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f9572dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to compute a mask with the data quality: 1 refers to NaNs and 0 to non-NaNs\n",
    "timeseries_EU_quality = (pd.isna(timeseries_EU)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee93961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use the calendar year, so the hydro_year starts in 1 January\n",
    "hydro_year = np.array(timeseries_EU_quality.index.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93652270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a 7-day backward-looking moving average\n",
    "timeseries_EU_smoothed = timeseries_EU.rolling(window=7, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34e2b9d",
   "metadata": {},
   "source": [
    "## Yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c7bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here all the operations are organized in the form of a \"pipeline\" for organization and progress visuatilization:\n",
    "\n",
    "# List of operations with names, functions, and simplified names for file export:\n",
    "operations = [\n",
    "    ('Mean', lambda x: np.mean(x) if x.count() >= THRESHOLD_YR else np.nan, 'mean'),\n",
    "    ('Standard Deviation', lambda x: np.std(x) if x.count() >= THRESHOLD_YR else np.nan, 'std'),\n",
    "    ('Coefficient of Variation', lambda x: np.var(x) if x.count() >= THRESHOLD_YR else np.nan, 'cv'),\n",
    "    ('Minimum', lambda x: np.min(x) if x.count() >= THRESHOLD_YR else np.nan, 'min'),\n",
    "    ('Maximum', lambda x: np.max(x) if x.count() >= THRESHOLD_YR else np.nan, 'max'),\n",
    "    ('IQR', lambda x: calculate_iqr(x, THRESHOLD_YR), 'iqr'),\n",
    "    ('Percentile 10', lambda x: np.percentile(x, 10) if x.count() >= THRESHOLD_YR else np.nan, 'p10'),\n",
    "    ('Percentile 20', lambda x: np.percentile(x, 20) if x.count() >= THRESHOLD_YR else np.nan, 'p20'),\n",
    "    ('Percentile 30', lambda x: np.percentile(x, 30) if x.count() >= THRESHOLD_YR else np.nan, 'p30'),\n",
    "    ('Percentile 40', lambda x: np.percentile(x, 40) if x.count() >= THRESHOLD_YR else np.nan, 'p40'),\n",
    "    ('Percentile 50', lambda x: np.percentile(x, 50) if x.count() >= THRESHOLD_YR else np.nan, 'p50'),\n",
    "    ('Percentile 60', lambda x: np.percentile(x, 60) if x.count() >= THRESHOLD_YR else np.nan, 'p60'),\n",
    "    ('Percentile 70', lambda x: np.percentile(x, 70) if x.count() >= THRESHOLD_YR else np.nan, 'p70'),\n",
    "    ('Percentile 80', lambda x: np.percentile(x, 80) if x.count() >= THRESHOLD_YR else np.nan, 'p80'),\n",
    "    ('Percentile 90', lambda x: np.percentile(x, 90) if x.count() >= THRESHOLD_YR else np.nan, 'p90'),\n",
    "    ('Minimum 7-days', lambda x: np.min(x) if x.count() >= THRESHOLD_YR else np.nan, 'min7days'),\n",
    "    ('Maximum 7-days', lambda x: np.max(x) if x.count() >= THRESHOLD_YR else np.nan, 'max7days'),\n",
    "    ('Center Timing', None, 'ct'),\n",
    "    ('DOY minimum', None, 'doymin'), \n",
    "    ('DOY maximum', None, 'doymax'),\n",
    "    ('DOY minimum 7-days', None, 'doy7min'), \n",
    "    ('DOY maximum 7-days', None, 'doy7max'), \n",
    "    ('Gini coefficient', None, 'gini')\n",
    "]\n",
    "\n",
    "# Dictionary to store the results of each operation\n",
    "results = {}\n",
    "\n",
    "# Iterate over operations to calculate metrics and export to CSV\n",
    "for op_name, op_func, op_file in tqdm.tqdm(operations, desc='Calculating Metrics'):\n",
    "    \n",
    "    if op_name == 'Minimum 7-days':\n",
    "        \n",
    "        # Calculate the metric using the resample method\n",
    "        results[op_name] = timeseries_EU_smoothed.resample('Y').agg(op_func)\n",
    "    \n",
    "    elif op_name == 'Maximum 7-days':\n",
    "        \n",
    "        # Calculate the metric using the resample method\n",
    "        results[op_name] = timeseries_EU_smoothed.resample('Y').agg(op_func)\n",
    "    \n",
    "    elif op_name == 'Center Timing':\n",
    "        \n",
    "        # Initialize an empty DataFrame to store count threshold results\n",
    "        center_timing_result = pd.DataFrame(index = timeseries_EU.index.year.unique(), \n",
    "                                            columns = timeseries_EU.columns)\n",
    "\n",
    "        # Iterate over gauges and calculate count thresholds\n",
    "        for gauge in timeseries_EU.columns:\n",
    "            center_timing_result[gauge] = calculate_ct(\n",
    "                streamflow=timeseries_EU.loc[:, gauge].values,\n",
    "                quality=timeseries_EU_quality.loc[:, gauge].values,\n",
    "                hydro_year=hydro_year\n",
    "            )\n",
    "        \n",
    "        results[op_name] = center_timing_result\n",
    "        \n",
    "    elif op_name == 'DOY minimum':\n",
    "        \n",
    "        # Initialize an empty DataFrame to store count threshold results\n",
    "        doy_min_result = pd.DataFrame(index = timeseries_EU.index.year.unique(), \n",
    "                                      columns = timeseries_EU.columns)\n",
    "\n",
    "        # Iterate over gauges and calculate count thresholds\n",
    "        for gauge in timeseries_EU.columns:\n",
    "            doy_min_result[gauge] = calculate_min_streamflow_day(\n",
    "                streamflow=timeseries_EU.loc[:, gauge].values,\n",
    "                quality=timeseries_EU_quality.loc[:, gauge].values,\n",
    "                hydro_year=hydro_year\n",
    "            )\n",
    "        \n",
    "        results[op_name] = doy_min_result\n",
    "        \n",
    "    elif op_name == 'DOY maximum':\n",
    "        \n",
    "        # Initialize an empty DataFrame to store count threshold results\n",
    "        doy_max_result = pd.DataFrame(index = timeseries_EU.index.year.unique(), \n",
    "                                      columns = timeseries_EU.columns)\n",
    "\n",
    "        # Iterate over gauges and calculate count thresholds\n",
    "        for gauge in timeseries_EU.columns:\n",
    "            doy_max_result[gauge] = calculate_max_streamflow_day(\n",
    "                streamflow=timeseries_EU.loc[:, gauge].values,\n",
    "                quality=timeseries_EU_quality.loc[:, gauge].values,\n",
    "                hydro_year=hydro_year\n",
    "            )\n",
    "        \n",
    "        results[op_name] = doy_max_result\n",
    "        \n",
    "    elif op_name == 'DOY minimum 7-days':\n",
    "        \n",
    "        # Initialize an empty DataFrame to store count threshold results\n",
    "        doy_7min_result = pd.DataFrame(index = timeseries_EU_smoothed.index.year.unique(), \n",
    "                                      columns = timeseries_EU_smoothed.columns)\n",
    "\n",
    "        # Iterate over gauges and calculate count thresholds\n",
    "        for gauge in timeseries_EU_smoothed.columns:\n",
    "            doy_7min_result[gauge] = calculate_min_streamflow_day(\n",
    "                streamflow=timeseries_EU_smoothed.loc[:, gauge].values,\n",
    "                quality=timeseries_EU_quality.loc[:, gauge].values,\n",
    "                hydro_year=hydro_year\n",
    "            )\n",
    "        \n",
    "        results[op_name] = doy_7min_result\n",
    "        \n",
    "    elif op_name == 'DOY maximum 7-days':\n",
    "        \n",
    "        # Initialize an empty DataFrame to store count threshold results\n",
    "        doy_7max_result = pd.DataFrame(index = timeseries_EU_smoothed.index.year.unique(), \n",
    "                                      columns = timeseries_EU_smoothed.columns)\n",
    "\n",
    "        # Iterate over gauges and calculate count thresholds\n",
    "        for gauge in timeseries_EU_smoothed.columns:\n",
    "            doy_7max_result[gauge] = calculate_max_streamflow_day(\n",
    "                streamflow=timeseries_EU_smoothed.loc[:, gauge].values,\n",
    "                quality=timeseries_EU_quality.loc[:, gauge].values,\n",
    "                hydro_year=hydro_year\n",
    "            )\n",
    "        \n",
    "        results[op_name] = doy_7max_result\n",
    "    \n",
    "    elif op_name == 'Gini coefficient':\n",
    "        \n",
    "        # Initialize an empty DataFrame to store count threshold results\n",
    "        gini_result = pd.DataFrame(index = timeseries_EU.index.year.unique(), \n",
    "                                   columns = timeseries_EU.columns)\n",
    "\n",
    "        # Iterate over gauges and calculate count thresholds\n",
    "        for gauge in timeseries_EU.columns:\n",
    "            gini_result[gauge] = calculate_gini_coefficient(\n",
    "                streamflow=timeseries_EU.loc[:, gauge].values,\n",
    "                quality=timeseries_EU_quality.loc[:, gauge].values,\n",
    "                hydro_year=hydro_year\n",
    "            )\n",
    "        \n",
    "        results[op_name] = gini_result\n",
    "        \n",
    "    else:\n",
    "        # Calculate the metric using the resample method\n",
    "        results[op_name] = timeseries_EU.resample('Y').agg(op_func)\n",
    "        \n",
    "    \n",
    "    # Access results as needed\n",
    "    current_result = results[op_name]\n",
    "\n",
    "    # Export to CSV-file\n",
    "    file_name = f\"yearly_streamflow_{op_file}.csv\"\n",
    "    file_path = os.path.join(PATH_YR, file_name)\n",
    "    current_result = current_result.sort_index(axis=1) # Here we sort the columns\n",
    "    current_result.to_csv(file_path)\n",
    "\n",
    "# Access results as needed\n",
    "streamflow_yr_ave = results['Mean']\n",
    "streamflow_yr_std = results['Standard Deviation']\n",
    "streamflow_yr_cv = results['Coefficient of Variation']\n",
    "streamflow_yr_min = results['Minimum']\n",
    "streamflow_yr_max = results['Maximum']\n",
    "streamflow_yr_iqr = results['IQR']\n",
    "streamflow_yr_p10 = results['Percentile 10']\n",
    "streamflow_yr_p20 = results['Percentile 20']\n",
    "streamflow_yr_p30 = results['Percentile 30']\n",
    "streamflow_yr_p40 = results['Percentile 40']\n",
    "streamflow_yr_p50 = results['Percentile 50']\n",
    "streamflow_yr_p60 = results['Percentile 60']\n",
    "streamflow_yr_p70 = results['Percentile 70']\n",
    "streamflow_yr_p80 = results['Percentile 80']\n",
    "streamflow_yr_p90 = results['Percentile 90']\n",
    "streamflow_yr_ct = results['Center Timing']\n",
    "streamflow_yr_doymin = results['DOY minimum']\n",
    "streamflow_yr_doymax = results['DOY maximum']\n",
    "streamflow_yr_doy7min = results['DOY minimum 7-days']\n",
    "streamflow_yr_doy7max = results['DOY maximum 7-days']\n",
    "streamflow_yr_gini = results['Gini coefficient']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25086a1",
   "metadata": {},
   "source": [
    "## Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here all the operations are organized in the form of a \"pipeline\" for organization and progress visuatilization:\n",
    "\n",
    "# List of operations with names, functions, and simplified names for file export:\n",
    "operations = [\n",
    "    ('Mean', lambda x: np.mean(x) if x.count() >= THRESHOLD_MO else np.nan, 'mean'),\n",
    "    ('Standard Deviation', lambda x: np.std(x) if x.count() >= THRESHOLD_MO else np.nan, 'std'),\n",
    "    ('Coefficient of Variation', lambda x: np.var(x) if x.count() >= THRESHOLD_MO else np.nan, 'cv'),\n",
    "    ('Minimum', lambda x: np.min(x) if x.count() >= THRESHOLD_MO else np.nan, 'min'),\n",
    "    ('Maximum', lambda x: np.max(x) if x.count() >= THRESHOLD_MO else np.nan, 'max'),\n",
    "    ('Minimum 7-days', lambda x: np.min(x) if x.count() >= THRESHOLD_MO else np.nan, 'min7days'),\n",
    "    ('Maximum 7-days', lambda x: np.max(x) if x.count() >= THRESHOLD_MO else np.nan, 'max7days'),\n",
    "    ('IQR', lambda x: calculate_iqr(x, THRESHOLD_MO), 'iqr')\n",
    "]\n",
    "\n",
    "# Dictionary to store the results of each operation\n",
    "results = {}\n",
    "\n",
    "# Iterate over operations to calculate metrics and export to CSV\n",
    "for op_name, op_func, op_file in tqdm.tqdm(operations, desc='Calculating Metrics'):\n",
    "    \n",
    "    if op_name == 'Minimum 7-days':\n",
    "        \n",
    "        # Calculate the metric using the resample method\n",
    "        results[op_name] = timeseries_EU_smoothed.resample('M').agg(op_func)\n",
    "    \n",
    "    elif op_name == 'Maximum 7-days':\n",
    "        \n",
    "        # Calculate the metric using the resample method\n",
    "        results[op_name] = timeseries_EU_smoothed.resample('M').agg(op_func)  \n",
    "    \n",
    "    else:\n",
    "            \n",
    "        # Calculate the metric using the resample method\n",
    "        results[op_name] = timeseries_EU.resample('M').agg(op_func)\n",
    "    \n",
    "    # Access results as needed\n",
    "    current_result = results[op_name]\n",
    "\n",
    "    # Export to CSV-file\n",
    "    file_name = f\"monthly_streamflow_{op_file}.csv\"\n",
    "    file_path = os.path.join(PATH_MO, file_name)\n",
    "    current_result = current_result.sort_index(axis=1) # Here we sort the columns\n",
    "    current_result.to_csv(file_path)\n",
    "    \n",
    "# Access results as needed\n",
    "streamflow_mo_ave = results['Mean']\n",
    "streamflow_mo_std = results['Standard Deviation']\n",
    "streamflow_mo_cv = results['Coefficient of Variation']\n",
    "streamflow_mo_min = results['Minimum']\n",
    "streamflow_mo_max = results['Maximum']\n",
    "streamflow_mo_min7days = results['Minimum 7-days']\n",
    "streamflow_mo_max7days = results['Maximum 7-days']\n",
    "streamflow_mo_iqr = results['IQR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe884e",
   "metadata": {},
   "source": [
    "## Seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here all the operations are organized in the form of a \"pipeline\" for organization and progress visuatilization:\n",
    "\n",
    "# List of operations with names, functions, and simplified names for file export:\n",
    "operations = [\n",
    "    ('Mean', lambda x: np.mean(x) if x.count() >= THRESHOLD_SE else np.nan, 'mean'),\n",
    "    ('Standard Deviation', lambda x: np.std(x) if x.count() >= THRESHOLD_SE else np.nan, 'std'),\n",
    "    ('Coefficient of Variation', lambda x: np.var(x) if x.count() >= THRESHOLD_SE else np.nan, 'cv'),\n",
    "    ('Minimum', lambda x: np.min(x) if x.count() >= THRESHOLD_SE else np.nan, 'min'),\n",
    "    ('Maximum', lambda x: np.max(x) if x.count() >= THRESHOLD_SE else np.nan, 'max'),\n",
    "    ('IQR', lambda x: calculate_iqr(x, THRESHOLD_SE), 'iqr'),\n",
    "    ('Percentile 10', lambda x: np.percentile(x, 10) if x.count() >= THRESHOLD_SE else np.nan, 'p10'),\n",
    "    ('Percentile 20', lambda x: np.percentile(x, 20) if x.count() >= THRESHOLD_SE else np.nan, 'p20'),\n",
    "    ('Percentile 30', lambda x: np.percentile(x, 30) if x.count() >= THRESHOLD_SE else np.nan, 'p30'),\n",
    "    ('Percentile 40', lambda x: np.percentile(x, 40) if x.count() >= THRESHOLD_SE else np.nan, 'p40'),\n",
    "    ('Percentile 50', lambda x: np.percentile(x, 50) if x.count() >= THRESHOLD_SE else np.nan, 'p50'),\n",
    "    ('Percentile 60', lambda x: np.percentile(x, 60) if x.count() >= THRESHOLD_SE else np.nan, 'p60'),\n",
    "    ('Percentile 70', lambda x: np.percentile(x, 70) if x.count() >= THRESHOLD_SE else np.nan, 'p70'),\n",
    "    ('Percentile 80', lambda x: np.percentile(x, 80) if x.count() >= THRESHOLD_SE else np.nan, 'p80'),\n",
    "    ('Percentile 90', lambda x: np.percentile(x, 90) if x.count() >= THRESHOLD_SE else np.nan, 'p90'),\n",
    "    ('Minimum 7-days', lambda x: np.min(x) if x.count() >= THRESHOLD_SE else np.nan, 'min7days'),\n",
    "    ('Maximum 7-days', lambda x: np.max(x) if x.count() >= THRESHOLD_SE else np.nan, 'max7days')]\n",
    "\n",
    "# Dictionary to store the results of each operation\n",
    "results = {}\n",
    "\n",
    "# Iterate over operations to calculate metrics and export to CSV\n",
    "for op_name, op_func, op_file in tqdm.tqdm(operations, desc='Calculating Metrics'):\n",
    "    \n",
    "    if op_name == 'Minimum 7-days':\n",
    "        \n",
    "        # Calculate the metric using the resample method\n",
    "        results[op_name] = timeseries_EU_smoothed.resample('QS-MAR').agg(op_func)\n",
    "    \n",
    "    elif op_name == 'Maximum 7-days':\n",
    "        \n",
    "        # Calculate the metric using the resample method\n",
    "        results[op_name] = timeseries_EU_smoothed.resample('QS-MAR').agg(op_func)\n",
    "        \n",
    "    else:\n",
    "        # Calculate the metric using the resample method\n",
    "        results[op_name] = timeseries_EU.resample('QS-MAR').agg(op_func)\n",
    "        \n",
    "    \n",
    "    # Access results as needed\n",
    "    current_result = results[op_name]\n",
    "    \n",
    "    # Delete the first row (1899)\n",
    "    current_result = current_result.iloc[1:, :]\n",
    "    \n",
    "    # Export to CSV-file\n",
    "    file_name = f\"seasonally_streamflow_{op_file}.csv\"\n",
    "    file_path = os.path.join(PATH_SE, file_name)\n",
    "    current_result = current_result.sort_index(axis=1) # Here we sort the columns\n",
    "    current_result.to_csv(file_path)\n",
    "\n",
    "# Access results as needed\n",
    "streamflow_se_ave = results['Mean']\n",
    "streamflow_se_std = results['Standard Deviation']\n",
    "streamflow_se_cv = results['Coefficient of Variation']\n",
    "streamflow_se_min = results['Minimum']\n",
    "streamflow_se_max = results['Maximum']\n",
    "streamflow_se_iqr = results['IQR']\n",
    "streamflow_se_p10 = results['Percentile 10']\n",
    "streamflow_se_p20 = results['Percentile 20']\n",
    "streamflow_se_p30 = results['Percentile 30']\n",
    "streamflow_se_p40 = results['Percentile 40']\n",
    "streamflow_se_p50 = results['Percentile 50']\n",
    "streamflow_se_p60 = results['Percentile 60']\n",
    "streamflow_se_p70 = results['Percentile 70']\n",
    "streamflow_se_p80 = results['Percentile 80']\n",
    "streamflow_se_p90 = results['Percentile 90']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f7d47f",
   "metadata": {},
   "source": [
    "## Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d93c2d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  83%|████████▎ | 5/6 [3:54:23<46:52, 2812.69s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Iterate over operations to calculate metrics and export to CSV\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m op_name, op_func, op_file \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(operations, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalculating Metrics\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Calculate the metric using the resample method\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     results[op_name] \u001b[38;5;241m=\u001b[39m \u001b[43mtimeseries_EU\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mW\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Access results as needed\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     current_result \u001b[38;5;241m=\u001b[39m results[op_name]\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/resample.py:341\u001b[0m, in \u001b[0;36mResampler.aggregate\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m     how \u001b[38;5;241m=\u001b[39m func\n\u001b[0;32m--> 341\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_groupby_and_aggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/resample.py:436\u001b[0m, in \u001b[0;36mResampler._groupby_and_aggregate\u001b[0;34m(self, how, *args, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(how):\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;66;03m# TODO: test_resample_apply_with_additional_args fails if we go\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;66;03m#  through the non-lambda path, not clear that it should.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: how(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 436\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     result \u001b[38;5;241m=\u001b[39m grouped\u001b[38;5;241m.\u001b[39maggregate(how, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/groupby/generic.py:1495\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m gba \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, [func], args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m{})\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1495\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mgba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/apply.py:178\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[1;32m    181\u001b[0m     f \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mget_cython_func(func)\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/apply.py:311\u001b[0m, in \u001b[0;36mApply.agg_list_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_list_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a list-like argument.\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_or_apply_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/apply.py:1351\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_list_like\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;66;03m# Only set as_index=True on groupby objects, not Window or Resample\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;66;03m# that inherit from this class.\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\n\u001b[1;32m   1349\u001b[0m     obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     keys, results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1352\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_list_like(keys, results)\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/apply.py:370\u001b[0m, in \u001b[0;36mApply.compute_list_like\u001b[0;34m(self, op_name, selected_obj, kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m colg \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_gotitem(col, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, subset\u001b[38;5;241m=\u001b[39mselected_obj\u001b[38;5;241m.\u001b[39miloc[:, index])\n\u001b[1;32m    365\u001b[0m args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    366\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs]\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m include_axis(op_name, colg)\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    369\u001b[0m )\n\u001b[0;32m--> 370\u001b[0m new_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(new_res)\n\u001b[1;32m    372\u001b[0m indices\u001b[38;5;241m.\u001b[39mappend(index)\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/groupby/generic.py:255\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine\n\u001b[1;32m    254\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[0;32m--> 255\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_multiple_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/groupby/generic.py:360\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[1;32m    359\u001b[0m         key \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mOutputKey(label\u001b[38;5;241m=\u001b[39mname, position\u001b[38;5;241m=\u001b[39midx)\n\u001b[0;32m--> 360\u001b[0m         results[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/groupby/generic.py:292\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_agg_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_named(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/groupby/generic.py:325\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    324\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n\u001b[0;32m--> 325\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m res \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_constructor(result, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/groupby/ops.py:850\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 850\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/groupby/ops.py:871\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    868\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_splitter(obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[0;32m--> 871\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/groupby/generic.py:322\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    320\u001b[0m     alias \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39m_builtin_table_alias[func]\n\u001b[1;32m    321\u001b[0m     warn_alias_replacement(\u001b[38;5;28mself\u001b[39m, orig_func, alias)\n\u001b[0;32m--> 322\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n\u001b[1;32m    325\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39magg_series(obj, f)\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/resample.py:435\u001b[0m, in \u001b[0;36mResampler._groupby_and_aggregate.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(how):\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;66;03m# TODO: test_resample_apply_with_additional_args fails if we go\u001b[39;00m\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;66;03m#  through the non-lambda path, not clear that it should.\u001b[39;00m\n\u001b[0;32m--> 435\u001b[0m         func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mhow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m         result \u001b[38;5;241m=\u001b[39m grouped\u001b[38;5;241m.\u001b[39maggregate(func)\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Here all the operations are organized in the form of a \"pipeline\" for organization and progress visuatilization:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# List of operations with names, functions, and simplified names for file export:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m operations \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mmean(x) \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcount() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m THRESHOLD_WE \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStandard Deviation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mstd(x) \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcount() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m THRESHOLD_WE \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCoefficient of Variation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mvar(x) \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcount() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m THRESHOLD_WE \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      8\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimum\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mmin(x) \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcount() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m THRESHOLD_WE \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      9\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaximum\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mmax(x) \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcount() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m THRESHOLD_WE \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m---> 10\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIQR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcalculate_iqr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTHRESHOLD_WE\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miqr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m ]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Dictionary to store the results of each operation\u001b[39;00m\n\u001b[1;32m     14\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/PhD/Eawag/Papers/Paper1_Database/GitHub/EStreams_original/EStreams_original/code/python/signatures_and_indices/utils/streamflowindices.py:230\u001b[0m, in \u001b[0;36mcalculate_iqr\u001b[0;34m(x, threshold)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_iqr\u001b[39m(x, threshold):\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m    Calculate the Interquartile Range (IQR) for a given array, if the number of non-nan values is above a specified threshold.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m        Interquartile Range (IQR) if the number of non-nan values is above the threshold, otherwise np.nan.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mpercentile(x\u001b[38;5;241m.\u001b[39mdropna(), \u001b[38;5;241m75\u001b[39m) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(x\u001b[38;5;241m.\u001b[39mdropna(), \u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/series.py:5604\u001b[0m, in \u001b[0;36mSeries.dropna\u001b[0;34m(self, axis, inplace, how, ignore_index)\u001b[0m\n\u001b[1;32m   5601\u001b[0m \u001b[38;5;66;03m# Validate the axis parameter\u001b[39;00m\n\u001b[1;32m   5602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m-> 5604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_can_hold_na\u001b[49m:\n\u001b[1;32m   5605\u001b[0m     result \u001b[38;5;241m=\u001b[39m remove_na_arraylike(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   5606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/series.py:623\u001b[0m, in \u001b[0;36mSeries._can_hold_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_can_hold_na\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_can_hold_na\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/internals/managers.py:1975\u001b[0m, in \u001b[0;36mSingleBlockManager._can_hold_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1973\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1974\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_can_hold_na\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m-> 1975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_block\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_can_hold_na\u001b[49m\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/estreams/lib/python3.9/site-packages/pandas/core/internals/blocks.py:209\u001b[0m, in \u001b[0;36mBlock._can_hold_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_can_hold_na\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    206\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    Can we store NA values in this Block?\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miub\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Here all the operations are organized in the form of a \"pipeline\" for organization and progress visuatilization:\n",
    "\n",
    "# List of operations with names, functions, and simplified names for file export:\n",
    "operations = [\n",
    "    ('Mean', lambda x: np.mean(x) if x.count() >= THRESHOLD_WE else np.nan, 'mean'),\n",
    "    ('Standard Deviation', lambda x: np.std(x) if x.count() >= THRESHOLD_WE else np.nan, 'std'),\n",
    "    ('Coefficient of Variation', lambda x: np.var(x) if x.count() >= THRESHOLD_WE else np.nan, 'cv'),\n",
    "    ('Minimum', lambda x: np.min(x) if x.count() >= THRESHOLD_WE else np.nan, 'min'),\n",
    "    ('Maximum', lambda x: np.max(x) if x.count() >= THRESHOLD_WE else np.nan, 'max'),\n",
    "    ('IQR', lambda x: calculate_iqr(x, THRESHOLD_WE), 'iqr')\n",
    "]\n",
    "\n",
    "# Dictionary to store the results of each operation\n",
    "results = {}\n",
    "\n",
    "# Iterate over operations to calculate metrics and export to CSV\n",
    "for op_name, op_func, op_file in tqdm.tqdm(operations, desc='Calculating Metrics'):\n",
    "\n",
    "    # Calculate the metric using the resample method\n",
    "    results[op_name] = timeseries_EU.resample('W').agg(op_func)\n",
    "    \n",
    "    # Access results as needed\n",
    "    current_result = results[op_name]\n",
    "\n",
    "    # Export to CSV-file\n",
    "    file_name = f\"weekly_streamflow_{op_file}.csv\"\n",
    "    file_path = os.path.join(PATH_WE, file_name)\n",
    "    current_result = current_result.sort_index(axis=1) # Here we sort the columns\n",
    "    current_result.to_csv(file_path)\n",
    "\n",
    "# Access results as needed\n",
    "streamflow_we_ave = results['Mean']\n",
    "streamflow_we_std = results['Standard Deviation']\n",
    "streamflow_we_cv = results['Coefficient of Variation']\n",
    "streamflow_we_min = results['Minimum']\n",
    "streamflow_we_max = results['Maximum']\n",
    "streamflow_we_iqr = results['IQR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b608e26e",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
