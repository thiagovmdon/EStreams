{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e94d6f",
   "metadata": {},
   "source": [
    "# Hydro-meteorological signatures computation\n",
    "\n",
    "Author: Thiago Nascimento (thiago.nascimento@eawag.ch)\n",
    "\n",
    "This notebook is part of the EStreams publication and was used to the computation of the miscelaneous of hydro-meteorological signatures provided in this publication.\n",
    "\n",
    "* Note that this code enables not only the replicability of the current database but also the extrapolation to new catchment areas. \n",
    "* Additionally, the user should download and insert the original raw-data in the folder of the same name prior to run this code. \n",
    "* The original third-party data used were not made available in this repository due to redistribution and storage-space reasons.  \n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "\n",
    "* Python>=3.6\n",
    "* Jupyter\n",
    "* geopandas=0.10.2\n",
    "* hydroanalysis https://pypi.org/project/hydroanalysis/ (Last access: 30 December 2023)\n",
    "* numpy\n",
    "* os\n",
    "* pandas=2.1.3\n",
    "* scipy=1.9.0\n",
    "* tqdm\n",
    "\n",
    "Check the Github repository for an environment.yml (for conda environments) or requirements.txt (pip) file.\n",
    "\n",
    "**Files:**\n",
    "\n",
    "* data/streamflow/estreams_timeseries_discharge.csv\n",
    "* results/timeseries/meteorology/estreams_timeseries_precipitation.csv\n",
    "* results/timeseries/meteorology/estreams_timeseries_temperature.csv\n",
    "* results/timeseries/meteorology/estreams_timeseries_pet.csv\n",
    "* data/streamflow/estreams_gauging_stations.csv\n",
    "* data/shapefiles/estreams_catchments.shp\n",
    "\n",
    "**Directory:**\n",
    "\n",
    "* Clone the GitHub directory locally\n",
    "* Place any third-data variables in their respective directory.\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. \n",
    "\n",
    "\n",
    "## References\n",
    "* Addor, N., Newman, A. J., Mizukami, N., and Clark, M. P.: The CAMELS data set: catchment attributes and meteorology for large-sample studies, Hydrol. Earth Syst. Sci., 21, 5293-5313, https://doi.org/10.5194/hess-21-5293-2017, 2017.\n",
    "* https://github.com/naddor/camels/blob/master/clim/clim_indices.R\n",
    "\n",
    "## Observations\n",
    "* Here we compute the hydro-climatic signatures well-discussed and computed in the Camels-like publications and avaialable at the HydroAnalysis module, which is based on Addor et al. (2017)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7648ab",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "import os\n",
    "from utils.streamflowindices import calculate_hydro_year\n",
    "from utils.general import count_num_measurements, find_first_non_nan_dates, find_last_non_nan_dates, calculate_areas_when_0, calculate_specific_discharge\n",
    "import warnings\n",
    "import hydroanalysis #Make sure to have this module locally installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a0050",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3eb41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variables:\n",
    "# Relative path to your local directory\n",
    "PATH = \"../../..\"\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c1c1e",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-editable variables:\n",
    "PATH_OUTPUT = \"results/staticattributes/\"\n",
    "\n",
    "# Set the directory:\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54907f",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea546d0",
   "metadata": {},
   "source": [
    "## Daily discharge\n",
    "It is important to note that this time series was already filtered under a quality-check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_discharge = pd.read_csv(\"data/streamflow/estreams_timeseries_streamflow.csv\", index_col=0)\n",
    "timeseries_discharge.index = pd.to_datetime(timeseries_discharge.index)\n",
    "timeseries_discharge.index.name = \"date\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a1b8a6",
   "metadata": {},
   "source": [
    "## Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d54d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_precipitation = pd.read_csv(\"results/timeseries/meteorology/estreams_meteorology_precipitation.csv\", index_col=0)\n",
    "timeseries_precipitation.index = pd.to_datetime(timeseries_precipitation.index)\n",
    "timeseries_precipitation.index.name = \"date\"\n",
    "timeseries_precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2887d3",
   "metadata": {},
   "source": [
    "## PET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9326f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_pet = pd.read_csv(\"results/timeseries/meteorology/estreams_meteorology_pet.csv\", index_col=0)\n",
    "timeseries_pet.index = pd.to_datetime(timeseries_pet.index)\n",
    "timeseries_pet.index.name = \"date\"\n",
    "timeseries_pet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef59395",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d0b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_temperature = pd.read_csv(\"results/timeseries/meteorology/estreams_meteorology_temperature.csv\", index_col=0)\n",
    "timeseries_temperature.index = pd.to_datetime(timeseries_temperature.index)\n",
    "timeseries_temperature.index.name = \"date\"\n",
    "timeseries_temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3c3ffc",
   "metadata": {},
   "source": [
    "## Streamflow gauges network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da333773",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_estreams = pd.read_csv('data/streamflow/estreams_gauging_stations.csv', encoding='utf-8')\n",
    "network_estreams.set_index(\"basin_id\", inplace = True)\n",
    "network_estreams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ca8f87",
   "metadata": {},
   "source": [
    "## Catchment boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f56e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_boundaries = gpd.read_file('data/shapefiles/estreams_catchments.shp')\n",
    "catchment_boundaries.set_index(\"basin_id\", inplace = True)\n",
    "catchment_boundaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The total number of catchments to be processed are:\", len(catchment_boundaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b17eb94",
   "metadata": {},
   "source": [
    "# Computation processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bac2ca6",
   "metadata": {},
   "source": [
    "## Computation of time specific discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a30207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust areas that might be zero: \n",
    "network_estreams = calculate_areas_when_0(network_estreams, catchment_boundaries)\n",
    "network_estreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific discharge computation\n",
    "timeseries_discharge = calculate_specific_discharge(network_estreams, timeseries_discharge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a8ae9",
   "metadata": {},
   "source": [
    "## Filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9572dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can filter only the gauges with non \"999\" or \"888\" values:\n",
    "network_estreams_filtered = network_estreams[network_estreams.area_flag < 888.0]\n",
    "network_estreams_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746abcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can filter only the gauges at least 1 year of consecutive measured days:\n",
    "network_estreams_filtered = network_estreams_filtered[network_estreams_filtered.num_continuous_days >= 365]\n",
    "network_estreams_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db12be29",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4834a7f",
   "metadata": {},
   "source": [
    "### Filter the time series\n",
    "* At this part we can filter the hydro-climatic time series to the filtered gauges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad905847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific discharge\n",
    "timeseries_discharge = timeseries_discharge.loc[:, network_estreams_filtered.index]\n",
    "\n",
    "# Precipitation\n",
    "timeseries_precipitation = timeseries_precipitation.loc[:, network_estreams_filtered.index]\n",
    "\n",
    "# Temperature\n",
    "timeseries_temperature = timeseries_temperature.loc[:, network_estreams_filtered.index]\n",
    "\n",
    "# Potential evapotranspiration\n",
    "timeseries_pet = timeseries_pet.loc[:, network_estreams_filtered.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59c0da1",
   "metadata": {},
   "source": [
    "### Subset the streamflow time series\n",
    "* Here we subset the streamflow time series to the same time-period of the meteorology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e1042",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_discharge = timeseries_discharge.loc[timeseries_precipitation.index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2560c3",
   "metadata": {},
   "source": [
    "### Compute quality masks\n",
    "* We need to compute a mask which will assin \"1\" to NaNs and \"0\" to good quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358650d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality-mask for joint specific discharge and precipitation (Hydrological signatures):  \n",
    "quality_discharge_precipitation = (pd.isna(timeseries_discharge) | pd.isna(timeseries_precipitation)).astype(int)\n",
    "\n",
    "# Quality-mask for joint precipitation, pet and temperature (Climatic signatures):\n",
    "quality_pet_precipitation_temperature = (pd.isna(timeseries_precipitation) | pd.isna(timeseries_pet) | pd.isna(timeseries_temperature)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c1060",
   "metadata": {},
   "source": [
    "### Calculate the hydrological years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc1d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_year = calculate_hydro_year(date=timeseries_discharge.index, first_month=10)\n",
    "hydro_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39145a21",
   "metadata": {},
   "source": [
    "### Adjust the precipitation elasticity function\n",
    "\n",
    "The function presents a small mistake in the hydroanalysis module and therefore needs to be updated.\n",
    "\n",
    "- Here we have a small turn around, where we corrected the function locally, replaced in the module, and applied here.\n",
    "\n",
    "- We have made a edition request to the GitHub page of the \"hydroanalysis\" creator, and as soon as they accept, we can simply import the updated function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a690ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below is only an small update of the original function from the module \"hydroanalysis\"\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import warnings\n",
    "import inspect\n",
    "from scipy import stats\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "def check_data(**kwargs):\n",
    "    \"\"\"\n",
    "    This function checks if all the input arguments:\n",
    "    - are 1D np.ndarray\n",
    "    - have the same shape\n",
    "    - there are data points with good quality code (0)\n",
    "    \"\"\"\n",
    "\n",
    "    for k in kwargs:\n",
    "        # Check if array\n",
    "        if not isinstance(kwargs[k], np.ndarray):\n",
    "            raise TypeError('{} is of type {}'.format(k, type(kwargs[k])))\n",
    "        # Check if shape\n",
    "        if len(kwargs[k].shape) != 1:\n",
    "            raise ValueError(\n",
    "                '{} must be 1D. Shape :  {}'.format(k, kwargs[k].shape))\n",
    "\n",
    "    for k1 in kwargs:\n",
    "        for k2 in kwargs:\n",
    "            if k1 == k2:\n",
    "                continue\n",
    "            if kwargs[k1].shape != kwargs[k2].shape:\n",
    "                raise ValueError('{} and {} have different shape: {}, {}'.format(k1,\n",
    "                                                                                 k2,\n",
    "                                                                                 kwargs[k1].shape,\n",
    "                                                                                 kwargs[k2].shape))\n",
    "\n",
    "    # Check if at least some data have good quality\n",
    "    good_quality_data = True\n",
    "\n",
    "    if 'quality' in kwargs:\n",
    "        if sum(kwargs['quality'] == 0) < 1:\n",
    "            good_quality_data = False\n",
    "            warnings.warn('Skipped because of no data')\n",
    "\n",
    "    return good_quality_data\n",
    "\n",
    "\n",
    "def calculate_p_seasonality(precipitation, quality, date, temperature):\n",
    "    \"\"\"\n",
    "    This function calculates the signature \"p_seasonality\".\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    precipitation : np.array\n",
    "        Array of precipitation measurements. It is assumed that it represent\n",
    "        daily data.\n",
    "    quality : np.array\n",
    "        Array containing the quality code for the precipitation measurements. It\n",
    "        is assumed that it is concomitant to the precipitation time series. Data\n",
    "        with good quality is \"0\", data with bad quality is \"1\"\n",
    "    date : pandas.core.indexes.datetimes.DatetimeIndex\n",
    "        Date series. It is assumed that it is concomitant to the precipitation\n",
    "        time series\n",
    "    temperature : np.array\n",
    "        Array containing the temperature time series. It is assumed that it is\n",
    "        concomitant to the precipitation time series.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Value of the signature.\n",
    "    \"\"\"\n",
    "\n",
    "    good_quality_data = check_data(precipitation=precipitation,\n",
    "                                   quality=quality,\n",
    "                                   temperature=temperature)\n",
    "\n",
    "    if not good_quality_data:\n",
    "        return None\n",
    "\n",
    "    if len(precipitation) != len(date):\n",
    "        raise ValueError('precipitation and date have different length: {} vs {}'.format(\n",
    "            len(precipitation), len(date)))\n",
    "\n",
    "    # Calculate the day of the year\n",
    "    t_julian = date.dayofyear-1  # 1 Jan is zero\n",
    "\n",
    "    # Create a DataFrame\n",
    "    prec = pd.DataFrame(data=np.array([precipitation, quality]).transpose(),\n",
    "                        index=date,\n",
    "                        columns=['P', 'QC'])\n",
    "\n",
    "    mean_month_prec = prec[prec.QC == 0].groupby(\n",
    "        prec.index[prec.QC == 0].month).mean()\n",
    "\n",
    "    # Get a first guess of the phase -> month with the most precipitation\n",
    "    sp_first_guess = 90 - (mean_month_prec.idxmax()['P'] - 1)*30\n",
    "    sp_first_guess = sp_first_guess + 360 if sp_first_guess < 0 else sp_first_guess\n",
    "\n",
    "    # Fit the two sine functions\n",
    "    def fit_p(pars, x, y):\n",
    "        prec = y.mean() * (1 + pars[0]*np.sin(2*np.pi*(x-pars[1])/365.25))\n",
    "        return y - prec\n",
    "\n",
    "    def fit_t(pars, x, y):\n",
    "        temp = y.mean() + pars[0]*np.sin(2*np.pi*(x-pars[1])/365.25)\n",
    "        return y - temp\n",
    "\n",
    "    prec_pars = least_squares(fun=fit_p,\n",
    "                              x0=[0.4, sp_first_guess],\n",
    "                              bounds=([-1, 0], [1, 365.25]),\n",
    "                              args=(t_julian[quality == 0], precipitation[quality == 0]))\n",
    "\n",
    "    temp_pars = least_squares(fun=fit_t,\n",
    "                              x0=[5, 270],\n",
    "                              args=(t_julian[quality == 0], temperature[quality == 0]))\n",
    "\n",
    "    # Explicit the parameters\n",
    "    delta_p = prec_pars.x[0]\n",
    "    sp = prec_pars.x[1]\n",
    "    delta_t = temp_pars.x[0]\n",
    "    st = temp_pars.x[1]\n",
    "\n",
    "    sig = delta_p * np.sign(delta_t) * np.cos(2 * np.pi * (sp - st) / 365.25)\n",
    "\n",
    "    return(float(sig))\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "# Finally, we replace the function with the corrected version: \n",
    "hydroanalysis.meteo_indexes.calculate_p_seasonality = calculate_p_seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b30d32",
   "metadata": {},
   "source": [
    "## Signatures computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09835ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrometeo_signatures_df = pd.DataFrame(index = network_estreams_filtered.index, \n",
    "                                        columns = [\"q_corr\", \"q_mean\", \"q_runoff_ratio\", \"q_elas_Sawicz\", \n",
    "                                                   \"q_elas_Sankarasubramanian\", \"slope_sawicz\", \"slope_yadav\",\n",
    "                                                   \"slope_mcmillan\", \"slope_addor\", \"baseflow_index\", \"hfd_mean\",\n",
    "                                                   \"hfd_std\", \"q_5\", \"q_95\", \"hq_freq\", \"hq_dur\", \"lq_freq\", \n",
    "                                                   \"lq_dur\", \"zero_q_freq\", \"p_mean\", \"pet_mean\", \"aridity\", \n",
    "                                                   \"p_seasonality\", \"frac_snow\", \"hp_freq\",\n",
    "                                                   \"hp_dur\", \"hp_time\", \"lp_freq\", \"lp_dur\",\n",
    "                                                   \"lp_time\"\n",
    "                                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8449c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamflow signatures\n",
    "for gauge in tqdm.tqdm(timeseries_discharge.columns):\n",
    "        \n",
    "    # Correlation between runoff and precipitation\n",
    "    hydrometeo_signatures_df.loc[gauge, \"q_corr\"] = timeseries_discharge.loc[:, gauge].corr(timeseries_precipitation.loc[:, gauge])\n",
    "    \n",
    "    # Runoff mean (mm/day)\n",
    "    hydrometeo_signatures_df.loc[gauge, \"q_mean\"] = hydroanalysis.streamflow_signatures.calculate_q_mean(timeseries_discharge.loc[:, gauge].values, quality_discharge_precipitation.loc[:, gauge].values)\n",
    "    \n",
    "    # Runoff ratio (-)\n",
    "    hydrometeo_signatures_df.loc[gauge, \"q_runoff_ratio\"] = hydroanalysis.streamflow_signatures.calculate_runoff_ratio(streamflow = timeseries_discharge.loc[:, gauge].values,\n",
    "                                                                                              quality  = quality_discharge_precipitation.loc[:, gauge].values,\n",
    "                                                                                            precipitation = timeseries_precipitation.loc[:, gauge].values)\n",
    "    # Streamflow elasticity (-)\n",
    "    elas_gauge = hydroanalysis.streamflow_signatures.calculate_stream_elas(streamflow = timeseries_discharge.loc[:, gauge].values,\n",
    "                                                                quality  = quality_discharge_precipitation.loc[:, gauge].values,\n",
    "                                                                precipitation = timeseries_precipitation.loc[:, gauge].values,\n",
    "                                                                hydro_year  = hydro_year)\n",
    "    try:\n",
    "        hydrometeo_signatures_df.loc[gauge, [\"q_elas_Sawicz\", \n",
    "                                         \"q_elas_Sankarasubramanian\"]] = elas_gauge[\"Sawicz\"],elas_gauge[\"Sankarasubramanian\"]\n",
    "    except: \n",
    "        hydrometeo_signatures_df.loc[gauge, [\"q_elas_Sawicz\", \n",
    "                                         \"q_elas_Sankarasubramanian\"]] = np.nan, np.nan\n",
    "    \n",
    "    # Slope (-)\n",
    "    slope_gauge = hydroanalysis.streamflow_signatures.calculate_slope_fdc(streamflow = timeseries_discharge.loc[:, gauge].values,                                                                  \n",
    "                                                                          quality  = quality_discharge_precipitation.loc[:, gauge].values)\n",
    "    try:\n",
    "        hydrometeo_signatures_df.loc[gauge, [\"slope_sawicz\", \"slope_yadav\",\n",
    "                                         \"slope_mcmillan\", \"slope_addor\"]] = slope_gauge[\"Sawicz\"],slope_gauge[\"Yadav\"],slope_gauge[\"McMillan\"],slope_gauge[\"Addor\"]\n",
    "    except: \n",
    "        hydrometeo_signatures_df.loc[gauge, [\"slope_sawicz\", \"slope_yadav\",\n",
    "                                         \"slope_mcmillan\", \"slope_addor\"]] = np.nan, np.nan, np.nan, np.nan\n",
    "    try: \n",
    "        # Baseflow index (-)\n",
    "        hydrometeo_signatures_df.loc[gauge, \"baseflow_index\"] = hydroanalysis.streamflow_signatures.calculate_baseflow_index(streamflow = timeseries_discharge.loc[:, gauge].values, \n",
    "                                                                                             quality = quality_discharge_precipitation.loc[:, gauge].values)\n",
    "    except:\n",
    "        # Baseflow index (-)\n",
    "        hydrometeo_signatures_df.loc[gauge, \"baseflow_index\"] = np.nan\n",
    "        \n",
    "        \n",
    "    # Half-flow duration (days)\n",
    "    hfd_gauge = hydroanalysis.streamflow_signatures.calculate_hfd_mean(streamflow = timeseries_discharge.loc[:, gauge].values,\n",
    "                                                                quality  = quality_discharge_precipitation.loc[:, gauge].values,\n",
    "                                                                hydro_year = hydro_year)\n",
    "    try:\n",
    "        hydrometeo_signatures_df.loc[gauge, [\"hfd_mean\", \n",
    "                          \"hfd_std\"]] = hfd_gauge[\"hfd_mean\"],hfd_gauge[\"hfd_std\"]\n",
    "    except:\n",
    "        hydrometeo_signatures_df.loc[gauge, [\"hfd_mean\", \n",
    "                          \"hfd_std\"]] = np.nan, np.nan\n",
    "        \n",
    "    # Q5 (mm/day)\n",
    "    hydrometeo_signatures_df.loc[gauge, \"q_5\"] = hydroanalysis.streamflow_signatures.calculate_q_5(streamflow = timeseries_discharge.loc[:, gauge].values, \n",
    "                                                                          quality = quality_discharge_precipitation.loc[:, gauge].values)\n",
    "    # Q95 (mm/day)\n",
    "    hydrometeo_signatures_df.loc[gauge, \"q_95\"] = hydroanalysis.streamflow_signatures.calculate_q_95(streamflow = timeseries_discharge.loc[:, gauge].values, \n",
    "                                                                          quality = quality_discharge_precipitation.loc[:, gauge].values)\n",
    "    \n",
    "    # High-flow frequency (days/year) and mean duration (days)\n",
    "    hq_gauge = hydroanalysis.streamflow_signatures.calculate_high_q_freq_dur(streamflow = timeseries_discharge.loc[:, gauge].values,\n",
    "                                                                              quality  = quality_discharge_precipitation.loc[:, gauge].values)\n",
    "    \n",
    "    try: \n",
    "        hydrometeo_signatures_df.loc[gauge, [\"hq_freq\", \n",
    "                                         \"hq_dur\"]] = hq_gauge[\"hq_freq\"],hq_gauge[\"hq_dur\"]\n",
    "    except:\n",
    "        hydrometeo_signatures_df.loc[gauge, [\"hq_freq\", \n",
    "                                         \"hq_dur\"]] = np.nan, np.nan\n",
    "\n",
    "    # Low-flow frequency (days/year) and mean duration (days)\n",
    "    lq_gauge = hydroanalysis.streamflow_signatures.calculate_low_q_freq_dur(streamflow = timeseries_discharge.loc[:, gauge].values,\n",
    "                                                                              quality  = quality_discharge_precipitation.loc[:, gauge].values)\n",
    "    \n",
    "    try:\n",
    "        hydrometeo_signatures_df.loc[gauge, [\"lq_freq\", \n",
    "                                         \"lq_dur\"]] = lq_gauge[\"lq_freq\"],lq_gauge[\"lq_dur\"]\n",
    "    except:\n",
    "        hydrometeo_signatures_df.loc[gauge, [\"lq_freq\", \n",
    "                                         \"lq_dur\"]] = np.nan, np.nan\n",
    "    \n",
    "    # Zero-flow frequency (-)\n",
    "    hydrometeo_signatures_df.loc[gauge, \"zero_q_freq\"] = hydroanalysis.streamflow_signatures.calculate_zero_q_freq(streamflow = timeseries_discharge.loc[:, gauge].values, \n",
    "                                                                          quality = quality_discharge_precipitation.loc[:, gauge].values)\n",
    "\n",
    "hydrometeo_signatures_df = hydrometeo_signatures_df.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aaa6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meteorological signatures\n",
    "\n",
    "for gauge in tqdm.tqdm(timeseries_discharge.columns):\n",
    "        \n",
    "    # P mean (mm/day)\n",
    "    hydrometeo_signatures_df.loc[gauge, \"p_mean\"] = hydroanalysis.meteo_indexes.calculate_p_mean(precipitation = timeseries_precipitation.loc[:, gauge].values,\n",
    "                                                                        quality  = quality_pet_precipitation_temperature.loc[:, gauge].values)\n",
    "    \n",
    "    # PET mean (mm/day)\n",
    "    hydrometeo_signatures_df.loc[gauge, \"pet_mean\"] = hydroanalysis.meteo_indexes.calculate_pet_mean(pet = timeseries_pet.loc[:, gauge].values,\n",
    "                                                                          quality  = quality_pet_precipitation_temperature.loc[:, gauge].values)\n",
    "    \n",
    "    # Aridity index (-)\n",
    "    hydrometeo_signatures_df.loc[gauge, \"aridity\"] = hydroanalysis.meteo_indexes.calculate_aridity(precipitation = timeseries_precipitation.loc[:, gauge].values,\n",
    "                                                                pet = timeseries_pet.loc[:, gauge].values,\n",
    "                                                                quality  = quality_pet_precipitation_temperature.loc[:, gauge].values)\n",
    "    # Precipitation seasonality (-)\n",
    "    hydrometeo_signatures_df.loc[gauge, \"p_seasonality\"] = hydroanalysis.meteo_indexes.calculate_p_seasonality(precipitation = timeseries_precipitation.loc[:, gauge].values,\n",
    "                                                                                quality  = quality_pet_precipitation_temperature.loc[:, gauge].values,\n",
    "                                                                                date =timeseries_precipitation.loc[:, gauge].index,\n",
    "                                                                                temperature = timeseries_temperature.loc[:, gauge].values)\n",
    "    # Fraction of snow (-)\n",
    "    hydrometeo_signatures_df.loc[gauge, \"frac_snow\"] = hydroanalysis.meteo_indexes.calculate_frac_snow(precipitation = timeseries_precipitation.loc[:, gauge].values,\n",
    "                                                                              temperature = timeseries_temperature.loc[:, gauge].values,\n",
    "                                                                              quality  = quality_pet_precipitation_temperature.loc[:, gauge].values,\n",
    "                                                                              threshold=0.0)\n",
    "    \n",
    "    # High-precipitation frequency time\n",
    "    high_prec_freq_time_gauge = hydroanalysis.meteo_indexes.calculate_high_prec_freq_time(precipitation = timeseries_precipitation.loc[:, gauge].values,\n",
    "                                                                              quality  = quality_pet_precipitation_temperature.loc[:, gauge].values,\n",
    "                                                                              date = timeseries_temperature.loc[:, gauge].index)\n",
    "    try:\n",
    "        hydrometeo_signatures_df.loc[gauge, [\"hp_freq\", \n",
    "                          \"hp_dur\", \"hp_time\"]] = high_prec_freq_time_gauge[\"hp_freq\"],high_prec_freq_time_gauge[\"hp_dur\"], high_prec_freq_time_gauge[\"hp_time\"]\n",
    "    except:\n",
    "        hydrometeo_signatures_df.loc[gauge, [\"hp_freq\", \n",
    "                          \"hp_dur\", \"hp_time\"]] = np.nan, np.nan, np.nan\n",
    "    \n",
    "    # Low-precipitation frequency time\n",
    "    low_prec_freq_time_gauge = hydroanalysis.meteo_indexes.calculate_low_prec_freq_time(precipitation = timeseries_precipitation.loc[:, gauge].values,\n",
    "                                                                              quality  = quality_pet_precipitation_temperature.loc[:, gauge].values,\n",
    "                                                                              date = timeseries_temperature.loc[:, gauge].index)\n",
    "    try:\n",
    "        hydrometeo_signatures_df.loc[gauge, [\"lp_freq\", \n",
    "                          \"lp_dur\", \"lp_time\"]] = low_prec_freq_time_gauge[\"lp_freq\"],low_prec_freq_time_gauge[\"lp_dur\"], low_prec_freq_time_gauge[\"lp_time\"]\n",
    "    except:\n",
    "        hydrometeo_signatures_df.loc[gauge, [\"lp_freq\", \n",
    "                          \"lp_dur\", \"lp_time\"]] = np.nan, np.nan, np.nan\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42754a",
   "metadata": {},
   "source": [
    "## Number of measurements used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37712a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of measurements:\n",
    "hydrometeo_signatures_df[[\"num_days\", \"num_months\", \"num_months_complete\", \"num_years_hydro\", \"num_years_complete\"]] = count_num_measurements(timeseries = timeseries_discharge)\n",
    "hydrometeo_signatures_df.drop([\"num_days\", \"num_months\", \"num_months_complete\", \"num_years_complete\"], axis = 1, inplace = True)\n",
    "\n",
    "hydrometeo_signatures_df[\"start_date_hydro\"] = find_first_non_nan_dates(timeseries_discharge)\n",
    "hydrometeo_signatures_df[\"end_date_hydro\"] = find_last_non_nan_dates(timeseries_discharge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b080ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Number of measurements:\n",
    "hydrometeo_signatures_df[[\"num_days\", \"num_months\", \"num_months_complete\", \"num_years_climatic\", \"num_years_complete\"]] = count_num_measurements(timeseries = timeseries_pet)\n",
    "hydrometeo_signatures_df.drop([\"num_days\", \"num_months\", \"num_months_complete\", \"num_years_complete\"], axis = 1, inplace = True)\n",
    "hydrometeo_signatures_df[\"start_date_climatic\"] = find_first_non_nan_dates(timeseries_pet)\n",
    "hydrometeo_signatures_df[\"end_date_climatic\"] = find_last_non_nan_dates(timeseries_pet)\n",
    "\n",
    "hydrometeo_signatures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce953897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we organize the data with all the catchments (not only the filtered)\n",
    "signatures_df = pd.DataFrame(columns = hydrometeo_signatures_df.columns, index = network_estreams.index)\n",
    "signatures_df.loc[hydrometeo_signatures_df.index, :] =  hydrometeo_signatures_df\n",
    "signatures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2add39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we filter only the fields used at Addor et al. (2017)\n",
    "signatures_df = signatures_df[[\"q_mean\", \"q_runoff_ratio\", \"q_elas_Sankarasubramanian\", \"slope_sawicz\",\n",
    "                               \"baseflow_index\", \"hfd_mean\", \"hfd_std\", \"q_5\", \"q_95\", \"hq_freq\", \"hq_dur\", \"lq_freq\", \n",
    "                               \"lq_dur\", \"zero_q_freq\", \"p_mean\", \"pet_mean\", \"aridity\", \n",
    "                               \"p_seasonality\", \"frac_snow\", \"hp_freq\",\n",
    "                               \"hp_dur\", \"hp_time\", \"lp_freq\", \"lp_dur\", \"lp_time\",\n",
    "                               \"num_years_hydro\", \"start_date_hydro\", \"end_date_hydro\",\n",
    "                               \"num_years_climatic\", \"start_date_climatic\", \"end_date_climatic\"  \n",
    "                                                  ]]\n",
    "signatures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e15eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures_df.iloc[:, 0:-10] = signatures_df.iloc[:, 0:-10].astype(float).round(3)\n",
    "signatures_df.iloc[:, -9:-7] = signatures_df.iloc[:, -9:-7].astype(float).round(3)\n",
    "signatures_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447810fd",
   "metadata": {},
   "source": [
    "# Data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the final dataset:\n",
    "signatures_df.to_csv(PATH_OUTPUT+\"estreams_hydrometeo_signatures.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b608e26e",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
