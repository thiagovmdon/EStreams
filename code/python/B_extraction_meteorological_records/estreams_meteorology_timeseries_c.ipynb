{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9429523",
   "metadata": {},
   "source": [
    "# Meteorological time-series extraction: Part C\n",
    "\n",
    "Author: Thiago Nascimento (thiago.nascimento@eawag.ch)\n",
    "\n",
    "This notebook is part of the EStreams publication and was used to extract and aggregate the meteorological time-series from the E-OBS dataset. At Part C we export the preprocessed daily data in the final time-series format. \n",
    "\n",
    "* Note that this code enables not only the replicability of the current database but also the extrapolation to new catchment areas. \n",
    "* Additionally, the user should download and insert the original raw-data in the folder of the same name prior to run this code. \n",
    "* The original third-party data used were not made available in this repository due to redistribution and storage-space reasons.  \n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "\n",
    "* Python>=3.6\n",
    "* Jupyter\n",
    "* geopandas=0.10.2\n",
    "* glob\n",
    "* netCDF4\n",
    "* numpy\n",
    "* os\n",
    "* pandas\n",
    "* tqdm\n",
    "\n",
    "Check the Github repository for an environment.yml (for conda environments) or requirements.txt (pip) file.\n",
    "\n",
    "**Files:**\n",
    "\n",
    "* data/meteorology/eobs/preprocessing/{rr, tg, tn, tx, pp, hu, fg, qq, pet, pet_iceland}\n",
    "* data/shapefiles/estreams_catchments.shp\n",
    "\n",
    "**Directory:**\n",
    "\n",
    "* Clone the GitHub directory locally\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. \n",
    "\n",
    "## References\n",
    "\n",
    "* Cornes, R., G. van der Schrier, E.J.M. van den Besselaar, and P.D. Jones. 2018: An Ensemble Version of the E-OBS Temperature and Precipitation Datasets, J. Geophys. Res. Atmos., 123. doi:10.1029/2017JD028200\n",
    "\n",
    "## Licenses\n",
    "* EOBS: \"The ECA&D data policy applies. These observational data are strictly for use in non-commercial research and non-commercial education projects only. Scientific results based on these data must be submitted for publication in the open literature without any delay linked to commercial objectives\" https://www.ecad.eu/download/ensembles/download.php#guidance (Last access: 27 November 2023)\n",
    "\n",
    "## Observations\n",
    "#### E-OBS filenames\n",
    "\n",
    "* rr = Total daily precipitation\n",
    "* tg = Mean daily temperature\n",
    "* tn = Minimum daily temperature\n",
    "* tx = Maximum daily temperature\n",
    "* pp = Mean daily air pressure at sea level\n",
    "* hu = Mean daily relative humidity\n",
    "* fg = Mean wind speed at 10-meters\n",
    "* qq = Total daily global radiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395ba82c",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tqdm\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f5a4e8",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variables:\n",
    "# Relative path to your local directory\n",
    "PATH = \"../../..\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656bdd51",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f300d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-editable variables:\n",
    "PATH_preprocessing = \"data/meteorology/eobs/preprocessing/\"\n",
    "PATH_OUTPUT = \"results/timeseries/meteorology/catchments\"\n",
    "PATH_OUTPUT_2 = \"results/timeseries/meteorology\"\n",
    "PATH_shapefile = \"data/shapefiles/estreams_catchments.shp\"\n",
    "variables = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet\", \"pet_iceland\"] # Eobs variables\n",
    "\n",
    "# Set the directory:\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896190fa",
   "metadata": {},
   "source": [
    "# Import data\n",
    "## Catchment boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ab7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_boundaries = gpd.read_file(PATH_shapefile)\n",
    "catchment_boundaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The total number of catchments to be processed are:\", len(catchment_boundaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e78cf",
   "metadata": {},
   "source": [
    "# Reproject to WGS-84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284610e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CRS of the shapefile's geometry to EPSG:4326 (WGS 84)\n",
    "catchment_boundaries[\"geometry\"] = catchment_boundaries[\"geometry\"].to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb39ab0",
   "metadata": {},
   "source": [
    "# Data organization and export\n",
    "* #### This part should only be run after all the e-obs variables time-series have already been extracted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e8a80",
   "metadata": {},
   "source": [
    "* Each catchment will be exported as one single CSV-file with their respective nine variables.\n",
    "* variables = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet\"].\n",
    "* We divide here the analsysis for first except Iceland, and for only Iceland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can check the folders again:\n",
    "folders = glob.glob(PATH_preprocessing+ \"/*\")\n",
    "folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0a5c0f",
   "metadata": {},
   "source": [
    "## No Iceland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3834caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first two rows from catchment_boundaries\n",
    "subset_catchment = catchment_boundaries[~catchment_boundaries['basin_id'].str.contains('IS00', case=False)]\n",
    "\n",
    "catchmentnames = subset_catchment.basin_id.tolist()\n",
    "len(catchmentnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e90f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we may organize our data:\n",
    "variables = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet\"]\n",
    "\n",
    "# The loop goes over each catchment and variable, and make one export per catchment. At the end we will have \n",
    "# 15,047 csv-files each with 9 columns, and one datetype index.\n",
    "for catchment in tqdm.tqdm(catchmentnames):\n",
    "    \n",
    "    timeseries_variables = pd.DataFrame(index=pd.date_range('01-01-1950', '06-30-2023', freq='D'), columns = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet\"])\n",
    "    \n",
    "    for variable in variables:\n",
    "        \n",
    "        # Wind speed (fg) has its date range from 1980-2023, while all other variables from 1950-2023. \n",
    "        # Therefore we apoly a if to deal with the situation: \n",
    "        if variable == \"fg\":\n",
    "            timeseries_catchment = pd.read_csv('data/meteorology/eobs/preprocessing/'+variable+\"/\"+variable+\"_\"+catchment+\".csv\", \n",
    "                                               usecols=[0], header=None, names=[\"weighted\"])\n",
    "            timeseries_catchment.index = pd.date_range('01-01-1980', '06-30-2023', freq='D')\n",
    "            timeseries_variables[variable] = timeseries_catchment\n",
    "            \n",
    "        else:\n",
    "            timeseries_catchment = pd.read_csv('data/meteorology/eobs/preprocessing/'+variable+\"/\"+variable+\"_\"+catchment+\".csv\", \n",
    "                                               usecols=[0], header=None, names=[\"weighted\"])\n",
    "            timeseries_catchment.index = pd.date_range('01-01-1950', '06-30-2023', freq='D')\n",
    "            timeseries_variables[variable] = timeseries_catchment\n",
    "    \n",
    "    # Here we rename our columns:\n",
    "    timeseries_variables.columns = [\"p_mean\", \"t_mean\", \"t_min\", \"t_max\", \"sp_mean\", \"rh_mean\", \"ws_mean\",\"swr_mean\", \"pet_mean\"]\n",
    "    timeseries_variables = timeseries_variables.round(2)\n",
    "    timeseries_variables.index.name = \"date\"\n",
    "    timeseries_variables.to_csv(PATH_OUTPUT + \"/estreams_meteorology_\"+catchment+\".csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c352df05",
   "metadata": {},
   "source": [
    "## Iceland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first two rows from catchment_boundaries\n",
    "subset_catchment = catchment_boundaries[catchment_boundaries['basin_id'].str.contains('IS00', case=False)]\n",
    "\n",
    "catchmentnames = subset_catchment.basin_id.tolist()\n",
    "len(catchmentnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eba7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we may organize our data:\n",
    "variables = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet_iceland\"]\n",
    "\n",
    "# The loop goes over each catchment and variable, and make one export per catchment. At the end we will have \n",
    "# 15,047 csv-files each with 9 columns, and one datetype index.\n",
    "for catchment in tqdm.tqdm(catchmentnames):\n",
    "    \n",
    "    timeseries_variables = pd.DataFrame(index=pd.date_range('01-01-1950', '06-30-2023', freq='D'), columns = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet_iceland\"])\n",
    "    \n",
    "    for variable in variables:\n",
    "        \n",
    "        # It may be the case that there is no csv-file for the respective catchment (areas not covered by E-OBS)\n",
    "        # Therefore the try except can deal with this situation\n",
    "        \n",
    "        # Wind speed (fg) has its date range from 1980-2023, while all other variables from 1950-2023. \n",
    "        # Therefore we apoly a if to deal with the situation: \n",
    "        if variable == \"fg\":\n",
    "            timeseries_catchment = pd.read_csv('data/meteorology/eobs/preprocessing/'+variable+\"/\"+variable+\"_\"+catchment+\".csv\", \n",
    "                                               usecols=[0], header=None, names=[\"weighted\"])\n",
    "            timeseries_catchment.index = pd.date_range('01-01-1980', '06-30-2023', freq='D')\n",
    "            timeseries_variables[variable] = timeseries_catchment\n",
    "            \n",
    "        else:\n",
    "            timeseries_catchment = pd.read_csv('data/meteorology/eobs/preprocessing/'+variable+\"/\"+variable+\"_\"+catchment+\".csv\", \n",
    "                                               usecols=[0], header=None, names=[\"weighted\"])\n",
    "            timeseries_catchment.index = pd.date_range('01-01-1950', '06-30-2023', freq='D')\n",
    "            timeseries_variables[variable] = timeseries_catchment\n",
    "    \n",
    "    # Here we rename our columns:\n",
    "    timeseries_variables.columns = [\"p_mean\", \"t_mean\", \"t_min\", \"t_max\", \"sp_min\", \"rh_mean\", \"ws_mean\",\"swr_mean\", \"pet_mean\"]\n",
    "    timeseries_variables = timeseries_variables.round(2)\n",
    "    timeseries_variables.index.name = \"date\"\n",
    "    timeseries_variables.to_csv(PATH_OUTPUT + \"/estreams_meteorology_\"+catchment+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed446c3",
   "metadata": {},
   "source": [
    "# CSV-files for hydro-climatic signatures and indexes  \n",
    "Here instead of individually, we export these variables in three csv-files because this format will be usefull for the streamflow signatures computation. We only export these three files because they are the only used for the signatures and indexes. \n",
    "\n",
    "* estreams_meteorology_precipitation.csv\n",
    "* estreams_meteorology_temperature.csv\n",
    "* estreams_meteorology_pet.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc42044",
   "metadata": {},
   "source": [
    "### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31968129",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(PATH_preprocessing+\"rr/\" +  \"/*.csv\")\n",
    "len(filenames)\n",
    "\n",
    "timeseries_p = pd.DataFrame(index=pd.date_range('01-01-1950', '06-30-2023', freq='D'))\n",
    "\n",
    "for filename in tqdm.tqdm(filenames):\n",
    "\n",
    "    catchmentname = os.path.basename(filename)\n",
    "    catchmentname = catchmentname.split(\"_\", 1)[1]\n",
    "    catchmentname = catchmentname.replace(\".csv\", \"\")\n",
    "\n",
    "    timeseries_catchment = pd.read_csv(filename, usecols=[0], header=None, names=[\"weighted\"])\n",
    "    timeseries_catchment.index = pd.date_range('01-01-1950', '06-30-2023', freq='D')\n",
    "\n",
    "    catchment_values = timeseries_catchment[\"weighted\"].values\n",
    "    \n",
    "    timeseries_p[str(catchmentname)+\"a\"] = catchment_values\n",
    "\n",
    "# The only way this code worked was after the addition of \"a\", then now we must delete it:    \n",
    "timeseries_p.columns = timeseries_p.columns.str.replace(\"a\", \"\")\n",
    "timeseries_p = timeseries_p.round(2)\n",
    "timeseries_p = timeseries_p.sort_index(axis=1)\n",
    "\n",
    "# Save the data:\n",
    "# Export the final dataset:\n",
    "timeseries_p.to_csv(PATH_OUTPUT_2 + \"/estreams_meteorology_precipitation.csv\")\n",
    "\n",
    "# Check it out:\n",
    "timeseries_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83f5787",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc8b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(PATH_preprocessing+\"tg/\" +  \"/*.csv\")\n",
    "len(filenames)\n",
    "\n",
    "timeseries_tmean = pd.DataFrame(index=pd.date_range('01-01-1950', '06-30-2023', freq='D'))\n",
    "\n",
    "for filename in tqdm.tqdm(filenames):\n",
    "\n",
    "    catchmentname = os.path.basename(filename)\n",
    "    catchmentname = catchmentname.split(\"_\", 1)[1]\n",
    "    catchmentname = catchmentname.replace(\".csv\", \"\")\n",
    "\n",
    "    timeseries_catchment = pd.read_csv(filename, usecols=[0], header=None, names=[\"weighted\"])\n",
    "    timeseries_catchment.index = pd.date_range('01-01-1950', '06-30-2023', freq='D')\n",
    "\n",
    "    catchment_values = timeseries_catchment[\"weighted\"].values\n",
    "    \n",
    "    timeseries_tmean[str(catchmentname)+\"a\"] = catchment_values\n",
    "\n",
    "# The only way this code worked was after the addition of \"a\", then now we must delete it:    \n",
    "timeseries_tmean.columns = timeseries_tmean.columns.str.replace(\"a\", \"\")\n",
    "timeseries_tmean = timeseries_tmean.round(2)\n",
    "timeseries_tmean = timeseries_tmean.sort_index(axis=1)\n",
    "\n",
    "# Save the data:\n",
    "# Export the final dataset:\n",
    "timeseries_tmean.to_csv(PATH_OUTPUT_2 + \"/estreams_meteorology_temperature.csv\")\n",
    "\n",
    "# Check it out:\n",
    "timeseries_tmean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc43c73",
   "metadata": {},
   "source": [
    "### Potential evapotranspiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd486d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the general catchments:\n",
    "filenames = glob.glob(PATH_preprocessing+\"pet/\" +  \"/*.csv\")\n",
    "\n",
    "timeseries_pet = pd.DataFrame(index=pd.date_range('01-01-1950', '06-30-2023', freq='D'))\n",
    "\n",
    "for filename in tqdm.tqdm(filenames):\n",
    "\n",
    "    catchmentname = os.path.basename(filename)\n",
    "    catchmentname = catchmentname.split(\"_\", 1)[1]\n",
    "    catchmentname = catchmentname.replace(\".csv\", \"\")\n",
    "\n",
    "    timeseries_catchment = pd.read_csv(filename, usecols=[0], header=None, names=[\"weighted\"])\n",
    "    timeseries_catchment.index = pd.date_range('01-01-1950', '06-30-2023', freq='D')\n",
    "\n",
    "    catchment_values = timeseries_catchment[\"weighted\"].values\n",
    "    \n",
    "    timeseries_pet[str(catchmentname)+\"a\"] = catchment_values\n",
    "\n",
    "# For the catchments in Iceland:\n",
    "filenames_iceland = glob.glob(PATH_preprocessing+\"pet_iceland/\" +  \"/*.csv\")\n",
    "\n",
    "timeseries_pet_iceland = pd.DataFrame(index=pd.date_range('01-01-1950', '06-30-2023', freq='D'))\n",
    "\n",
    "for filename in tqdm.tqdm(filenames_iceland):\n",
    "\n",
    "    catchmentname = os.path.basename(filename)\n",
    "    catchmentname = catchmentname.split(\"_\", 2)[2]\n",
    "    catchmentname = catchmentname.replace(\".csv\", \"\")\n",
    "\n",
    "    timeseries_catchment = pd.read_csv(filename, usecols=[0], header=None, names=[\"weighted\"])\n",
    "    timeseries_catchment.index = pd.date_range('01-01-1950', '06-30-2023', freq='D')\n",
    "\n",
    "    catchment_values = timeseries_catchment[\"weighted\"].values\n",
    "    \n",
    "    timeseries_pet_iceland[str(catchmentname)+\"a\"] = catchment_values\n",
    "\n",
    "\n",
    "timeseries_pet = pd.concat([timeseries_pet, timeseries_pet_iceland], axis=1)\n",
    "    \n",
    "# The only way this code worked was after the addition of \"a\", then now we must delete it:    \n",
    "timeseries_pet.columns = timeseries_pet.columns.str.replace(\"a\", \"\")\n",
    "timeseries_pet = timeseries_pet.round(2)\n",
    "timeseries_pet = timeseries_pet.sort_index(axis=1)\n",
    "\n",
    "# Save the data:\n",
    "# Export the final dataset:\n",
    "timeseries_pet.to_csv(PATH_OUTPUT_2 + \"/estreams_meteorology_pet.csv\")\n",
    "\n",
    "# Check it out:\n",
    "timeseries_pet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3890db",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
