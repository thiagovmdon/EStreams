{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9429523",
   "metadata": {},
   "source": [
    "# Meteorological time-series extraction: Part C\n",
    "\n",
    "Author: Thiago Nascimento (thiago.nascimento@eawag.ch)\n",
    "\n",
    "This notebook is part of the EStreams publication and was used to extract and aggregate the meteorological time-series from the E-OBS dataset. At Part C we export the preprocessed daily data in the final time-series format. \n",
    "\n",
    "* Note that this code enables not only the replicability of the current database but also the extrapolation to new catchment areas. \n",
    "* Additionally, the user should download and insert the original raw-data in the folder of the same name prior to run this code. \n",
    "* The original third-party data used were not made available in this repository due to redistribution and storage-space reasons.  \n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "\n",
    "* Python>=3.6\n",
    "* Jupyter\n",
    "* geopandas=0.10.2\n",
    "* glob\n",
    "* netCDF4\n",
    "* numpy\n",
    "* os\n",
    "* pandas\n",
    "* tqdm\n",
    "\n",
    "Check the Github repository for an environment.yml (for conda environments) or requirements.txt (pip) file.\n",
    "\n",
    "**Files:**\n",
    "\n",
    "* data/meteorology/eobs/preprocessing/{rr, tg, tn, tx, pp, hu, fg, qq, pet, pet_iceland}\n",
    "* data/shapefiles/estreams_catchments.shp\n",
    "\n",
    "**Directory:**\n",
    "\n",
    "* Clone the GitHub directory locally\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. \n",
    "\n",
    "## References\n",
    "\n",
    "* Cornes, R., G. van der Schrier, E.J.M. van den Besselaar, and P.D. Jones. 2018: An Ensemble Version of the E-OBS Temperature and Precipitation Datasets, J. Geophys. Res. Atmos., 123. doi:10.1029/2017JD028200\n",
    "\n",
    "## Licenses\n",
    "* EOBS: \"The ECA&D data policy applies. These observational data are strictly for use in non-commercial research and non-commercial education projects only. Scientific results based on these data must be submitted for publication in the open literature without any delay linked to commercial objectives\" https://www.ecad.eu/download/ensembles/download.php#guidance (Last access: 27 November 2023)\n",
    "\n",
    "## Observations\n",
    "#### E-OBS filenames\n",
    "\n",
    "* rr = Total daily precipitation\n",
    "* tg = Mean daily temperature\n",
    "* tn = Minimum daily temperature\n",
    "* tx = Maximum daily temperature\n",
    "* pp = Mean daily air pressure at sea level\n",
    "* hu = Mean daily relative humidity\n",
    "* fg = Mean wind speed at 10-meters\n",
    "* qq = Total daily global radiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395ba82c",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ad4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tqdm\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f5a4e8",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4d9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variables:\n",
    "# Relative path to your local directory\n",
    "PATH = \"../../..\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656bdd51",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f300d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-editable variables:\n",
    "PATH_preprocessing = \"data/meteorology/eobs/preprocessing/\"\n",
    "PATH_OUTPUT = \"results/timeseries/meteorology/catchments\"\n",
    "PATH_OUTPUT_2 = \"results/timeseries/meteorology\"\n",
    "PATH_shapefile = \"data/shapefiles/estreams_catchments.shp\"\n",
    "variables = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet\", \"pet_iceland\"] # Eobs variables\n",
    "\n",
    "# Set the directory:\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896190fa",
   "metadata": {},
   "source": [
    "# Import data\n",
    "## Catchment boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409ab7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>area_km2</th>\n",
       "      <th>outlet_lat</th>\n",
       "      <th>outlet_lng</th>\n",
       "      <th>name</th>\n",
       "      <th>area_offic</th>\n",
       "      <th>layer</th>\n",
       "      <th>path</th>\n",
       "      <th>area_diff</th>\n",
       "      <th>area_calc</th>\n",
       "      <th>basin_id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HUGR020</td>\n",
       "      <td>9,600</td>\n",
       "      <td>46.785</td>\n",
       "      <td>21.142</td>\n",
       "      <td>6444410</td>\n",
       "      <td>9011</td>\n",
       "      <td>HUGR020</td>\n",
       "      <td>C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...</td>\n",
       "      <td>6.536</td>\n",
       "      <td>9595.794</td>\n",
       "      <td>HUGR020</td>\n",
       "      <td>POLYGON ((21.13208 46.77291, 21.13208 46.77375...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HUGR021</td>\n",
       "      <td>189,000</td>\n",
       "      <td>46.423</td>\n",
       "      <td>18.896</td>\n",
       "      <td>6442080</td>\n",
       "      <td>189538</td>\n",
       "      <td>HUGR021</td>\n",
       "      <td>C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>188597.110</td>\n",
       "      <td>HUGR021</td>\n",
       "      <td>POLYGON ((18.91708 46.41791, 18.91708 46.41625...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HUGR022</td>\n",
       "      <td>28,500</td>\n",
       "      <td>48.126</td>\n",
       "      <td>22.340</td>\n",
       "      <td>6444304</td>\n",
       "      <td>29057</td>\n",
       "      <td>HUGR022</td>\n",
       "      <td>C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...</td>\n",
       "      <td>-1.917</td>\n",
       "      <td>28507.473</td>\n",
       "      <td>HUGR022</td>\n",
       "      <td>POLYGON ((22.32875 48.10875, 22.32791 48.10875...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HUGR023</td>\n",
       "      <td>188,000</td>\n",
       "      <td>46.627</td>\n",
       "      <td>18.869</td>\n",
       "      <td>6442060</td>\n",
       "      <td>189092</td>\n",
       "      <td>HUGR023</td>\n",
       "      <td>C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>188286.167</td>\n",
       "      <td>HUGR023</td>\n",
       "      <td>POLYGON ((18.89041 46.62875, 18.88875 46.62708...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HUGR025</td>\n",
       "      <td>1,210</td>\n",
       "      <td>47.662</td>\n",
       "      <td>19.683</td>\n",
       "      <td>6444240</td>\n",
       "      <td>1222</td>\n",
       "      <td>HUGR025</td>\n",
       "      <td>C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>1206.441</td>\n",
       "      <td>HUGR025</td>\n",
       "      <td>POLYGON ((19.68124 47.66875, 19.68291 47.66875...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id area_km2  outlet_lat  outlet_lng     name area_offic    layer  \\\n",
       "0  HUGR020    9,600      46.785      21.142  6444410       9011  HUGR020   \n",
       "1  HUGR021  189,000      46.423      18.896  6442080     189538  HUGR021   \n",
       "2  HUGR022   28,500      48.126      22.340  6444304      29057  HUGR022   \n",
       "3  HUGR023  188,000      46.627      18.869  6442060     189092  HUGR023   \n",
       "4  HUGR025    1,210      47.662      19.683  6444240       1222  HUGR025   \n",
       "\n",
       "                                                path  area_diff   area_calc  \\\n",
       "0  C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...      6.536    9595.794   \n",
       "1  C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...     -0.284  188597.110   \n",
       "2  C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...     -1.917   28507.473   \n",
       "3  C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...     -0.577  188286.167   \n",
       "4  C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...     -0.982    1206.441   \n",
       "\n",
       "  basin_id                                           geometry  \n",
       "0  HUGR020  POLYGON ((21.13208 46.77291, 21.13208 46.77375...  \n",
       "1  HUGR021  POLYGON ((18.91708 46.41791, 18.91708 46.41625...  \n",
       "2  HUGR022  POLYGON ((22.32875 48.10875, 22.32791 48.10875...  \n",
       "3  HUGR023  POLYGON ((18.89041 46.62875, 18.88875 46.62708...  \n",
       "4  HUGR025  POLYGON ((19.68124 47.66875, 19.68291 47.66875...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catchment_boundaries = gpd.read_file(PATH_shapefile)\n",
    "catchment_boundaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563a4b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of catchments to be processed are: 33\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of catchments to be processed are:\", len(catchment_boundaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e78cf",
   "metadata": {},
   "source": [
    "# Reproject to WGS-84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284610e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CRS of the shapefile's geometry to EPSG:4326 (WGS 84)\n",
    "catchment_boundaries[\"geometry\"] = catchment_boundaries[\"geometry\"].to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb39ab0",
   "metadata": {},
   "source": [
    "# Data organization and export\n",
    "* #### This part should only be run after all the e-obs variables time-series have already been extracted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e8a80",
   "metadata": {},
   "source": [
    "* Each catchment will be exported as one single CSV-file with their respective nine variables.\n",
    "* variables = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet\"].\n",
    "* We divide here the analsysis for first except Iceland, and for only Iceland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b2548e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/meteorology/eobs/preprocessing/pp',\n",
       " 'data/meteorology/eobs/preprocessing/rr',\n",
       " 'data/meteorology/eobs/preprocessing/tx',\n",
       " 'data/meteorology/eobs/preprocessing/pet',\n",
       " 'data/meteorology/eobs/preprocessing/hu',\n",
       " 'data/meteorology/eobs/preprocessing/fg',\n",
       " 'data/meteorology/eobs/preprocessing/pet_iceland',\n",
       " 'data/meteorology/eobs/preprocessing/tn',\n",
       " 'data/meteorology/eobs/preprocessing/tg',\n",
       " 'data/meteorology/eobs/preprocessing/qq']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can check the folders again:\n",
    "folders = glob.glob(PATH_preprocessing+ \"/*\")\n",
    "folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0a5c0f",
   "metadata": {},
   "source": [
    "## No Iceland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3834caca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the first two rows from catchment_boundaries\n",
    "subset_catchment = catchment_boundaries[~catchment_boundaries['basin_id'].str.contains('ISGR', case=False)]\n",
    "\n",
    "catchmentnames = subset_catchment.basin_id.tolist()\n",
    "len(catchmentnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "940e90f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:03<00:00,  8.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Now we may organize our data:\n",
    "variables = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet\"]\n",
    "\n",
    "# The loop goes over each catchment and variable, and make one export per catchment. At the end we will have \n",
    "# 15,047 csv-files each with 9 columns, and one datetype index.\n",
    "for catchment in tqdm.tqdm(catchmentnames):\n",
    "    \n",
    "    timeseries_variables = pd.DataFrame(index=pd.date_range('01-01-1950', '06-30-2023', freq='D'), columns = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet\"])\n",
    "    \n",
    "    for variable in variables:\n",
    "        \n",
    "        # Wind speed (fg) has its date range from 1980-2023, while all other variables from 1950-2023. \n",
    "        # Therefore we apoly a if to deal with the situation: \n",
    "        if variable == \"fg\":\n",
    "            timeseries_catchment = pd.read_csv('data/meteorology/eobs/preprocessing/'+variable+\"/\"+variable+\"_\"+catchment+\".csv\", \n",
    "                                               usecols=[0], header=None, names=[\"weighted\"])\n",
    "            timeseries_catchment.index = pd.date_range('01-01-1980', '06-30-2023', freq='D')\n",
    "            timeseries_variables[variable] = timeseries_catchment\n",
    "            \n",
    "        else:\n",
    "            timeseries_catchment = pd.read_csv('data/meteorology/eobs/preprocessing/'+variable+\"/\"+variable+\"_\"+catchment+\".csv\", \n",
    "                                               usecols=[0], header=None, names=[\"weighted\"])\n",
    "            timeseries_catchment.index = pd.date_range('01-01-1950', '06-30-2023', freq='D')\n",
    "            timeseries_variables[variable] = timeseries_catchment\n",
    "    \n",
    "    # Here we rename our columns:\n",
    "    timeseries_variables.columns = [\"p_mean\", \"t_mean\", \"t_min\", \"t_max\", \"sp_min\", \"rh_mean\", \"ws_mean\",\"swr_mean\", \"pet_mean\"]\n",
    "    timeseries_variables = timeseries_variables.round(2)\n",
    "    timeseries_variables.index.name = \"date\"\n",
    "    timeseries_variables.to_csv(PATH_OUTPUT + \"/estreams_meteorology_\"+catchment+\".csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c352df05",
   "metadata": {},
   "source": [
    "## Iceland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first two rows from catchment_boundaries\n",
    "subset_catchment = catchment_boundaries[catchment_boundaries['basin_id'].str.contains('ISGR', case=False)]\n",
    "\n",
    "catchmentnames = subset_catchment.basin_id.tolist()\n",
    "len(catchmentnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eba7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we may organize our data:\n",
    "variables = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet_iceland\"]\n",
    "\n",
    "# The loop goes over each catchment and variable, and make one export per catchment. At the end we will have \n",
    "# 15,047 csv-files each with 9 columns, and one datetype index.\n",
    "for catchment in tqdm.tqdm(catchmentnames):\n",
    "    \n",
    "    timeseries_variables = pd.DataFrame(index=pd.date_range('01-01-1950', '06-30-2023', freq='D'), columns = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet_iceland\"])\n",
    "    \n",
    "    for variable in variables:\n",
    "        \n",
    "        # It may be the case that there is no csv-file for the respective catchment (areas not covered by E-OBS)\n",
    "        # Therefore the try except can deal with this situation\n",
    "        \n",
    "        # Wind speed (fg) has its date range from 1980-2023, while all other variables from 1950-2023. \n",
    "        # Therefore we apoly a if to deal with the situation: \n",
    "        if variable == \"fg\":\n",
    "            timeseries_catchment = pd.read_csv('data/meteorology/eobs/preprocessing/'+variable+\"/\"+variable+\"_\"+catchment+\".csv\", \n",
    "                                               usecols=[0], header=None, names=[\"weighted\"])\n",
    "            timeseries_catchment.index = pd.date_range('01-01-1980', '06-30-2023', freq='D')\n",
    "            timeseries_variables[variable] = timeseries_catchment\n",
    "            \n",
    "        else:\n",
    "            timeseries_catchment = pd.read_csv('data/meteorology/eobs/preprocessing/'+variable+\"/\"+variable+\"_\"+catchment+\".csv\", \n",
    "                                               usecols=[0], header=None, names=[\"weighted\"])\n",
    "            timeseries_catchment.index = pd.date_range('01-01-1950', '06-30-2023', freq='D')\n",
    "            timeseries_variables[variable] = timeseries_catchment\n",
    "    \n",
    "    # Here we rename our columns:\n",
    "    timeseries_variables.columns = [\"p_mean\", \"t_mean\", \"t_min\", \"t_max\", \"sp_min\", \"rh_mean\", \"ws_mean\",\"swr_mean\", \"pet_mean\"]\n",
    "    timeseries_variables = timeseries_variables.round(2)\n",
    "    timeseries_variables.index.name = \"date\"\n",
    "    timeseries_variables.to_csv(PATH_OUTPUT + \"/estreams_meteorology_\"+catchment+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed446c3",
   "metadata": {},
   "source": [
    "# CSV-files for hydro-climatic signatures and indexes  \n",
    "Here instead of individually, we export these variables in three csv-files because this format will be usefull for the streamflow signatures computation. We only export these three files because they are the only used for the signatures and indexes. \n",
    "\n",
    "* estreams_meteorology_precipitation.csv\n",
    "* estreams_meteorology_temperature.csv\n",
    "* estreams_meteorology_pet.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc42044",
   "metadata": {},
   "source": [
    "### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31968129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 33/33 [00:00<00:00, 224.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HUGR019</th>\n",
       "      <th>HUGR020</th>\n",
       "      <th>HUGR021</th>\n",
       "      <th>HUGR022</th>\n",
       "      <th>HUGR023</th>\n",
       "      <th>HUGR024</th>\n",
       "      <th>HUGR025</th>\n",
       "      <th>HUGR026</th>\n",
       "      <th>HUGR027</th>\n",
       "      <th>HUGR028</th>\n",
       "      <th>...</th>\n",
       "      <th>HUGR042</th>\n",
       "      <th>HUGR043</th>\n",
       "      <th>HUGR044</th>\n",
       "      <th>HUGR045</th>\n",
       "      <th>HUGR046</th>\n",
       "      <th>HUGR047</th>\n",
       "      <th>HUGR048</th>\n",
       "      <th>HUGR049</th>\n",
       "      <th>HUGR050</th>\n",
       "      <th>HUGR051</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1950-01-01</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-02</th>\n",
       "      <td>1.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.33</td>\n",
       "      <td>7.84</td>\n",
       "      <td>4.79</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-03</th>\n",
       "      <td>3.88</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.14</td>\n",
       "      <td>2.02</td>\n",
       "      <td>4.15</td>\n",
       "      <td>5.23</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2.60</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0.28</td>\n",
       "      <td>...</td>\n",
       "      <td>2.71</td>\n",
       "      <td>4.10</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.42</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.22</td>\n",
       "      <td>5.90</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-04</th>\n",
       "      <td>3.19</td>\n",
       "      <td>1.95</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.11</td>\n",
       "      <td>6.13</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1.76</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.58</td>\n",
       "      <td>3.02</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.18</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.64</td>\n",
       "      <td>6.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-05</th>\n",
       "      <td>1.20</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5.11</td>\n",
       "      <td>1.14</td>\n",
       "      <td>5.12</td>\n",
       "      <td>2.27</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.76</td>\n",
       "      <td>3.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-26</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-27</th>\n",
       "      <td>4.47</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.73</td>\n",
       "      <td>4.29</td>\n",
       "      <td>2.72</td>\n",
       "      <td>6.20</td>\n",
       "      <td>4.82</td>\n",
       "      <td>5.85</td>\n",
       "      <td>5.80</td>\n",
       "      <td>7.29</td>\n",
       "      <td>...</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.54</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.96</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3.91</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28</th>\n",
       "      <td>2.33</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.77</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.44</td>\n",
       "      <td>...</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.32</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26844 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HUGR019  HUGR020  HUGR021  HUGR022  HUGR023  HUGR024  HUGR025  \\\n",
       "1950-01-01     0.01     0.00     0.00     0.02     0.00     0.00     0.00   \n",
       "1950-01-02     1.79     0.00     7.83     0.33     7.84     4.79     3.95   \n",
       "1950-01-03     3.88     3.00     4.14     2.02     4.15     5.23     4.20   \n",
       "1950-01-04     3.19     1.95     6.12     3.11     6.13     2.61     0.00   \n",
       "1950-01-05     1.20     0.87     5.11     1.14     5.12     2.27     1.99   \n",
       "...             ...      ...      ...      ...      ...      ...      ...   \n",
       "2023-06-26     0.36     0.00     1.04     0.00     1.04     3.16     1.05   \n",
       "2023-06-27     4.47     3.55     2.73     4.29     2.72     6.20     4.82   \n",
       "2023-06-28     2.33     1.32     0.78     2.40     0.77     3.45     2.63   \n",
       "2023-06-29     0.00     0.00     0.68     0.00     0.68     0.00     0.00   \n",
       "2023-06-30     0.00     0.00     6.37     0.00     6.38     0.00     0.00   \n",
       "\n",
       "            HUGR026  HUGR027  HUGR028  ...  HUGR042  HUGR043  HUGR044  \\\n",
       "1950-01-01     0.00     0.00     0.00  ...     0.00     0.00     0.01   \n",
       "1950-01-02     0.22     4.79     0.00  ...     0.00     0.20     1.80   \n",
       "1950-01-03     2.60     6.07     0.28  ...     2.71     4.10     3.88   \n",
       "1950-01-04     0.00     3.92     1.76  ...     2.12     2.58     3.02   \n",
       "1950-01-05     0.38     1.76     3.29  ...     0.80     1.50     1.22   \n",
       "...             ...      ...      ...  ...      ...      ...      ...   \n",
       "2023-06-26     0.00     0.60     0.00  ...     0.00     0.00     0.35   \n",
       "2023-06-27     5.85     5.80     7.29  ...     2.73     3.22     4.54   \n",
       "2023-06-28     1.40     3.32     1.44  ...     1.40     1.26     2.31   \n",
       "2023-06-29     0.00     0.00     0.00  ...     0.00     0.00     0.00   \n",
       "2023-06-30     0.00     0.00     0.00  ...     0.00     0.00     0.00   \n",
       "\n",
       "            HUGR045  HUGR046  HUGR047  HUGR048  HUGR049  HUGR050  HUGR051  \n",
       "1950-01-01     0.00     0.00     0.00     0.02     0.00     0.00     0.00  \n",
       "1950-01-02     0.03     0.03     0.00     0.33     0.25     2.94     0.79  \n",
       "1950-01-03     3.66     3.10     3.42     2.35     3.22     5.90     1.98  \n",
       "1950-01-04     2.58     1.73     2.18     3.12     0.01     3.64     6.31  \n",
       "1950-01-05     1.38     0.98     1.02     1.12     1.31     0.49     3.34  \n",
       "...             ...      ...      ...      ...      ...      ...      ...  \n",
       "2023-06-26     0.00     0.00     0.00     0.00     0.00     0.02     0.22  \n",
       "2023-06-27     3.77     3.80     3.96     4.23     4.26     3.91    13.29  \n",
       "2023-06-28     1.58     1.34     1.32     2.28     1.19     2.14     0.42  \n",
       "2023-06-29     0.00     0.00     0.00     0.00     0.00     0.00     0.00  \n",
       "2023-06-30     0.00     0.00     0.00     0.00     0.00     0.00     7.08  \n",
       "\n",
       "[26844 rows x 33 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = glob.glob(PATH_preprocessing+\"rr/\" +  \"/*.csv\")\n",
    "len(filenames)\n",
    "\n",
    "timeseries_p = pd.DataFrame(index=pd.date_range('01-01-1950', '06-30-2023', freq='D'))\n",
    "\n",
    "for filename in tqdm.tqdm(filenames):\n",
    "\n",
    "    catchmentname = os.path.basename(filename)\n",
    "    catchmentname = catchmentname.split(\"_\", 1)[1]\n",
    "    catchmentname = catchmentname.replace(\".csv\", \"\")\n",
    "\n",
    "    timeseries_catchment = pd.read_csv(filename, usecols=[0], header=None, names=[\"weighted\"])\n",
    "    timeseries_catchment.index = pd.date_range('01-01-1950', '06-30-2023', freq='D')\n",
    "\n",
    "    catchment_values = timeseries_catchment[\"weighted\"].values\n",
    "    \n",
    "    timeseries_p[str(catchmentname)+\"a\"] = catchment_values\n",
    "\n",
    "# The only way this code worked was after the addition of \"a\", then now we must delete it:    \n",
    "timeseries_p.columns = timeseries_p.columns.str.replace(\"a\", \"\")\n",
    "timeseries_p = timeseries_p.round(2)\n",
    "timeseries_p = timeseries_p.sort_index(axis=1)\n",
    "\n",
    "# Save the data:\n",
    "# Export the final dataset:\n",
    "timeseries_p.to_csv(PATH_OUTPUT_2 + \"/estreams_meteorology_precipitation.csv\")\n",
    "\n",
    "# Check it out:\n",
    "timeseries_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83f5787",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcc8b678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 33/33 [00:00<00:00, 222.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HUGR019</th>\n",
       "      <th>HUGR020</th>\n",
       "      <th>HUGR021</th>\n",
       "      <th>HUGR022</th>\n",
       "      <th>HUGR023</th>\n",
       "      <th>HUGR024</th>\n",
       "      <th>HUGR025</th>\n",
       "      <th>HUGR026</th>\n",
       "      <th>HUGR027</th>\n",
       "      <th>HUGR028</th>\n",
       "      <th>...</th>\n",
       "      <th>HUGR042</th>\n",
       "      <th>HUGR043</th>\n",
       "      <th>HUGR044</th>\n",
       "      <th>HUGR045</th>\n",
       "      <th>HUGR046</th>\n",
       "      <th>HUGR047</th>\n",
       "      <th>HUGR048</th>\n",
       "      <th>HUGR049</th>\n",
       "      <th>HUGR050</th>\n",
       "      <th>HUGR051</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1950-01-01</th>\n",
       "      <td>-9.44</td>\n",
       "      <td>-6.83</td>\n",
       "      <td>-5.54</td>\n",
       "      <td>-11.11</td>\n",
       "      <td>-5.54</td>\n",
       "      <td>-7.04</td>\n",
       "      <td>-4.91</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>-8.87</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.74</td>\n",
       "      <td>-7.61</td>\n",
       "      <td>-9.25</td>\n",
       "      <td>-8.95</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>-7.29</td>\n",
       "      <td>-10.71</td>\n",
       "      <td>-5.74</td>\n",
       "      <td>-8.92</td>\n",
       "      <td>-5.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-02</th>\n",
       "      <td>-5.63</td>\n",
       "      <td>-4.31</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>-5.91</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>-5.13</td>\n",
       "      <td>-3.59</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>-6.02</td>\n",
       "      <td>-3.03</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.52</td>\n",
       "      <td>-4.48</td>\n",
       "      <td>-5.53</td>\n",
       "      <td>-5.31</td>\n",
       "      <td>-4.28</td>\n",
       "      <td>-4.38</td>\n",
       "      <td>-5.78</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>-5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-03</th>\n",
       "      <td>-3.11</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-4.04</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-3.26</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-2.92</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>-1.83</td>\n",
       "      <td>-2.07</td>\n",
       "      <td>-3.76</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>-0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-04</th>\n",
       "      <td>-4.01</td>\n",
       "      <td>-2.64</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-4.58</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-4.70</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.72</td>\n",
       "      <td>-2.97</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>-4.30</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>-4.39</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-4.01</td>\n",
       "      <td>-2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-05</th>\n",
       "      <td>-7.07</td>\n",
       "      <td>-4.53</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>-7.84</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>-5.54</td>\n",
       "      <td>-3.01</td>\n",
       "      <td>-2.65</td>\n",
       "      <td>-7.24</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.47</td>\n",
       "      <td>-5.43</td>\n",
       "      <td>-6.90</td>\n",
       "      <td>-6.27</td>\n",
       "      <td>-4.72</td>\n",
       "      <td>-4.85</td>\n",
       "      <td>-7.59</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>-7.39</td>\n",
       "      <td>-3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-26</th>\n",
       "      <td>19.31</td>\n",
       "      <td>20.51</td>\n",
       "      <td>20.38</td>\n",
       "      <td>18.17</td>\n",
       "      <td>20.38</td>\n",
       "      <td>19.55</td>\n",
       "      <td>20.95</td>\n",
       "      <td>22.21</td>\n",
       "      <td>19.03</td>\n",
       "      <td>21.44</td>\n",
       "      <td>...</td>\n",
       "      <td>20.40</td>\n",
       "      <td>21.19</td>\n",
       "      <td>19.45</td>\n",
       "      <td>19.48</td>\n",
       "      <td>20.58</td>\n",
       "      <td>20.32</td>\n",
       "      <td>18.52</td>\n",
       "      <td>22.00</td>\n",
       "      <td>19.80</td>\n",
       "      <td>18.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-27</th>\n",
       "      <td>17.51</td>\n",
       "      <td>20.42</td>\n",
       "      <td>17.93</td>\n",
       "      <td>17.49</td>\n",
       "      <td>17.92</td>\n",
       "      <td>16.85</td>\n",
       "      <td>19.22</td>\n",
       "      <td>21.24</td>\n",
       "      <td>15.42</td>\n",
       "      <td>20.92</td>\n",
       "      <td>...</td>\n",
       "      <td>20.37</td>\n",
       "      <td>20.20</td>\n",
       "      <td>17.63</td>\n",
       "      <td>19.14</td>\n",
       "      <td>20.34</td>\n",
       "      <td>20.19</td>\n",
       "      <td>17.80</td>\n",
       "      <td>21.10</td>\n",
       "      <td>16.78</td>\n",
       "      <td>17.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28</th>\n",
       "      <td>14.83</td>\n",
       "      <td>17.13</td>\n",
       "      <td>15.63</td>\n",
       "      <td>14.27</td>\n",
       "      <td>15.63</td>\n",
       "      <td>14.66</td>\n",
       "      <td>16.74</td>\n",
       "      <td>18.77</td>\n",
       "      <td>13.65</td>\n",
       "      <td>18.59</td>\n",
       "      <td>...</td>\n",
       "      <td>17.00</td>\n",
       "      <td>17.25</td>\n",
       "      <td>14.98</td>\n",
       "      <td>15.53</td>\n",
       "      <td>17.12</td>\n",
       "      <td>16.91</td>\n",
       "      <td>14.57</td>\n",
       "      <td>18.88</td>\n",
       "      <td>14.60</td>\n",
       "      <td>14.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29</th>\n",
       "      <td>15.91</td>\n",
       "      <td>16.71</td>\n",
       "      <td>17.82</td>\n",
       "      <td>14.27</td>\n",
       "      <td>17.81</td>\n",
       "      <td>17.54</td>\n",
       "      <td>18.61</td>\n",
       "      <td>19.04</td>\n",
       "      <td>16.69</td>\n",
       "      <td>19.34</td>\n",
       "      <td>...</td>\n",
       "      <td>16.48</td>\n",
       "      <td>17.18</td>\n",
       "      <td>16.06</td>\n",
       "      <td>15.50</td>\n",
       "      <td>16.74</td>\n",
       "      <td>16.61</td>\n",
       "      <td>14.61</td>\n",
       "      <td>18.12</td>\n",
       "      <td>16.75</td>\n",
       "      <td>15.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>18.59</td>\n",
       "      <td>19.03</td>\n",
       "      <td>18.67</td>\n",
       "      <td>17.45</td>\n",
       "      <td>18.66</td>\n",
       "      <td>18.31</td>\n",
       "      <td>20.21</td>\n",
       "      <td>21.17</td>\n",
       "      <td>18.00</td>\n",
       "      <td>21.34</td>\n",
       "      <td>...</td>\n",
       "      <td>18.79</td>\n",
       "      <td>19.97</td>\n",
       "      <td>18.70</td>\n",
       "      <td>18.10</td>\n",
       "      <td>19.13</td>\n",
       "      <td>18.95</td>\n",
       "      <td>17.76</td>\n",
       "      <td>20.66</td>\n",
       "      <td>19.65</td>\n",
       "      <td>18.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26844 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HUGR019  HUGR020  HUGR021  HUGR022  HUGR023  HUGR024  HUGR025  \\\n",
       "1950-01-01    -9.44    -6.83    -5.54   -11.11    -5.54    -7.04    -4.91   \n",
       "1950-01-02    -5.63    -4.31    -3.12    -5.91    -3.12    -5.13    -3.59   \n",
       "1950-01-03    -3.11    -1.94     0.64    -4.04     0.64    -1.13     1.10   \n",
       "1950-01-04    -4.01    -2.64    -1.09    -4.58    -1.09    -3.12    -0.73   \n",
       "1950-01-05    -7.07    -4.53    -1.79    -7.84    -1.79    -5.54    -3.01   \n",
       "...             ...      ...      ...      ...      ...      ...      ...   \n",
       "2023-06-26    19.31    20.51    20.38    18.17    20.38    19.55    20.95   \n",
       "2023-06-27    17.51    20.42    17.93    17.49    17.92    16.85    19.22   \n",
       "2023-06-28    14.83    17.13    15.63    14.27    15.63    14.66    16.74   \n",
       "2023-06-29    15.91    16.71    17.82    14.27    17.81    17.54    18.61   \n",
       "2023-06-30    18.59    19.03    18.67    17.45    18.66    18.31    20.21   \n",
       "\n",
       "            HUGR026  HUGR027  HUGR028  ...  HUGR042  HUGR043  HUGR044  \\\n",
       "1950-01-01    -4.80    -8.87    -3.28  ...    -6.74    -7.61    -9.25   \n",
       "1950-01-02    -2.27    -6.02    -3.03  ...    -4.52    -4.48    -5.53   \n",
       "1950-01-03     0.94    -3.26     2.03  ...    -2.21    -1.39    -2.92   \n",
       "1950-01-04     0.17    -4.70     0.80  ...    -2.72    -2.97    -3.86   \n",
       "1950-01-05    -2.65    -7.24    -2.67  ...    -4.47    -5.43    -6.90   \n",
       "...             ...      ...      ...  ...      ...      ...      ...   \n",
       "2023-06-26    22.21    19.03    21.44  ...    20.40    21.19    19.45   \n",
       "2023-06-27    21.24    15.42    20.92  ...    20.37    20.20    17.63   \n",
       "2023-06-28    18.77    13.65    18.59  ...    17.00    17.25    14.98   \n",
       "2023-06-29    19.04    16.69    19.34  ...    16.48    17.18    16.06   \n",
       "2023-06-30    21.17    18.00    21.34  ...    18.79    19.97    18.70   \n",
       "\n",
       "            HUGR045  HUGR046  HUGR047  HUGR048  HUGR049  HUGR050  HUGR051  \n",
       "1950-01-01    -8.95    -7.00    -7.29   -10.71    -5.74    -8.92    -5.45  \n",
       "1950-01-02    -5.31    -4.28    -4.38    -5.78    -3.24    -5.92    -5.47  \n",
       "1950-01-03    -3.16    -1.83    -2.07    -3.76    -0.09    -3.35    -0.86  \n",
       "1950-01-04    -4.30    -2.67    -2.99    -4.39    -1.34    -4.01    -2.49  \n",
       "1950-01-05    -6.27    -4.72    -4.85    -7.59    -4.17    -7.39    -3.87  \n",
       "...             ...      ...      ...      ...      ...      ...      ...  \n",
       "2023-06-26    19.48    20.58    20.32    18.52    22.00    19.80    18.62  \n",
       "2023-06-27    19.14    20.34    20.19    17.80    21.10    16.78    17.46  \n",
       "2023-06-28    15.53    17.12    16.91    14.57    18.88    14.60    14.35  \n",
       "2023-06-29    15.50    16.74    16.61    14.61    18.12    16.75    15.73  \n",
       "2023-06-30    18.10    19.13    18.95    17.76    20.66    19.65    18.21  \n",
       "\n",
       "[26844 rows x 33 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = glob.glob(PATH_preprocessing+\"tg/\" +  \"/*.csv\")\n",
    "len(filenames)\n",
    "\n",
    "timeseries_tmean = pd.DataFrame(index=pd.date_range('01-01-1950', '06-30-2023', freq='D'))\n",
    "\n",
    "for filename in tqdm.tqdm(filenames):\n",
    "\n",
    "    catchmentname = os.path.basename(filename)\n",
    "    catchmentname = catchmentname.split(\"_\", 1)[1]\n",
    "    catchmentname = catchmentname.replace(\".csv\", \"\")\n",
    "\n",
    "    timeseries_catchment = pd.read_csv(filename, usecols=[0], header=None, names=[\"weighted\"])\n",
    "    timeseries_catchment.index = pd.date_range('01-01-1950', '06-30-2023', freq='D')\n",
    "\n",
    "    catchment_values = timeseries_catchment[\"weighted\"].values\n",
    "    \n",
    "    timeseries_tmean[str(catchmentname)+\"a\"] = catchment_values\n",
    "\n",
    "# The only way this code worked was after the addition of \"a\", then now we must delete it:    \n",
    "timeseries_tmean.columns = timeseries_tmean.columns.str.replace(\"a\", \"\")\n",
    "timeseries_tmean = timeseries_tmean.round(2)\n",
    "timeseries_tmean = timeseries_tmean.sort_index(axis=1)\n",
    "\n",
    "# Save the data:\n",
    "# Export the final dataset:\n",
    "timeseries_tmean.to_csv(PATH_OUTPUT_2 + \"/estreams_meteorology_temperature.csv\")\n",
    "\n",
    "# Check it out:\n",
    "timeseries_tmean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc43c73",
   "metadata": {},
   "source": [
    "### Potential evapotranspiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cd486d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 33/33 [00:00<00:00, 221.72it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HUGR019</th>\n",
       "      <th>HUGR020</th>\n",
       "      <th>HUGR021</th>\n",
       "      <th>HUGR022</th>\n",
       "      <th>HUGR023</th>\n",
       "      <th>HUGR024</th>\n",
       "      <th>HUGR025</th>\n",
       "      <th>HUGR026</th>\n",
       "      <th>HUGR027</th>\n",
       "      <th>HUGR028</th>\n",
       "      <th>...</th>\n",
       "      <th>HUGR042</th>\n",
       "      <th>HUGR043</th>\n",
       "      <th>HUGR044</th>\n",
       "      <th>HUGR045</th>\n",
       "      <th>HUGR046</th>\n",
       "      <th>HUGR047</th>\n",
       "      <th>HUGR048</th>\n",
       "      <th>HUGR049</th>\n",
       "      <th>HUGR050</th>\n",
       "      <th>HUGR051</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1950-01-01</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-02</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-03</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-04</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-05</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-26</th>\n",
       "      <td>5.00</td>\n",
       "      <td>5.22</td>\n",
       "      <td>5.91</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.37</td>\n",
       "      <td>5.82</td>\n",
       "      <td>6.04</td>\n",
       "      <td>4.97</td>\n",
       "      <td>5.78</td>\n",
       "      <td>...</td>\n",
       "      <td>5.15</td>\n",
       "      <td>5.37</td>\n",
       "      <td>5.04</td>\n",
       "      <td>4.89</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.14</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-27</th>\n",
       "      <td>4.33</td>\n",
       "      <td>5.40</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.59</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.44</td>\n",
       "      <td>5.24</td>\n",
       "      <td>3.65</td>\n",
       "      <td>4.28</td>\n",
       "      <td>...</td>\n",
       "      <td>5.47</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.96</td>\n",
       "      <td>5.30</td>\n",
       "      <td>5.28</td>\n",
       "      <td>4.61</td>\n",
       "      <td>5.22</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28</th>\n",
       "      <td>3.73</td>\n",
       "      <td>3.88</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.49</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.41</td>\n",
       "      <td>3.73</td>\n",
       "      <td>4.18</td>\n",
       "      <td>...</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.53</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29</th>\n",
       "      <td>4.38</td>\n",
       "      <td>4.97</td>\n",
       "      <td>5.48</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.48</td>\n",
       "      <td>4.89</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.42</td>\n",
       "      <td>4.32</td>\n",
       "      <td>5.40</td>\n",
       "      <td>...</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.21</td>\n",
       "      <td>5.23</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>5.26</td>\n",
       "      <td>5.77</td>\n",
       "      <td>4.89</td>\n",
       "      <td>5.04</td>\n",
       "      <td>4.89</td>\n",
       "      <td>5.50</td>\n",
       "      <td>6.07</td>\n",
       "      <td>6.28</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.96</td>\n",
       "      <td>...</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.81</td>\n",
       "      <td>5.30</td>\n",
       "      <td>5.41</td>\n",
       "      <td>5.76</td>\n",
       "      <td>5.71</td>\n",
       "      <td>5.13</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.28</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26844 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HUGR019  HUGR020  HUGR021  HUGR022  HUGR023  HUGR024  HUGR025  \\\n",
       "1950-01-01     0.15     0.23     0.25     0.12     0.25     0.19     0.21   \n",
       "1950-01-02     0.30     0.39     0.40     0.32     0.40     0.28     0.34   \n",
       "1950-01-03     0.24     0.34     0.33     0.26     0.33     0.25     0.32   \n",
       "1950-01-04     0.27     0.30     0.25     0.26     0.25     0.26     0.31   \n",
       "1950-01-05     0.25     0.33     0.29     0.26     0.29     0.21     0.24   \n",
       "...             ...      ...      ...      ...      ...      ...      ...   \n",
       "2023-06-26     5.00     5.22     5.91     4.71     5.91     5.37     5.82   \n",
       "2023-06-27     4.33     5.40     3.98     4.59     3.98     4.00     4.44   \n",
       "2023-06-28     3.73     3.88     4.18     3.49     4.18     3.97     4.28   \n",
       "2023-06-29     4.38     4.97     5.48     4.14     5.48     4.89     5.33   \n",
       "2023-06-30     5.26     5.77     4.89     5.04     4.89     5.50     6.07   \n",
       "\n",
       "            HUGR026  HUGR027  HUGR028  ...  HUGR042  HUGR043  HUGR044  \\\n",
       "1950-01-01     0.23     0.15     0.31  ...     0.24     0.19     0.16   \n",
       "1950-01-02     0.40     0.26     0.44  ...     0.39     0.36     0.30   \n",
       "1950-01-03     0.36     0.19     0.53  ...     0.34     0.32     0.25   \n",
       "1950-01-04     0.33     0.23     0.43  ...     0.31     0.28     0.27   \n",
       "1950-01-05     0.27     0.20     0.36  ...     0.34     0.29     0.25   \n",
       "...             ...      ...      ...  ...      ...      ...      ...   \n",
       "2023-06-26     6.04     4.97     5.78  ...     5.15     5.37     5.04   \n",
       "2023-06-27     5.24     3.65     4.28  ...     5.47     4.96     4.35   \n",
       "2023-06-28     4.41     3.73     4.18  ...     3.84     3.94     3.76   \n",
       "2023-06-29     5.42     4.32     5.40  ...     4.97     4.87     4.43   \n",
       "2023-06-30     6.28     5.04     5.96  ...     5.75     5.81     5.30   \n",
       "\n",
       "            HUGR045  HUGR046  HUGR047  HUGR048  HUGR049  HUGR050  HUGR051  \n",
       "1950-01-01     0.17     0.22     0.21     0.13     0.23     0.16     0.30  \n",
       "1950-01-02     0.35     0.38     0.38     0.32     0.40     0.26     0.37  \n",
       "1950-01-03     0.29     0.33     0.33     0.26     0.34     0.20     0.45  \n",
       "1950-01-04     0.25     0.29     0.29     0.26     0.29     0.28     0.34  \n",
       "1950-01-05     0.29     0.32     0.32     0.27     0.28     0.21     0.33  \n",
       "...             ...      ...      ...      ...      ...      ...      ...  \n",
       "2023-06-26     4.89     5.25     5.14     4.79     5.67     5.05     5.37  \n",
       "2023-06-27     4.96     5.30     5.28     4.61     5.22     4.03     3.96  \n",
       "2023-06-28     3.61     3.90     3.85     3.53     4.26     3.83     3.72  \n",
       "2023-06-29     4.50     4.94     4.87     4.21     5.23     4.33     5.01  \n",
       "2023-06-30     5.41     5.76     5.71     5.13     6.02     5.28     5.08  \n",
       "\n",
       "[26844 rows x 33 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the general catchments:\n",
    "filenames = glob.glob(PATH_preprocessing+\"pet/\" +  \"/*.csv\")\n",
    "\n",
    "timeseries_pet = pd.DataFrame(index=pd.date_range('01-01-1950', '06-30-2023', freq='D'))\n",
    "\n",
    "for filename in tqdm.tqdm(filenames):\n",
    "\n",
    "    catchmentname = os.path.basename(filename)\n",
    "    catchmentname = catchmentname.split(\"_\", 1)[1]\n",
    "    catchmentname = catchmentname.replace(\".csv\", \"\")\n",
    "\n",
    "    timeseries_catchment = pd.read_csv(filename, usecols=[0], header=None, names=[\"weighted\"])\n",
    "    timeseries_catchment.index = pd.date_range('01-01-1950', '06-30-2023', freq='D')\n",
    "\n",
    "    catchment_values = timeseries_catchment[\"weighted\"].values\n",
    "    \n",
    "    timeseries_pet[str(catchmentname)+\"a\"] = catchment_values\n",
    "\n",
    "# For the catchments in Iceland:\n",
    "filenames_iceland = glob.glob(PATH_preprocessing+\"pet_iceland/\" +  \"/*.csv\")\n",
    "\n",
    "timeseries_pet_iceland = pd.DataFrame(index=pd.date_range('01-01-1950', '06-30-2023', freq='D'))\n",
    "\n",
    "for filename in tqdm.tqdm(filenames_iceland):\n",
    "\n",
    "    catchmentname = os.path.basename(filename)\n",
    "    catchmentname = catchmentname.split(\"_\", 2)[2]\n",
    "    catchmentname = catchmentname.replace(\".csv\", \"\")\n",
    "\n",
    "    timeseries_catchment = pd.read_csv(filename, usecols=[0], header=None, names=[\"weighted\"])\n",
    "    timeseries_catchment.index = pd.date_range('01-01-1950', '06-30-2023', freq='D')\n",
    "\n",
    "    catchment_values = timeseries_catchment[\"weighted\"].values\n",
    "    \n",
    "    timeseries_pet_iceland[str(catchmentname)+\"a\"] = catchment_values\n",
    "\n",
    "\n",
    "timeseries_pet = pd.concat([timeseries_pet, timeseries_pet_iceland], axis=1)\n",
    "    \n",
    "# The only way this code worked was after the addition of \"a\", then now we must delete it:    \n",
    "timeseries_pet.columns = timeseries_pet.columns.str.replace(\"a\", \"\")\n",
    "timeseries_pet = timeseries_pet.round(2)\n",
    "timeseries_pet = timeseries_pet.sort_index(axis=1)\n",
    "\n",
    "# Save the data:\n",
    "# Export the final dataset:\n",
    "timeseries_pet.to_csv(PATH_OUTPUT_2 + \"/estreams_meteorology_pet.csv\")\n",
    "\n",
    "# Check it out:\n",
    "timeseries_pet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3890db",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
