{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9429523",
   "metadata": {},
   "source": [
    "# Meteorological time-series extraction: Part B\n",
    "\n",
    "Author: Thiago Nascimento (thiago.nascimento@eawag.ch)\n",
    "\n",
    "This notebook is part of the EStreams publication and was used to extract and aggregate the meteorological time-series from the E-OBS dataset. At Part B we extract the data from the nc-files and export as individual intermediate files.  \n",
    "\n",
    "* Note that this code enables not only the replicability of the current database but also the extrapolation to new catchment areas. \n",
    "* Additionally, the user should download and insert the original raw-data in the folder of the same name prior to run this code. \n",
    "* The original third-party data used were not made available in this repository due to redistribution and storage-space reasons.  \n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "\n",
    "* Python>=3.6\n",
    "* Jupyter\n",
    "* geopandas=0.10.2\n",
    "* glob\n",
    "* netCDF4\n",
    "* numpy\n",
    "* os\n",
    "* pandas\n",
    "* tqdm\n",
    "* concurrent\n",
    "\n",
    "Check the Github repository for an environment.yml (for conda environments) or requirements.txt (pip) file.\n",
    "\n",
    "**Files:**\n",
    "\n",
    "* data/shapefiles/estreams_catchments.shp\n",
    "* meteorology/eobs/{rr, tg, tn, tx, pp, hu, fg, qq}_ens_mean_0.25deg_reg_v27.0e.nc   https://www.ecad.eu/download/ensembles/download.php (Last access: 27 November 2023)\n",
    "* meteorology/eobs/pet_hargreaves_025deg_v280e.nc. Derived hargreaves daily potential evapotranspiration. https://github.com/pyet-org/pyet Last access: 27 November 2023)\n",
    "* In the output directory it is important to have one folder for each variable to be exported.\n",
    "\n",
    "**Directory:**\n",
    "\n",
    "* Clone the GitHub directory locally\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. \n",
    "\n",
    "## References\n",
    "\n",
    "* Cornes, R., G. van der Schrier, E.J.M. van den Besselaar, and P.D. Jones. 2018: An Ensemble Version of the E-OBS Temperature and Precipitation Datasets, J. Geophys. Res. Atmos., 123. doi:10.1029/2017JD028200\n",
    "\n",
    "## Licenses\n",
    "* EOBS: \"The ECA&D data policy applies. These observational data are strictly for use in non-commercial research and non-commercial education projects only. Scientific results based on these data must be submitted for publication in the open literature without any delay linked to commercial objectives\" https://www.ecad.eu/download/ensembles/download.php#guidance (Last access: 27 November 2023)\n",
    "\n",
    "## Observations\n",
    "#### E-OBS filenames\n",
    "\n",
    "* rr = Total daily precipitation\n",
    "* tg = Mean daily temperature\n",
    "* tn = Minimum daily temperature\n",
    "* tx = Maximum daily temperature\n",
    "* pp = Mean daily air pressure at sea level\n",
    "* hu = Mean daily relative humidity\n",
    "* fg = Mean wind speed at 10-meters\n",
    "* qq = Total daily global radiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395ba82c",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tqdm\n",
    "import time\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from utils.meteorology import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f5a4e8",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variables:\n",
    "# Relative path to your local directory\n",
    "PATH = \"../../..\"\n",
    "# Set the number of workers for parallel processing\n",
    "num_workers = 5\n",
    "\n",
    "# Chunk size for reading NetCDF data\n",
    "chunk_size = 100  # Adjust this value based on your available memory\n",
    "\n",
    "# Choose the variable\n",
    "chosen_variable = \"pet\"  # Variable to be processed [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet\", \"pet_iceland\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656bdd51",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f300d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-editable variables:\n",
    "PATH_preprocessing = \"data/meteorology/eobs/preprocessing/\"\n",
    "PATH_netcdfs = \"data/meteorology/eobs/\"\n",
    "PATH_OUTPUT = \"results/timeseries/meteorology/catchments\"\n",
    "PATH_OUTPUT_2 = \"results/timeseries/meteorology\"\n",
    "PATH_shapefile = \"data/shapefiles/estreams_catchments.shp\"\n",
    "variables = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet\", \"pet_iceland\"] # Eobs variables\n",
    "\n",
    "# Set the directory:\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896190fa",
   "metadata": {},
   "source": [
    "# Import data\n",
    "## Catchment boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ab7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_boundaries = gpd.read_file(PATH_shapefile)\n",
    "catchment_boundaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The total number of catchments to be processed are:\", len(catchment_boundaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e78cf",
   "metadata": {},
   "source": [
    "# Reproject to WGS-84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284610e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CRS of the shapefile's geometry to EPSG:4326 (WGS 84)\n",
    "catchment_boundaries[\"geometry\"] = catchment_boundaries[\"geometry\"].to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f253c199",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d5b80",
   "metadata": {},
   "source": [
    "## Variable to be processed\n",
    "* Due to processing reasons PET for Iceland is stored in a different netcdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map variables to their corresponding file names\n",
    "variable_file_mapping = {\n",
    "    \"rr\": \"rr_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"tg\": \"tg_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"tn\": \"tn_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"tx\": \"tx_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"pp\": \"pp_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"hu\": \"hu_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"fg\": \"fg_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"qq\": \"qq_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"pet\": \"pet_hargreaves_025deg_v280e.nc\",\n",
    "    \"pet_iceland\": \"pet_hargreaves_iceland_025deg_v280e.nc\"\n",
    "}\n",
    "\n",
    "# Create a dictionary to map variables to their corresponding variable names\n",
    "variable_name_mapping = {\n",
    "    \"rr\": \"rr\",\n",
    "    \"tg\": \"tg\",\n",
    "    \"tn\": \"tn\",\n",
    "    \"tx\": \"tx\",\n",
    "    \"pp\": \"pp\",\n",
    "    \"hu\": \"hu\",\n",
    "    \"fg\": \"fg\",\n",
    "    \"qq\": \"qq\",\n",
    "    \"pet\": \"Hargreaves\",\n",
    "    \"pet_iceland\": \"Hargreaves\"\n",
    "\n",
    "}\n",
    "\n",
    "# Get the file name for the chosen variable\n",
    "nc_file = variable_file_mapping.get(chosen_variable)\n",
    "nc_variable_name = variable_name_mapping.get(chosen_variable)\n",
    "\n",
    "if nc_file is not None:\n",
    "    # Generate variable_name and path_preprocessing based on the chosen variable\n",
    "    variable_name = nc_variable_name\n",
    "    path_preprocessing = PATH_preprocessing + chosen_variable + \"/\"\n",
    "\n",
    "    # Read NetCDF data\n",
    "    with nc.Dataset(PATH_netcdfs + nc_file, mode='r', format='NETCDF4') as nc_dataset:\n",
    "        latitude = nc_dataset[\"latitude\"][:]\n",
    "        longitude = nc_dataset[\"longitude\"][:]\n",
    "        values = nc_dataset[variable_name][:]\n",
    "\n",
    "    # Print variables for checking\n",
    "    print(f\"Variables in NetCDF file for {chosen_variable}: {nc_dataset.variables.keys()}\")\n",
    "else:\n",
    "    print(\"Invalid variable choice.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518d51c",
   "metadata": {},
   "source": [
    "## Calculate pixels extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fbe5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pixel extents using vectorized operations\n",
    "lon_idx, lat_idx = np.meshgrid(range(len(longitude)), range(len(latitude)))\n",
    "pixel_extents = np.stack(\n",
    "    (longitude[lon_idx], latitude[lat_idx], longitude[lon_idx] + 0.25, latitude[lat_idx] + 0.25),\n",
    "    axis=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c459d8",
   "metadata": {},
   "source": [
    "## Extract catchment names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c94ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract catchment names. \n",
    "if chosen_variable == \"pet_iceland\":\n",
    "    # Extract catchment names for Iceland \n",
    "    desired_substring = 'ISGR'\n",
    "    subset_catchment = catchment_boundaries[catchment_boundaries['basin_id'].str.contains(desired_substring)]\n",
    "    catchmentnames = subset_catchment.basin_id.tolist()\n",
    "else:\n",
    "    catchmentnames = catchment_boundaries.basin_id.tolist()\n",
    "\n",
    "catchmentnames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1439a082",
   "metadata": {},
   "source": [
    "## Parallel processing of the catchment polygons\n",
    "* This process may take a while deoending on the used machine and configurations adopted\n",
    "* The output of this phase is the export of individual CSV-files for each catchment for each variable.\n",
    "* The data will be later concatenate together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108e467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    futures = [executor.submit(process_catchment, catchmentname, catchment_boundaries, values, latitude, longitude, path_preprocessing, variable_name = chosen_variable)\n",
    "               for catchmentname in tqdm.tqdm(catchmentnames)]\n",
    "    \n",
    "    # Wait for all futures to complete\n",
    "    for future in futures:\n",
    "        future.result()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Total time:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3890db",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
