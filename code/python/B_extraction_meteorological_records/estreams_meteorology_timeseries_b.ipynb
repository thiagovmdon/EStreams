{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9429523",
   "metadata": {},
   "source": [
    "# Meteorological time-series extraction: Part B\n",
    "\n",
    "Author: Thiago Nascimento (thiago.nascimento@eawag.ch)\n",
    "\n",
    "This notebook is part of the EStreams publication and was used to extract and aggregate the meteorological time-series from the E-OBS dataset. At Part B we extract the data from the nc-files and export as individual intermediate files.  \n",
    "\n",
    "* Note that this code enables not only the replicability of the current database but also the extrapolation to new catchment areas. \n",
    "* Additionally, the user should download and insert the original raw-data in the folder of the same name prior to run this code. \n",
    "* The original third-party data used were not made available in this repository due to redistribution and storage-space reasons.  \n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "\n",
    "* Python>=3.6\n",
    "* Jupyter\n",
    "* geopandas=0.10.2\n",
    "* glob\n",
    "* netCDF4\n",
    "* numpy\n",
    "* os\n",
    "* pandas\n",
    "* tqdm\n",
    "* concurrent\n",
    "\n",
    "Check the Github repository for an environment.yml (for conda environments) or requirements.txt (pip) file.\n",
    "\n",
    "**Files:**\n",
    "\n",
    "* data/shapefiles/estreams_catchments.shp\n",
    "* meteorology/eobs/{rr, tg, tn, tx, pp, hu, fg, qq}_ens_mean_0.25deg_reg_v27.0e.nc   https://www.ecad.eu/download/ensembles/download.php (Last access: 27 November 2023)\n",
    "* meteorology/eobs/pet_hargreaves_025deg_v280e.nc. Derived hargreaves daily potential evapotranspiration. https://github.com/pyet-org/pyet Last access: 27 November 2023)\n",
    "* In the output directory it is important to have one folder for each variable to be exported.\n",
    "\n",
    "**Directory:**\n",
    "\n",
    "* Clone the GitHub directory locally\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. \n",
    "\n",
    "## References\n",
    "\n",
    "* Cornes, R., G. van der Schrier, E.J.M. van den Besselaar, and P.D. Jones. 2018: An Ensemble Version of the E-OBS Temperature and Precipitation Datasets, J. Geophys. Res. Atmos., 123. doi:10.1029/2017JD028200\n",
    "\n",
    "## Licenses\n",
    "* EOBS: \"The ECA&D data policy applies. These observational data are strictly for use in non-commercial research and non-commercial education projects only. Scientific results based on these data must be submitted for publication in the open literature without any delay linked to commercial objectives\" https://www.ecad.eu/download/ensembles/download.php#guidance (Last access: 27 November 2023)\n",
    "\n",
    "## Observations\n",
    "#### E-OBS filenames\n",
    "\n",
    "* rr = Total daily precipitation\n",
    "* tg = Mean daily temperature\n",
    "* tn = Minimum daily temperature\n",
    "* tx = Maximum daily temperature\n",
    "* pp = Mean daily air pressure at sea level\n",
    "* hu = Mean daily relative humidity\n",
    "* fg = Mean wind speed at 10-meters\n",
    "* qq = Total daily global radiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395ba82c",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ad4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tqdm\n",
    "import time\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from utils.meteorology import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f5a4e8",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4d9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variables:\n",
    "# Relative path to your local directory\n",
    "PATH = \"../../..\"\n",
    "# Set the number of workers for parallel processing\n",
    "num_workers = 5\n",
    "\n",
    "# Chunk size for reading NetCDF data\n",
    "chunk_size = 100  # Adjust this value based on your available memory\n",
    "\n",
    "# Choose the variable\n",
    "chosen_variable = \"pet\"  # Variable to be processed [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet\", \"pet_iceland\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656bdd51",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f300d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-editable variables:\n",
    "PATH_preprocessing = \"data/meteorology/eobs/preprocessing/\"\n",
    "PATH_netcdfs = \"data/meteorology/eobs/\"\n",
    "PATH_OUTPUT = \"results/timeseries/meteorology/catchments\"\n",
    "PATH_OUTPUT_2 = \"results/timeseries/meteorology\"\n",
    "PATH_shapefile = \"data/shapefiles/estreams_catchments.shp\"\n",
    "variables = [\"rr\", \"tg\", \"tn\", \"tx\", \"pp\", \"hu\", \"fg\", \"qq\", \"pet\", \"pet_iceland\"] # Eobs variables\n",
    "\n",
    "# Set the directory:\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896190fa",
   "metadata": {},
   "source": [
    "# Import data\n",
    "## Catchment boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409ab7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>area_km2</th>\n",
       "      <th>outlet_lat</th>\n",
       "      <th>outlet_lng</th>\n",
       "      <th>name</th>\n",
       "      <th>area_offic</th>\n",
       "      <th>layer</th>\n",
       "      <th>path</th>\n",
       "      <th>area_diff</th>\n",
       "      <th>area_calc</th>\n",
       "      <th>basin_id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HUGR020</td>\n",
       "      <td>9,600</td>\n",
       "      <td>46.785</td>\n",
       "      <td>21.142</td>\n",
       "      <td>6444410</td>\n",
       "      <td>9011</td>\n",
       "      <td>HUGR020</td>\n",
       "      <td>C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...</td>\n",
       "      <td>6.536</td>\n",
       "      <td>9595.794</td>\n",
       "      <td>HUGR020</td>\n",
       "      <td>POLYGON ((21.13208 46.77291, 21.13208 46.77375...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HUGR021</td>\n",
       "      <td>189,000</td>\n",
       "      <td>46.423</td>\n",
       "      <td>18.896</td>\n",
       "      <td>6442080</td>\n",
       "      <td>189538</td>\n",
       "      <td>HUGR021</td>\n",
       "      <td>C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>188597.110</td>\n",
       "      <td>HUGR021</td>\n",
       "      <td>POLYGON ((18.91708 46.41791, 18.91708 46.41625...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HUGR022</td>\n",
       "      <td>28,500</td>\n",
       "      <td>48.126</td>\n",
       "      <td>22.340</td>\n",
       "      <td>6444304</td>\n",
       "      <td>29057</td>\n",
       "      <td>HUGR022</td>\n",
       "      <td>C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...</td>\n",
       "      <td>-1.917</td>\n",
       "      <td>28507.473</td>\n",
       "      <td>HUGR022</td>\n",
       "      <td>POLYGON ((22.32875 48.10875, 22.32791 48.10875...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HUGR023</td>\n",
       "      <td>188,000</td>\n",
       "      <td>46.627</td>\n",
       "      <td>18.869</td>\n",
       "      <td>6442060</td>\n",
       "      <td>189092</td>\n",
       "      <td>HUGR023</td>\n",
       "      <td>C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>188286.167</td>\n",
       "      <td>HUGR023</td>\n",
       "      <td>POLYGON ((18.89041 46.62875, 18.88875 46.62708...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HUGR025</td>\n",
       "      <td>1,210</td>\n",
       "      <td>47.662</td>\n",
       "      <td>19.683</td>\n",
       "      <td>6444240</td>\n",
       "      <td>1222</td>\n",
       "      <td>HUGR025</td>\n",
       "      <td>C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>1206.441</td>\n",
       "      <td>HUGR025</td>\n",
       "      <td>POLYGON ((19.68124 47.66875, 19.68291 47.66875...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id area_km2  outlet_lat  outlet_lng     name area_offic    layer  \\\n",
       "0  HUGR020    9,600      46.785      21.142  6444410       9011  HUGR020   \n",
       "1  HUGR021  189,000      46.423      18.896  6442080     189538  HUGR021   \n",
       "2  HUGR022   28,500      48.126      22.340  6444304      29057  HUGR022   \n",
       "3  HUGR023  188,000      46.627      18.869  6442060     189092  HUGR023   \n",
       "4  HUGR025    1,210      47.662      19.683  6444240       1222  HUGR025   \n",
       "\n",
       "                                                path  area_diff   area_calc  \\\n",
       "0  C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...      6.536    9595.794   \n",
       "1  C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...     -0.284  188597.110   \n",
       "2  C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...     -1.917   28507.473   \n",
       "3  C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...     -0.577  188286.167   \n",
       "4  C:/Users/nascimth/Documents/Thiago/Eawag/Pytho...     -0.982    1206.441   \n",
       "\n",
       "  basin_id                                           geometry  \n",
       "0  HUGR020  POLYGON ((21.13208 46.77291, 21.13208 46.77375...  \n",
       "1  HUGR021  POLYGON ((18.91708 46.41791, 18.91708 46.41625...  \n",
       "2  HUGR022  POLYGON ((22.32875 48.10875, 22.32791 48.10875...  \n",
       "3  HUGR023  POLYGON ((18.89041 46.62875, 18.88875 46.62708...  \n",
       "4  HUGR025  POLYGON ((19.68124 47.66875, 19.68291 47.66875...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catchment_boundaries = gpd.read_file(PATH_shapefile)\n",
    "catchment_boundaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563a4b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of catchments to be processed are: 33\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of catchments to be processed are:\", len(catchment_boundaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e78cf",
   "metadata": {},
   "source": [
    "# Reproject to WGS-84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284610e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CRS of the shapefile's geometry to EPSG:4326 (WGS 84)\n",
    "catchment_boundaries[\"geometry\"] = catchment_boundaries[\"geometry\"].to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f253c199",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d5b80",
   "metadata": {},
   "source": [
    "## Variable to be processed\n",
    "* Due to processing reasons PET for Iceland is stored in a different netcdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b0b5161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in NetCDF file for pet: dict_keys(['latitude', 'longitude', 'time', 'Hargreaves'])\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map variables to their corresponding file names\n",
    "variable_file_mapping = {\n",
    "    \"rr\": \"rr_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"tg\": \"tg_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"tn\": \"tn_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"tx\": \"tx_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"pp\": \"pp_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"hu\": \"hu_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"fg\": \"fg_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"qq\": \"qq_ens_mean_0.25deg_reg_v28.0e.nc\",\n",
    "    \"pet\": \"pet_hargreaves_025deg_v280e.nc\",\n",
    "    \"pet_iceland\": \"pet_hargreaves_iceland_025deg_v280e.nc\"\n",
    "}\n",
    "\n",
    "# Create a dictionary to map variables to their corresponding variable names\n",
    "variable_name_mapping = {\n",
    "    \"rr\": \"rr\",\n",
    "    \"tg\": \"tg\",\n",
    "    \"tn\": \"tn\",\n",
    "    \"tx\": \"tx\",\n",
    "    \"pp\": \"pp\",\n",
    "    \"hu\": \"hu\",\n",
    "    \"fg\": \"fg\",\n",
    "    \"qq\": \"qq\",\n",
    "    \"pet\": \"Hargreaves\",\n",
    "    \"pet_iceland\": \"Hargreaves\"\n",
    "\n",
    "}\n",
    "\n",
    "# Get the file name for the chosen variable\n",
    "nc_file = variable_file_mapping.get(chosen_variable)\n",
    "nc_variable_name = variable_name_mapping.get(chosen_variable)\n",
    "\n",
    "if nc_file is not None:\n",
    "    # Generate variable_name and path_preprocessing based on the chosen variable\n",
    "    variable_name = nc_variable_name\n",
    "    path_preprocessing = PATH_preprocessing + chosen_variable + \"/\"\n",
    "\n",
    "    # Read NetCDF data\n",
    "    with nc.Dataset(PATH_netcdfs + nc_file, mode='r', format='NETCDF4') as nc_dataset:\n",
    "        latitude = nc_dataset[\"latitude\"][:]\n",
    "        longitude = nc_dataset[\"longitude\"][:]\n",
    "        values = nc_dataset[variable_name][:]\n",
    "\n",
    "    # Print variables for checking\n",
    "    print(f\"Variables in NetCDF file for {chosen_variable}: {nc_dataset.variables.keys()}\")\n",
    "else:\n",
    "    print(\"Invalid variable choice.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518d51c",
   "metadata": {},
   "source": [
    "## Calculate pixels extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7fbe5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pixel extents using vectorized operations\n",
    "lon_idx, lat_idx = np.meshgrid(range(len(longitude)), range(len(latitude)))\n",
    "pixel_extents = np.stack(\n",
    "    (longitude[lon_idx], latitude[lat_idx], longitude[lon_idx] + 0.25, latitude[lat_idx] + 0.25),\n",
    "    axis=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c459d8",
   "metadata": {},
   "source": [
    "## Extract catchment names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34c94ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HUGR020',\n",
       " 'HUGR021',\n",
       " 'HUGR022',\n",
       " 'HUGR023',\n",
       " 'HUGR025',\n",
       " 'HUGR026',\n",
       " 'HUGR027',\n",
       " 'HUGR028',\n",
       " 'HUGR029',\n",
       " 'HUGR030',\n",
       " 'HUGR031',\n",
       " 'HUGR032',\n",
       " 'HUGR033',\n",
       " 'HUGR034',\n",
       " 'HUGR035',\n",
       " 'HUGR036',\n",
       " 'HUGR037',\n",
       " 'HUGR038',\n",
       " 'HUGR039',\n",
       " 'HUGR040',\n",
       " 'HUGR041',\n",
       " 'HUGR042',\n",
       " 'HUGR043',\n",
       " 'HUGR044',\n",
       " 'HUGR045',\n",
       " 'HUGR046',\n",
       " 'HUGR047',\n",
       " 'HUGR048',\n",
       " 'HUGR049',\n",
       " 'HUGR050',\n",
       " 'HUGR051',\n",
       " 'HUGR019',\n",
       " 'HUGR024']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract catchment names. \n",
    "if chosen_variable == \"pet_iceland\":\n",
    "    # Extract catchment names for Iceland \n",
    "    desired_substring = 'ISGR'\n",
    "    subset_catchment = catchment_boundaries[catchment_boundaries['basin_id'].str.contains(desired_substring)]\n",
    "    catchmentnames = subset_catchment.basin_id.tolist()\n",
    "else:\n",
    "    catchmentnames = catchment_boundaries.basin_id.tolist()\n",
    "\n",
    "catchmentnames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1439a082",
   "metadata": {},
   "source": [
    "## Parallel processing of the catchment polygons\n",
    "* This process may take a while deoending on the used machine and configurations adopted\n",
    "* The output of this phase is the export of individual CSV-files for each catchment for each variable.\n",
    "* The data will be later concatenate together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0108e467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 814.63it/s]\n",
      "/Users/thiagomedeirosdonascimento/Library/CloudStorage/OneDrive-Personal/PhD/Eawag/Papers/Paper1_Database/GitHub/EStreams/code/python/utils/meteorology.py:120: RuntimeWarning: invalid value encountered in divide\n",
      "  weighted_sum = np.where(sum_valid_weights > 0, valid_weighted_sum / sum_valid_weights, np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catchment HUGR025. Processed.\n",
      "Catchment HUGR020. Processed.\n",
      "Catchment HUGR022. Processed.\n",
      "Catchment HUGR021. Processed.\n",
      "Catchment HUGR023. Processed.\n",
      "Catchment HUGR026. Processed.\n",
      "Catchment HUGR027. Processed.\n",
      "Catchment HUGR030. Processed.\n",
      "Catchment HUGR028. Processed.\n",
      "Catchment HUGR029. Processed.\n",
      "Catchment HUGR033. Processed.\n",
      "Catchment HUGR031. Processed.\n",
      "Catchment HUGR035. Processed.\n",
      "Catchment HUGR034. Processed.\n",
      "Catchment HUGR032. Processed.\n",
      "Catchment HUGR036. Processed.\n",
      "Catchment HUGR037. Processed.\n",
      "Catchment HUGR038. Processed.\n",
      "Catchment HUGR039. Processed.\n",
      "Catchment HUGR040. Processed.\n",
      "Catchment HUGR042. Processed.\n",
      "Catchment HUGR043. Processed.\n",
      "Catchment HUGR041. Processed.\n",
      "Catchment HUGR045. Processed.\n",
      "Catchment HUGR044. Processed.\n",
      "Catchment HUGR046. Processed.\n",
      "Catchment HUGR047. Processed.\n",
      "Catchment HUGR049. Processed.\n",
      "Catchment HUGR048. Processed.\n",
      "Catchment HUGR050. Processed.\n",
      "Catchment HUGR051. Processed.\n",
      "Catchment HUGR024. Processed.\n",
      "Catchment HUGR019. Processed.\n",
      "Total time: 40.42923879623413\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    futures = [executor.submit(process_catchment, catchmentname, catchment_boundaries, values, latitude, longitude, path_preprocessing, variable_name = chosen_variable)\n",
    "               for catchmentname in tqdm.tqdm(catchmentnames)]\n",
    "    \n",
    "    # Wait for all futures to complete\n",
    "    for future in futures:\n",
    "        future.result()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Total time:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3890db",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
