{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e94d6f",
   "metadata": {},
   "source": [
    "# Complementary extra codes: Find duplicate candidates\n",
    "\n",
    "Author: Thiago Nascimento (thiago.nascimento@eawag.ch)\n",
    "\n",
    "This notebook complements the EStreams publication and can be used to find potential duplicated catchments within the dataset, following the criterion described in the EStreams manuscript.\n",
    "\n",
    "* Note that this code enables not only the replicability of the current database but also the extrapolation to new catchment areas. \n",
    "* Additionally, the user should download and insert the original raw-data in the folder of the same name prior to run this code. \n",
    "* The original third-party data used were not made available in this repository due to redistribution and storage-space reasons.  \n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "\n",
    "* Python>=3.6\n",
    "* Jupyter\n",
    "* geopandas=0.10.2\n",
    "* numpy\n",
    "* os\n",
    "* pandas\n",
    "* shapely\n",
    "* textdistance\n",
    "* tqdm\n",
    "* warnings\n",
    "\n",
    "Check the Github repository for an environment.yml (for conda environments) or requirements.txt (pip) file.\n",
    "\n",
    "**Files:**\n",
    "\n",
    "* data/streamflow/estreams_gauging_stations.csv\n",
    "\n",
    "**Directory:**\n",
    "\n",
    "* Clone the GitHub directory locally\n",
    "* Place any third-data variables in their respective directory.\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. \n",
    "\n",
    "\n",
    "## Observations\n",
    "* As this step is rather qualitative, we believe that the users can also adapt the conditons accordinly to their needs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7648ab",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "import os\n",
    "import warnings\n",
    "import textdistance\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c9d67",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13078a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variable:\n",
    "# Relative path to your local directory\n",
    "PATH = \"../../..\"\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Constrains\n",
    "JARO_THRESHOLD = 0.7\n",
    "SPATIAL_THRESHOLD = 1000\n",
    "PROVIDER_THRESHOLD = 0.9\n",
    "SPATIAL_PROVIDER_THRESHOLD = 50\n",
    "AREA_THRESHOLD = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c05d88a",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f5fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-editable variables:\n",
    "PATH_OUTPUT = \"results/\"\n",
    "# Set the directory:\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909fe84",
   "metadata": {},
   "source": [
    "# Import data\n",
    "## Streamflow gauges network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b61c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_estreams = pd.read_csv('results/estreams_gauging_stations.csv', encoding='utf-8')\n",
    "network_estreams.set_index(\"basin_id\", inplace = True)\n",
    "network_estreams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d3d112",
   "metadata": {},
   "source": [
    "# Processing\n",
    "- Pre-process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e595f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to clip the data to be used:\n",
    "df = network_estreams.iloc[:, :]\n",
    "\n",
    "# Create a GeoDataFrame from DataFrame with WGS 84 coordinates\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(network_estreams['lon'], network_estreams['lat'])]\n",
    "gdf_wgs84 = gpd.GeoDataFrame(network_estreams, geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "# Reproject the GeoDataFrame to ETRS89 LAEA (EPSG:3035)\n",
    "gdf_etrs89 = gdf_wgs84.to_crs(epsg=3035)\n",
    "\n",
    "df = gdf_etrs89.loc[df.index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f293c70",
   "metadata": {},
   "source": [
    "- Compute the distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eee76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store distances\n",
    "distances = {}\n",
    "\n",
    "# Calculate Jaro-Winkler distance for each unique pair of 'gauge_name'\n",
    "for i, row1 in tqdm.tqdm(df.iterrows()):\n",
    "    for j, row2 in gdf_etrs89.iterrows():\n",
    "        # Skip self-comparisons\n",
    "        if i != j:\n",
    "            # Calculate gauge name distance\n",
    "            try:\n",
    "                gauge_distance = textdistance.jaro_winkler(row1['gauge_name'].lower(), row2['gauge_name'].lower())\n",
    "            except:\n",
    "                gauge_distance = np.nan\n",
    "                \n",
    "            # Calculate river distance\n",
    "            try:\n",
    "                river_distance = textdistance.jaro_winkler(row1['river'].lower(), row2['river'].lower())\n",
    "            except:\n",
    "                river_distance = np.nan\n",
    "                \n",
    "            provider_distance = row1['gauge_provider'].lower() == row2['gauge_provider'].lower()          \n",
    "        \n",
    "            # Calculate distance between points\n",
    "            point1 = row1['geometry']\n",
    "            point2 = row2['geometry']\n",
    "            point_distance = point1.distance(point2)\n",
    "            \n",
    "            # Calculate area_calc difference\n",
    "            area_calc_diff = abs(row1['area_calc'] - row2['area_calc']) / max(row1['area_calc'], row2['area_calc'])\n",
    "            \n",
    "            # Store distances along with first and second gauge indices only if gauge_distance > 0.9\n",
    "            if (gauge_distance > JARO_THRESHOLD) & (river_distance > JARO_THRESHOLD) & (point_distance < SPATIAL_THRESHOLD) & (provider_distance == False):\n",
    "                distances[(row1['gauge_name'], row2['gauge_name'])] = {\n",
    "                    'gauge_first_index': i, \n",
    "                    'gauge_second_index': j,\n",
    "                    'gauge_distance': gauge_distance, \n",
    "                    'river_distance': river_distance,\n",
    "                    'point_distance': point_distance,\n",
    "                    'provider_distance': provider_distance\n",
    "                }\n",
    "                \n",
    "            # Additional condition: if provider_distance is True and point_distance < 250m and area_calc_diff <= 0.01\n",
    "            if provider_distance and point_distance < SPATIAL_PROVIDER_THRESHOLD and area_calc_diff <= AREA_THRESHOLD:\n",
    "                distances[(row1['gauge_name'], row2['gauge_name'])] = {\n",
    "                    'gauge_first_index': i,\n",
    "                    'gauge_second_index': j,\n",
    "                    'gauge_distance': gauge_distance,\n",
    "                    'river_distance': river_distance,\n",
    "                    'point_distance': point_distance,\n",
    "                    'provider_distance': provider_distance\n",
    "                }\n",
    "\n",
    "# Convert dictionary to DataFrame for visualization\n",
    "dist_df = pd.DataFrame.from_dict(distances, orient='index')\n",
    "dist_df.index.names = ['gauge_name1', 'gauge_name2']\n",
    "dist_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c44fd9",
   "metadata": {},
   "source": [
    "- Quick overview of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf117439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of duplicates (considering only first row, so not necessarly accurate)\n",
    "len(dist_df.gauge_first_index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bbf861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the distances table\n",
    "dist_df[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the gauge with the most duplicated suspects\n",
    "most_common_name = dist_df['gauge_first_index'].value_counts().idxmax()\n",
    "\n",
    "print(\"The most common name in the column is:\", most_common_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4499a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check it out\n",
    "dist_df[dist_df.gauge_first_index == \"FR000504\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f75d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df[dist_df.provider_distance == True][dist_df.point_distance <= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb05506",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df[dist_df.provider_distance == True].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df[dist_df.gauge_first_index == \"ITLI0307\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae4574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gauges located in different providers\n",
    "dist_df[dist_df.provider_distance == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a visual inspection of the results\n",
    "dist_df['gauge_first_index'].value_counts().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a6bcfb",
   "metadata": {},
   "source": [
    "### Here we add the list of duplicated suspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbfd034",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_estreams[\"duplicated_suspect\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c13a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the first column:\n",
    "for gauge in tqdm.tqdm(dist_df.gauge_first_index):\n",
    "    \n",
    "    duplicated_list = str(dist_df.gauge_second_index[dist_df.gauge_first_index == gauge].tolist()).replace(\"[\", \"\")\n",
    "    duplicated_list = duplicated_list.replace(\"]\", \"\")\n",
    "    duplicated_list = duplicated_list.replace(\"'\", \"\")\n",
    "    network_estreams.loc[gauge, \"duplicated_suspect\"] = duplicated_list\n",
    "    network_estreams.loc[gauge, \"duplicated_suspect\"] = network_estreams.loc[gauge, \"duplicated_suspect\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbc6d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the second column:\n",
    "for gauge in tqdm.tqdm(dist_df.gauge_second_index):\n",
    "    \n",
    "    duplicated_list = str(dist_df.gauge_first_index[dist_df.gauge_second_index == gauge].tolist()).replace(\"[\", \"\")\n",
    "    duplicated_list = duplicated_list.replace(\"]\", \"\")\n",
    "    duplicated_list = duplicated_list.replace(\"'\", \"\")\n",
    "    network_estreams.loc[gauge, \"duplicated_suspect\"] = duplicated_list\n",
    "    network_estreams.loc[gauge, \"duplicated_suspect\"] = network_estreams.loc[gauge, \"duplicated_suspect\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the duplicated_suspect column\n",
    "network_estreams['duplicated_suspect'] = network_estreams['duplicated_suspect'].str.replace(r'\\s*,\\s*', ',')\n",
    "network_estreams['duplicated_suspect'] = network_estreams['duplicated_suspect'].str.split(',')\n",
    "network_estreams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4800b2",
   "metadata": {},
   "source": [
    "## Analysis of the duplicates\n",
    "- At this part we have the correct analysis, rater than the previous estimatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc187b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The number of duplicates suspects is\", network_estreams.duplicated_suspect.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35477766",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_estreams[network_estreams.gauge_country==\"LV\"].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d83027a",
   "metadata": {},
   "source": [
    "- Overview of the number of duplicates per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_duplicates = pd.DataFrame(network_estreams.groupby('gauge_country')['duplicated_suspect'].count())\n",
    "network_duplicates.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f02527",
   "metadata": {},
   "source": [
    "## Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01757eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data:\n",
    "dist_df.to_csv(\"results/extras/distance_mattrix_duplicates.csv\", encoding='utf-8')\n",
    "network_estreams.to_csv(\"results/extras/estreams_gauging_stations_duplicates.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee74dfa",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
