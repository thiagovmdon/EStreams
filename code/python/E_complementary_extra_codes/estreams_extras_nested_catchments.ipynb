{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e94d6f",
   "metadata": {},
   "source": [
    "# Complementary extra codes: Group basins, find nested catchments and number of gauges upstream\n",
    "\n",
    "Author: Thiago Nascimento (thiago.nascimento@eawag.ch)\n",
    "\n",
    "This notebook complements the EStreams publication. The code is divided into first assigning groups for each catchment based on their conectivity (e.g., Rhine, Danube, etc); creating a list of all the nested catchments within each basin; and computing the number of gauges upstream the given basin. \n",
    "\n",
    "* Note that this code enables not only the replicability of the current database but also the extrapolation to new catchment areas. \n",
    "* Additionally, the user should download and insert the original raw-data in the folder of the same name prior to run this code. \n",
    "* The original third-party data used were not made available in this repository due to redistribution and storage-space reasons.  \n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "\n",
    "* Python>=3.6\n",
    "* Jupyter\n",
    "* geopandas=0.10.2\n",
    "* numpy\n",
    "* os\n",
    "* pandas\n",
    "* shapely\n",
    "* networkx\n",
    "* tqdm\n",
    "\n",
    "Check the Github repository for an environment.yml (for conda environments) or requirements.txt (pip) file.\n",
    "\n",
    "**Files:**\n",
    "\n",
    "* results/estreams_catchments.shp \n",
    "* results/estreams_gauging_stations.csv\n",
    "\n",
    "**Directory:**\n",
    "\n",
    "* Clone the GitHub directory locally\n",
    "* Place any third-data variables in their respective directory.\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7648ab",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b9bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "from shapely.geometry import Polygon, Point\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f0a427",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13078a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variable:\n",
    "# Relative path to your local directory\n",
    "PATH = \"../../..\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d779eea",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527527f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-editable variables:\n",
    "PATH_OUTPUT = \"results/\"\n",
    "\n",
    "# Set the directory:\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54907f",
   "metadata": {},
   "source": [
    "# Import data\n",
    "## Catchment boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_boundaries = gpd.read_file('results/estreams_catchments.shp')\n",
    "catchment_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f823d",
   "metadata": {},
   "source": [
    "## Network information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb885499",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_EU = pd.read_csv('results/estreams_gauging_stations_duplicates.csv', encoding='utf-8')\n",
    "network_EU.set_index(\"basin_id\", inplace = True)\n",
    "network_EU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a2418",
   "metadata": {},
   "source": [
    "## Subset of the catchments to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c45687",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchments = catchment_boundaries.iloc[:, :]\n",
    "\n",
    "network = network_EU.copy()\n",
    "catchments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae820e82",
   "metadata": {},
   "source": [
    "## Make a buffer around the catchments\n",
    "* We can either make the buffer here, or upload an already buffered version (made using QGIS) which is faster. \n",
    "* The buffering using Python may take a considerable while. Interestingly if one make the buffer first for a subset and then to the complete list, it processes faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we assign a tolerance to overcome problems of catchments with delineations \n",
    "# slightly outside the other catchment. \n",
    "# This code may take a while.\n",
    "\n",
    "start_time = time.time()\n",
    "tolerance = 0.01\n",
    "catchments_buffer = catchments.copy()\n",
    "catchments_buffer['geometry'] = catchments['geometry'].buffer(tolerance)\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the total time elapsed\n",
    "print(\"Elapsed time: {:.1f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474a052",
   "metadata": {},
   "source": [
    "# Processing\n",
    "## Nested catchments groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153b1b0",
   "metadata": {},
   "source": [
    "* First we classifiy the catchments according to their possibility of being nested.\n",
    "* At the end we have groups (main watershed) to where each sub-catchment is assigned.\n",
    "* For example, watershed_group == 1 corresponds to the Rhine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested catchments:\n",
    "# Initialize an empty list to store nested catchments\n",
    "nested_catchments = []\n",
    "\n",
    "# Iterate over each catchment\n",
    "for index, catchment in tqdm.tqdm(catchments.iterrows()):\n",
    "    # Get the geometry of the current catchment\n",
    "    geom = catchment['geometry']\n",
    "    \n",
    "    # Iterate over other catchments to check if they are nested\n",
    "    for index2, other_catchment in catchments_buffer.iterrows():\n",
    "        # Skip the same catchment\n",
    "        if index == index2:\n",
    "            continue\n",
    "        \n",
    "        other_geom = other_catchment['geometry']\n",
    "        \n",
    "        # Check if the current catchment is completely within the other catchment\n",
    "        if geom.within(other_geom):\n",
    "            nested_catchments.append((catchment.basin_id, other_catchment.basin_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73329fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the big-groups (main watershed):\n",
    "# Initialize an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes for each catchment\n",
    "for index, catchment in catchments.iterrows():\n",
    "    G.add_node(catchment['basin_id'])\n",
    "\n",
    "# Add edges for nested catchments\n",
    "for nested_pair in nested_catchments:\n",
    "    G.add_edge(nested_pair[0], nested_pair[1])\n",
    "\n",
    "# Find connected components\n",
    "groups = list(nx.connected_components(G))\n",
    "\n",
    "# Assign groups to catchments\n",
    "group_assignment = {}\n",
    "for i, group in enumerate(groups):\n",
    "    for catchment_id in group:\n",
    "        group_assignment[catchment_id] = i + 1  # Assigning group numbers starting from 1\n",
    "\n",
    "# Update the catchments GeoDataFrame with the group assignments\n",
    "catchments['watershed_group'] = catchments['basin_id'].map(group_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea749d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchments.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1010cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchments[catchments.watershed_group == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee23b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_catchments_df = pd.DataFrame(nested_catchments)\n",
    "nested_catchments_df.columns = [\"catchment_1\", \"catchment_2\"]\n",
    "nested_catchments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3697137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_catchments_df.to_excel(\"results/extras/nested_catchments_assignment_one2one.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d62d5",
   "metadata": {},
   "source": [
    "## Nested catchments within \n",
    "* Here we provide the list of nested catchments within each catchment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a geometry column with Point objects for being used:\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(network['lon_snap'], network['lat_snap'])]\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "network = gpd.GeoDataFrame(network, geometry=geometry)\n",
    "\n",
    "# Optional: Set the coordinate reference system (CRS) if known\n",
    "# For example, if your coordinates are in WGS84 (EPSG:4326)\n",
    "network.crs = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4cf43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the results\n",
    "catchments_nested = []\n",
    "\n",
    "# Iterate through each catchments geometry\n",
    "for i, catchment in tqdm.tqdm(catchments.iterrows()):\n",
    "    # Find the network points located within the current catchments geometry\n",
    "    network_in_catchment = network[network.within(catchment.geometry)]\n",
    "\n",
    "    # Get the indices of the network points within the current catchments geometry\n",
    "    indices = network_in_catchment.index.tolist()\n",
    "\n",
    "    # Append the list of indices to the results list\n",
    "    catchments_nested.append(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed910d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of lists to a pandas DataFrame\n",
    "catchments_nested_df = pd.DataFrame({'nested_catchments': catchments_nested})\n",
    "\n",
    "# Set the index of the DataFrame to be the index of the catchments GeoDataFrame\n",
    "catchments_nested_df.index = catchments.basin_id\n",
    "\n",
    "# Check each row and replace empty lists with the index value\n",
    "# It may happen when the outlet is slightly outside (coordinates) the shapefile\n",
    "for index, row in catchments_nested_df.iterrows():\n",
    "    if not row['nested_catchments']:\n",
    "        catchments_nested_df.at[index, 'nested_catchments'] = [index]  # Replace the empty list with the index as a list\n",
    "          \n",
    "catchments_nested_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we make sure that the outlet is within the list:\n",
    "# Ensure that the basin_id is in the nested_catchments\n",
    "for basin_id in catchments_nested_df.index:\n",
    "    if basin_id not in catchments_nested_df.at[basin_id, 'nested_catchments']:\n",
    "        catchments_nested_df.at[basin_id, 'nested_catchments'].append(basin_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66b1865",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.loc[catchments_nested_df.loc[\"AT000001\", \"nested_catchments\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf22d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchments_nested_df.to_csv(\"results/extras/estreams_gauging_stations_nested_catchments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b096eca0",
   "metadata": {},
   "source": [
    "## Number of unique gauges upstream\n",
    "* Here we comoute the number of gauges upstream.\n",
    "* A headwater catchment will have a number 1, while a downstream catchment that has two gauges within (not counting the outlet) has a number 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34da5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the index to the shapefile:\n",
    "catchments.set_index(\"basin_id\", inplace = True)\n",
    "\n",
    "# Keep one field with the same name:\n",
    "catchments[\"basin_id\"] = catchments.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde23752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one field with the same name as the index:\n",
    "network[\"basin_id\"]= network.index\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a8636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a geometry column with Point objects for being used:\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(network['lon_snap'], network['lat_snap'])]\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "network = gpd.GeoDataFrame(network, geometry=geometry)\n",
    "\n",
    "# Optional: Set the coordinate reference system (CRS) if known\n",
    "# For example, if your coordinates are in WGS84 (EPSG:4326)\n",
    "network.crs = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16309549",
   "metadata": {},
   "source": [
    "### Apply the count taking into account some filters:\n",
    "       - Points to pay attention:\n",
    "* Outlet is seldom slightly outside the shapefile. \n",
    "* Catchment outlet has one duplicate within the shapefile.\n",
    "* Catchments within the shapefile also have duplicates. \n",
    "\n",
    "       - Solution:\n",
    "* We exclude the outlet from the count, and count + 1 at the end for all catchments. \n",
    "* We apply a filter to delete the catchment outlet to count duplicated_suspects that are within the catchment shapefile. \n",
    "* We count the number of duplicates, and when it is even, we simply divide per 2 and substract at the end count = count - (n/2). If it is odd, we do count = count - ((n - 1)/2 + 1). The reason is that when we have a two duplicates, they could delete each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486c99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial join to count geometries within the catchments shapefile\n",
    "joined = gpd.sjoin(catchments, network, how='inner', op='intersects')\n",
    "\n",
    "# Exclude geometries with the same \"basin_id\" as in the network GeoDataFrame (exclude the outlet):\n",
    "joined_filtered = joined[joined['basin_id_left'] != joined['basin_id_right']]\n",
    "\n",
    "# Here we create a function to deal with the duplicates of the outlet when they happen to be within:\n",
    "# Parse the \"duplicated_suspect\" column to extract individual basin_ids\n",
    "def parse_duplicated_suspect(suspect):\n",
    "    if pd.isna(suspect):\n",
    "        return []\n",
    "    else:\n",
    "        return suspect.split(', ')\n",
    "\n",
    "joined_filtered['duplicated_suspect_ids'] = joined_filtered['duplicated_suspect'].apply(parse_duplicated_suspect)\n",
    "\n",
    "# Exclude basin IDs from the count when there are duplicated suspects\n",
    "def exclude_duplicated_suspects(row):\n",
    "    if len(row['duplicated_suspect_ids']) > 0:\n",
    "        return row['basin_id_left'] not in row['duplicated_suspect_ids']\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "joined_filtered = joined_filtered[joined_filtered.apply(exclude_duplicated_suspects, axis=1)]\n",
    "\n",
    "# Count the number of geometries for each unique \"basin_id\" in the catchments shapefile\n",
    "count_per_basin = joined_filtered['basin_id_left'].value_counts()\n",
    "\n",
    "# Count the number of non-null values in the \"duplicated_suspect\" column for each basin ID\n",
    "duplicates_count = joined_filtered.groupby('basin_id_left')['duplicated_suspect'].count()\n",
    "\n",
    "# Adjust the count based on the number of duplicates within each catchment\n",
    "for basin_id, count in duplicates_count.items():\n",
    "    if count % 2 == 0:\n",
    "        count_per_basin[basin_id] -= count // 2\n",
    "    else:\n",
    "        count_per_basin[basin_id] -= (count - 1) // 2\n",
    "        count_per_basin[basin_id] += 1\n",
    "\n",
    "# Here we add 1 station to include the outlet\n",
    "count_per_basin += 1\n",
    "\n",
    "network[\"gauges_upstream\"] = np.nan      \n",
    "network[\"gauges_upstream\"] = count_per_basin\n",
    "\n",
    "# Filter the potential NaNs:\n",
    "network['gauges_upstream'] = network['gauges_upstream'].fillna(1)\n",
    "\n",
    "network.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c265d716",
   "metadata": {},
   "source": [
    "## Assign the new values to the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_EU['watershed_group'] = catchments['watershed_group']\n",
    "network_EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_EU['gauges_upstream'] = network['gauges_upstream'].astype(int)\n",
    "network_EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_EU[network_EU.watershed_group== 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdd49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_EU['nested_catchments'] = catchments_nested_df['nested_catchments']\n",
    "network_EU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ce1a9",
   "metadata": {},
   "source": [
    "## Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d952a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe:\n",
    "network_EU.to_csv('results/extras/estreams_gauging_stations_nested.csv',  encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e9d2f",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
